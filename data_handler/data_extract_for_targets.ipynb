{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2022/11/19 10:05\n",
    "# @Author  : Wang Yujia\n",
    "# @File    : data_extract_for_targets.ipynb\n",
    "# @Description : 为了target datas提取信息，而且提取data_key"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Preparations\n",
    "## 1.1 全局设置\n",
    "1. input的data包括那些duration过长的结果\n",
    "2. output一共`data_key.shape[0]`+1个文件"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Small dataset\n",
    "small_data_np_path = r'../data/small_auctions_np.csv'\n",
    "settings_small_NN_path = r\"../data/small_settings_NN.csv\"\n",
    "\n",
    "# Large data\n",
    "large_data_np_path = r'E:\\DATA\\large_dta\\large_auctions_np.csv'\n",
    "settings_large_NN_path = r'E:\\DATA\\large_dta\\large_settings_NN.csv'\n",
    "\n",
    "# output path\n",
    "target_output_head= \"../data/targets_all/target_data_NP_\"\n",
    "target_output_tail= \".csv\"\n",
    "data_key_path = \"../data/target_datakey_all.csv\"\n",
    "\n",
    "unique_setting_NN = ['desc','bidincrement','bidfee','retail','flg_endprice']\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from visdom import Visdom\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2 data读取"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "小数据集有 *1196* 场auction，大数据集有 *80* 场auction，一共*1276*\n"
     ]
    }
   ],
   "source": [
    "data_small = pd.read_csv(small_data_np_path,encoding=\"utf-8\")\n",
    "data_large = pd.read_csv(large_data_np_path,encoding=\"utf-8\")\n",
    "\n",
    "data_key_small = pd.read_csv(settings_small_NN_path,encoding=\"utf-8\")\n",
    "data_key_large = pd.read_csv(settings_large_NN_path,encoding=\"utf-8\")\n",
    "\n",
    "len_small = data_key_small.shape[0]\n",
    "len_large = data_key_large.shape[0]\n",
    "print(f\"小数据集有 *{len_small}* 场auction，大数据集有 *{len_large}* 场auction，一共*{len_small+len_large}*\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.3 functions about 'key'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def select_data_fromkey(data,data_key,i):\n",
    "    return data[(data['desc'] == data_key.iloc[i,0]) &\n",
    "                (data['bidincrement'] == data_key.iloc[i,1]) &\n",
    "                (data['bidfee'] == data_key.iloc[i,2]) &\n",
    "                (data['retail'] == data_key.iloc[i,3]) &\n",
    "                (data['flg_endprice'] == data_key.iloc[i,4])].copy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. 整理与输出\n",
    "\n",
    "1. 最后的data只有N和P，\n",
    "2. 注意一定要按照`data_key`逐行保存csv，这样index可以对应\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "plot_flag = 0\n",
    "if(plot_flag):\n",
    "    env_str = 'N_targets'\n",
    "    viz = Visdom(env=env_str)\n",
    "\n",
    "# Col we want to save in target file\n",
    "col_names = unique_setting_NN+['N','cnt_N','P']\n",
    "col_NP = ['N','P']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 先做small的"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 125.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum of cnt_N:3539, len of file: 1381\n",
      "    auction_id  product_id                         desc  retail  price  \\\n",
      "0       132599    10011393  DS | Nintendo DS Lite Black  129.99   1.05   \n",
      "1       129477    10011406  DS | Nintendo DS Lite Black  129.99   1.50   \n",
      "2       106657    10007296  DS | Nintendo DS Lite Black  129.99   1.80   \n",
      "3       142964    10011393  DS | Nintendo DS Lite Black  129.99   2.10   \n",
      "4       126670    10011316  DS | Nintendo DS Lite Black  129.99   2.10   \n",
      "5       134657    10011393  DS | Nintendo DS Lite Black  129.99   2.25   \n",
      "6       142789    10011499  DS | Nintendo DS Lite Black  129.99   2.40   \n",
      "7       134817    10010658  DS | Nintendo DS Lite Black  129.99   2.55   \n",
      "8       149583    10011393  DS | Nintendo DS Lite Black  129.99   3.15   \n",
      "9       143338    10011499  DS | Nintendo DS Lite Black  129.99   3.45   \n",
      "10      153649    10011393  DS | Nintendo DS Lite Black  129.99   3.45   \n",
      "11      143306    10011499  DS | Nintendo DS Lite Black  129.99   3.45   \n",
      "12      127854    10011393  DS | Nintendo DS Lite Black  129.99   3.45   \n",
      "13      127852    10011393  DS | Nintendo DS Lite Black  129.99   3.45   \n",
      "14       97846    10010185  DS | Nintendo DS Lite Black  129.99   3.60   \n",
      "15       99958    10007296  DS | Nintendo DS Lite Black  129.99   3.60   \n",
      "16      143334    10011499  DS | Nintendo DS Lite Black  129.99   3.60   \n",
      "17      126667    10011316  DS | Nintendo DS Lite Black  129.99   3.90   \n",
      "18      132584    10011393  DS | Nintendo DS Lite Black  129.99   4.05   \n",
      "19      136735    10011499  DS | Nintendo DS Lite Black  129.99   4.05   \n",
      "\n",
      "    bidincrement  bidfee  flg_endprice   N  cnt_N         P  \n",
      "0           0.15    0.75             0   7      1  0.000724  \n",
      "1           0.15    0.75             0  10      1  0.000724  \n",
      "2           0.15    0.75             0  12      1  0.000724  \n",
      "3           0.15    0.75             0  14      2  0.001448  \n",
      "4           0.15    0.75             0  14      2  0.001448  \n",
      "5           0.15    0.75             0  15      1  0.000724  \n",
      "6           0.15    0.75             0  16      1  0.000724  \n",
      "7           0.15    0.75             0  17      1  0.000724  \n",
      "8           0.15    0.75             0  21      1  0.000724  \n",
      "9           0.15    0.75             0  23      5  0.003621  \n",
      "10          0.15    0.75             0  23      5  0.003621  \n",
      "11          0.15    0.75             0  23      5  0.003621  \n",
      "12          0.15    0.75             0  23      5  0.003621  \n",
      "13          0.15    0.75             0  23      5  0.003621  \n",
      "14          0.15    0.75             0  24      3  0.002172  \n",
      "15          0.15    0.75             0  24      3  0.002172  \n",
      "16          0.15    0.75             0  24      3  0.002172  \n",
      "17          0.15    0.75             0  26      1  0.000724  \n",
      "18          0.15    0.75             0  27      2  0.001448  \n",
      "19          0.15    0.75             0  27      2  0.001448  \n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len_small)):\n",
    "# for i in tqdm(range(11,12)):\n",
    "\n",
    "    # Get data according to the data_key\n",
    "    data_i = select_data_fromkey(data_small,data_key_small,i)\n",
    "    # Sort data according to 'N'\n",
    "    data_i.reset_index(drop=True,inplace=True)\n",
    "    data_i.sort_values(by='N',ignore_index=True,inplace=True)\n",
    "    # Only keep col we need\n",
    "    data_i_df = data_i[col_NP]\n",
    "\n",
    "    # Get the output path\n",
    "    target_output_path = target_output_head+str(i).zfill(4)+target_output_tail\n",
    "    data_i_df.to_csv(target_output_path,header=True,index=False,encoding=\"utf-8\")\n",
    "\n",
    "print(\"Done\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 大数据集"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:00<00:00, 586.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len_large)):\n",
    "\n",
    "    # Get data according to the data_key\n",
    "    data_i = select_data_fromkey(data_large,data_key_large,i)\n",
    "    # Sort data according to 'N'\n",
    "    data_i.reset_index(drop=True,inplace=True)\n",
    "    data_i.sort_values(by='N',ignore_index=True,inplace=True)\n",
    "    # Only keep col we need\n",
    "    data_i_df = data_i[col_NP]\n",
    "    # Get the output path\n",
    "    target_output_path = target_output_head+str(i+len_small).zfill(4)+target_output_tail\n",
    "    data_i_df.to_csv(target_output_path,header=True,index=False,encoding=\"utf-8\")\n",
    "\n",
    "print(\"Done\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- concat and save key"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "data_key = pd.concat([data_key_small,data_key_large],axis=0,ignore_index=True)\n",
    "data_key.to_csv(data_key_path,encoding=\"utf-8\",header=True,index=False)\n",
    "data_key.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. 整理粒度(TARGET = 5)\n",
    "1. 添加了“整理粒度”的代码，注意必须有'cnt'这个属性才可以进行粒度的整理\n",
    "2. 对于DA之后的target data，重新整理粒度的代码在DA那个文件里"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TARGET = 5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
