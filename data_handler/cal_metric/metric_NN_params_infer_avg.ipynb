{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1. 'InferNet(AVG)'\n",
    "2. 用avg on training set作为testing set的param value值\n",
    "2. 然后计算testing set的metric"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from metric_for_GTs_func import *\n",
    "from MLP.utils import setup_seed\n",
    "\n",
    "ARTIFICIAL = True\n",
    "noise_pct = 0.05\n",
    "SET_VAL = False\n",
    "seed = 512      # 3,31,204,223,407,62,508，626 # [4,31,34,204,407,66,508,512]\n",
    "\n",
    "\n",
    "train_pct = 0.7\n",
    "vali_pct = 0.2\n",
    "test_pct = 0.1\n",
    "\n",
    "\n",
    "if ARTIFICIAL:\n",
    "    target_path = \"../data/artificial_targets_v2_\" + \"noise=\" + str(noise_pct)\n",
    "    # SA 的 params\n",
    "    params_opitim_path_SA = \"../data/SA_PT/params_opitim_artificial_v2_noise_\"+str(noise_pct)+\".csv\"\n",
    "    # params_opitim_path_SA = \"../data/SA_PT/params_opitim_artificial_noise_\"+str(noise_pct)+\".csv\"\n",
    "    params_opitim_unified_path = r\"../data/SA_PT/params_artificial_unified_noise=\"+str(noise_pct)+ \"_seed=\"+str(seed)+\".csv\"\n",
    "else:\n",
    "    target_path = \"../data/targets_all\"\n",
    "    # SA 的 params\n",
    "    params_opitim_path_SA = \"../data/SA_PT/params_opitim_delta_T.csv\"\n",
    "    params_opitim_unified_path = \"../data/SA_PT/params_opitim_unified_seed=\"+str(seed)+\".csv\"\n",
    "\n",
    "# Small dataset\n",
    "small_settings_NN_path = r\"../data/small_settings_NN.csv\"\n",
    "# Large data\n",
    "large_settings_NN_path = r'E:\\DATA\\large_dta\\large_settings_NN.csv'\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "AVG = False\n",
    "# 计算GT2-AVG\n",
    "UNIFIED = True  # 计算GT2-Unified"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# target_path里有全部的target data地址\n",
    "target_all_path = os.listdir(target_path)\n",
    "\n",
    "data_key_small = pd.read_csv(small_settings_NN_path,encoding=\"utf-8\")\n",
    "data_key_large = pd.read_csv(large_settings_NN_path,encoding=\"utf-8\")\n",
    "\n",
    "data_key = pd.concat([data_key_small,data_key_large],axis=0,ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set pct: 0.19984326018808776\n"
     ]
    }
   ],
   "source": [
    "setup_seed(seed)\n",
    "\n",
    "DATA_len = len(target_all_path)\n",
    "shuffled_indices = np.random.permutation(DATA_len)\n",
    "\n",
    "\n",
    "train_idx = shuffled_indices[:int(train_pct * DATA_len)]\n",
    "if SET_VAL:\n",
    "    tmp = int((train_pct + vali_pct) * DATA_len)\n",
    "    val_idx = shuffled_indices[int(train_pct * DATA_len):tmp]\n",
    "    test_idx = shuffled_indices[tmp:]\n",
    "else :\n",
    "    # Exchange. 20% for testing\n",
    "    tmp = int((train_pct + vali_pct) * DATA_len)\n",
    "    test_idx = shuffled_indices[int(train_pct * DATA_len):tmp]\n",
    "    val_idx = shuffled_indices[tmp:]\n",
    "print(f\"test set pct: {len(test_idx)/DATA_len}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "-\n",
    "- 计算avg param values\n",
    "- 或者计算unified"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "array([3.5, 4.5])"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 创建原始数组\n",
    "arr = np.array([1, 2, 3.5, 4.5])\n",
    "\n",
    "# 创建布尔数组\n",
    "mask = arr > 2.5\n",
    "\n",
    "# 使用布尔数组提取大于2.5的数值\n",
    "result = arr[mask]\n",
    "arr[arr > 2.5]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "if AVG:\n",
    "    params_opitim_SA = pd.read_csv(params_opitim_path_SA,encoding=\"utf-8\")\n",
    "    params_train = params_opitim_SA.iloc[train_idx,:].copy()\n",
    "    params_avg = params_train.reset_index().mean()\n",
    "\n",
    "    alpha = params_avg.alpha\n",
    "    labda = params_avg.labda\n",
    "elif UNIFIED:\n",
    "    params_train = pd.read_csv(params_opitim_unified_path,encoding=\"utf-8\")\n",
    "    # avg_loss最低的那个\n",
    "    idx = params_train.avg_loss.idxmin(0)\n",
    "    params_unified = params_train.iloc[idx,:]\n",
    "\n",
    "    alpha = params_unified.alpha\n",
    "    labda = params_unified.labda"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 计算testing上的metric"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "(-0.000597471772696, 9.17836246339773, 512)"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NLL_metric = []\n",
    "alpha,labda,seed"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "for i in test_idx:\n",
    "        # Get target data\n",
    "        target_path_i_path = os.path.join(target_path, target_all_path[i])\n",
    "        target_df = pd.read_csv(target_path_i_path,encoding=\"utf-8\")\n",
    "        target = list(target_df.iloc[:,0])\n",
    "\n",
    "        # Get the auction setting\n",
    "        settings_df = data_key.iloc[i,:]\n",
    "\n",
    "        # GT-2: SA-AVG\n",
    "        NLL_metric.append(GT_2_uniq(settings_df,target,alpha,labda))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "255"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(NLL_metric)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed= 512\n"
     ]
    },
    {
     "data": {
      "text/plain": "6.425299187556018"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"seed=\",seed)\n",
    "np.mean(NLL_metric)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
