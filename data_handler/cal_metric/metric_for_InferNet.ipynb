{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 0. Intro\n",
    "1. 计算得到GT2(InferNet)和GT3(InferNet)对于testing set上的NLL和KL-D\n",
    "\n",
    "# 1. Preparations\n",
    "## 1.1 global settings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "from MLP.utils import *\n",
    "import os\n",
    "\n",
    "# For GT-2\n",
    "from GT_model.GT_2.SA_for_PT_funcs_delta_eq1 import *\n",
    "import GT_model.GT_2.SA_for_PT_funcs_delta_eq1\n",
    "# reload(GT_model.GT_2.SA_for_PT_funcs_delta_eq1)\n",
    "from importlib import reload\n",
    "import metric_for_GTs_func\n",
    "from metric_for_GTs_func import *\n",
    "reload(metric_for_GTs_func)\n",
    "\n",
    "from MLP.Config.config_base import BaseConfig\n",
    "config = BaseConfig()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2 the data path\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "ARTIFICIAL = True\n",
    "noise_pct = 0.05           # 噪音占比:我们希望生成的data总体上最多浮动的百分比noise_pct\n",
    "# seed = 3                 # [3,31,204,223,407]\n",
    "q=1                        # q=1表示不使用quantile 计算metric\n",
    "THRESHOLD = 0   # 0: 计算全部的data\n",
    "\n",
    "# Target data\n",
    "if ARTIFICIAL:\n",
    "        target_path = \"../../data/artificial_targets_v2_\" + \"noise=\" + str(noise_pct)\n",
    "else:\n",
    "        target_path = r\"../../data/targets_all\"\n",
    "\n",
    "# Output\n",
    "output_path = r\"../../MLP/metric_saved/\"\n",
    "prefix = \"\"\n",
    "if ARTIFICIAL:\n",
    "        prefix = \"synthetic_\"\n",
    "else:\n",
    "        prefix = \"real_\"\n",
    "\n",
    "# Input: GT-2 params\n",
    "# if ARTIFICIAL:\n",
    "#         # GT-2 NN 产生的params\n",
    "#         params_opitim_path_NN = r\"../data/SA_PT/params_artificial_v2_noise=\" + str(noise_pct)+\"_seed=\" + str(seed) + \".csv\"\n",
    "#         # SA 的 params\n",
    "#         params_opitim_path_SA = \"../data/SA_PT/params_opitim_artificial_v2_noise_\"+str(noise_pct)+\".csv\"\n",
    "# else:\n",
    "#         # GT-2 NN 产生的params\n",
    "#         params_opitim_path_NN_2 = r\"../data/SA_PT/params_seed=\" + str(seed) + \".csv\"\n",
    "#         params_opitim_path_NN_3 = r\"../data/SA_PT/params_GT3_seed=\" + str(seed) + \".csv\"\n",
    "#         # SA 的 params\n",
    "#         params_opitim_path_SA = \"../data/SA_PT/params_opitim_delta_T.csv\"\n",
    "\n",
    "# target data是target_5时 TARGET = 5\n",
    "TARGET = 1\n",
    "\n",
    "# Output path\n",
    "# 3 col and 4 col\n",
    "# if ARTIFICIAL:\n",
    "#         NLL_metric_path_1  = r\"../data/GT_metric/NLL_metric_GT_Tgt=1_e30_artificial_v_2_noise=\"+str(noise_pct)+\".csv\"\n",
    "#         NLL_metric_path_2  =\"../data/GT_metric/NLL_metric_GT_Tgt=1_e30_all_\"+\"artificial_targets_v2_\" + \"noise=\" + str(noise_pct)+\"_seed=\"+str(seed)+\".csv\"\n",
    "# else:\n",
    "#         NLL_metric_path_1  =\"../data/GT_metric/NLL_metric_GT_Tgt=1_e30.csv\"\n",
    "#         # 添加的这一列和seed有关！\n",
    "#         NLL_metric_path_2  =\"../data/GT_metric/NLL_metric_GT_Tgt=1_e30_seed=\"+str(seed)+\".csv\"\n",
    "\n",
    "col_names = ['GT2(NN)','GT3(NN)']\n",
    "\n",
    "# For GT-2\n",
    "alpha = -0.013581112\n",
    "delta = 1\n",
    "labda = 3.312402533\n",
    "\n",
    "MIN_LOSS = 1e-30"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.3 Read in"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一共*1276*场auction\n"
     ]
    }
   ],
   "source": [
    "data_key = pd.read_csv(config.data_key_path,encoding=\"utf-8\")\n",
    "\n",
    "# target_path里有全部的target data地址\n",
    "target_all_path = os.listdir(target_path)\n",
    "len_all = len(target_all_path)\n",
    "print(f\"一共*{len(data_key)}*场auction\")\n",
    "\n",
    "assert len_all == len(data_key),\"wrong in len_all\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Random seed"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "\n",
    "# 简易的提取test set中的sample index\n",
    "def save_data_idx_simplified(LEN):\n",
    "        \"\"\"\n",
    "        因为objective function会被执行很多次，所以这里先保存一下idx，使得所有objective在同一组dataset上进行。\n",
    "        然后在tuning时，会在shuffle_time组不同的dataset split上进行，用以取平均\n",
    "        Args:\n",
    "        dataset:\n",
    "        opt:\n",
    "        shuffle_time: The num of list of index to be generated.\n",
    "        \"\"\"\n",
    "        shuffled_indices = np.random.permutation(LEN)\n",
    "\n",
    "        return shuffled_indices"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Compute the KL-D for GT1, GT2(InferNet), GT3(InferNet)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "[4, 31, 35, 66, 204, 407, 508, 512]"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Real\n",
    "if not ARTIFICIAL:\n",
    "        seed_list = [3,31,62,204,223,407,508,626]\n",
    "\n",
    "## Synth.\n",
    "else:\n",
    "        seed_list = [4,31,35,66,204,407,508,512]\n",
    "seed_list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== seed = 4 ==========\n",
      "========== seed = 31 ==========\n",
      "========== seed = 35 ==========\n",
      "========== seed = 66 ==========\n"
     ]
    }
   ],
   "source": [
    "GT_metric_pd_KL = pd.DataFrame()\n",
    "\n",
    "for seed in seed_list:\n",
    "        setup_seed(seed)\n",
    "        shuffled_indices = save_data_idx_simplified(len_all)\n",
    "        _,_,test_idx = get_data_idx(shuffled_indices, train_pct = config.train_pct, vali_pct=config.vali_pct)\n",
    "\n",
    "        print(f\"========== seed = {seed} ==========\")\n",
    "\n",
    "        if not ARTIFICIAL:\n",
    "                params_opitim_path_NN_2 = r\"../../data/SA_PT/params_GT2_seed=\" + str(seed) + \".csv\"\n",
    "                params_opitim_path_NN_3 = r\"../../data/SA_PT/params_GT3_seed=\" + str(seed) + \".csv\"\n",
    "        else:\n",
    "                params_opitim_path_NN_2 = r\"../../data/SA_PT/params_artificial_GT2_noise=\" + str(noise_pct)+\"_seed=\" + str(seed) + \".csv\"\n",
    "                params_opitim_path_NN_3 = r\"../../data/SA_PT/params_artificial_GT3_noise=\" + str(noise_pct)+\"_seed=\" + str(seed) + \".csv\"\n",
    "\n",
    "        params_opitim_NN_2 = pd.read_csv(params_opitim_path_NN_2,encoding=\"utf-8\")\n",
    "        params_opitim_NN_3 = pd.read_csv(params_opitim_path_NN_3,encoding=\"utf-8\")\n",
    "\n",
    "        pd_idx = 0\n",
    "        metric_pd = pd.DataFrame()\n",
    "        for i in test_idx:\n",
    "                # Get target data\n",
    "                target_path_i_path = os.path.join(target_path, target_all_path[i])\n",
    "                target_df = pd.read_csv(target_path_i_path,encoding=\"utf-8\")\n",
    "                # target = list(target_df.iloc[:,0]) # NLL 使用\n",
    "                target_df_uniq = pd.DataFrame(np.unique(target_df,axis=0)) # KL-D计算必须有这一步，去掉N值重复的sample\n",
    "\n",
    "                if target_df.shape[0] >= THRESHOLD:\n",
    "                        pass\n",
    "                else:   # 不计算少于THRESHOLD的auction\n",
    "                        continue\n",
    "\n",
    "                # if not ARTIFICIAL:\n",
    "                #         target_df_uniq = pd.DataFrame(np.unique(target_df,axis=0)) # KL-D计算必须有这一步，去掉N值重复的sample\n",
    "                # else: # 对于生成数据，不包含P列，需要手动计算\n",
    "                #         target_df_group = target_df.groupby(by = ['N'],as_index=False).size()\n",
    "                #         target_df_group['P'] = target_df_group['size'] / sum(target_df_group['size'])\n",
    "                #\n",
    "                #         target_df_uniq = pd.merge(left = target_df, right=target_df_group ,how=\"left\", on=['N'])\n",
    "                #         target_df_uniq.drop(labels='size',axis=1,inplace=True)\n",
    "                #         target_df_uniq = pd.DataFrame(np.unique(target_df_uniq,axis=0)).copy()    # KL-D计算必须有这一步，去掉N值重复的sample\n",
    "                #         target_df_uniq.columns = ['N','P']\n",
    "\n",
    "                # Get the auction setting of i_th according to the test_idx\n",
    "                settings_df = data_key.iloc[i,:]\n",
    "\n",
    "                alpha_2 = params_opitim_NN_2.loc[i,'alpha'].item()\n",
    "                labda_2 = params_opitim_NN_2.loc[i,'labda'].item()\n",
    "                alpha_3 = params_opitim_NN_3.loc[i,'alpha'].item()\n",
    "\n",
    "                # metric_pd.loc[pd_idx,col_names[0]] = GT1_KL(settings_df,target_df_uniq)\n",
    "                metric_pd.loc[pd_idx,col_names[0]] = GT2_KL(settings_df,target_df_uniq,alpha_2,labda_2)\n",
    "                metric_pd.loc[pd_idx,col_names[1]] = GT3_KL(settings_df,target_df_uniq,alpha_3)\n",
    "\n",
    "                pd_idx += 1\n",
    "\n",
    "        # GT_metric_pd_KL.loc[seed,col_names[0]] = np.mean(metric_pd.loc[:,col_names[0]])\n",
    "        GT_metric_pd_KL.loc[seed,col_names[0]] = np.mean(metric_pd.loc[:,col_names[0]])\n",
    "        GT_metric_pd_KL.loc[seed,col_names[1]] = np.mean(metric_pd.loc[:,col_names[1]])\n",
    "\n",
    "\n",
    "GT_metric_pd_KL.reset_index(inplace=True)\n",
    "print(GT_metric_pd_KL)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "GT_metric_pd_KL"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "output_file = output_path + prefix +\"InferNet_metric_KL.csv\"\n",
    "GT_metric_pd_KL.to_csv(output_file)\n",
    "output_file"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Compute the NLL for GT1, GT2(InferNet), GT3(InferNet)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "GT_metric_pd_NLL = pd.DataFrame()\n",
    "\n",
    "for seed in seed_list:\n",
    "        setup_seed(seed)\n",
    "        shuffled_indices = save_data_idx_simplified(len_all)\n",
    "        _,_,test_idx = get_data_idx(shuffled_indices, train_pct = config.train_pct, vali_pct=config.vali_pct)\n",
    "\n",
    "        print(f\"========== seed = {seed} ==========\")\n",
    "\n",
    "        if not ARTIFICIAL:\n",
    "                params_opitim_path_NN_2 = r\"../../data/SA_PT/params_GT2_seed=\" + str(seed) + \".csv\"\n",
    "                params_opitim_path_NN_3 = r\"../../data/SA_PT/params_GT3_seed=\" + str(seed) + \".csv\"\n",
    "        else:\n",
    "                params_opitim_path_NN_2 = r\"../../data/SA_PT/params_artificial_GT2_noise=\" + str(noise_pct)+\"_seed=\" + str(seed) + \".csv\"\n",
    "                params_opitim_path_NN_3 = r\"../../data/SA_PT/params_artificial_GT3_noise=\" + str(noise_pct)+\"_seed=\" + str(seed) + \".csv\"\n",
    "\n",
    "        params_opitim_NN_2 = pd.read_csv(params_opitim_path_NN_2,encoding=\"utf-8\")\n",
    "        params_opitim_NN_3 = pd.read_csv(params_opitim_path_NN_3,encoding=\"utf-8\")\n",
    "\n",
    "        pd_idx = 0\n",
    "        metric_pd = pd.DataFrame()\n",
    "        for i in test_idx:\n",
    "                # Get target data\n",
    "                target_path_i_path = os.path.join(target_path, target_all_path[i])\n",
    "                target_df = pd.read_csv(target_path_i_path,encoding=\"utf-8\")\n",
    "                target = list(target_df.iloc[:,0])\n",
    "\n",
    "                if target_df.shape[0] >= THRESHOLD:\n",
    "                        pass\n",
    "                else:   # 不计算少于THRESHOLD的auction\n",
    "                        continue\n",
    "\n",
    "                # Get the auction setting of i_th according to the test_idx\n",
    "                settings_df = data_key.iloc[i,:]\n",
    "\n",
    "                alpha_2 = params_opitim_NN_2.loc[i,'alpha'].item()\n",
    "                labda_2 = params_opitim_NN_2.loc[i,'labda'].item()\n",
    "                alpha_3 = params_opitim_NN_3.loc[i,'alpha'].item()\n",
    "\n",
    "                # Compute the NLL value of each GT models\n",
    "                # metric_pd.loc[pd_idx,col_names[0]] = GT_1(settings_df,target)\n",
    "                metric_pd.loc[pd_idx,col_names[0]] = GT_2_uniq(settings_df,target,alpha_2,labda_2,q=q)\n",
    "                metric_pd.loc[pd_idx,col_names[1]] = GT_3_uniq(settings_df,target,alpha_3,q=q)\n",
    "\n",
    "                pd_idx += 1\n",
    "\n",
    "        # GT_metric_pd_NLL.loc[seed,col_names[0]] = np.mean(metric_pd.loc[:,col_names[0]])\n",
    "        GT_metric_pd_NLL.loc[seed,col_names[0]] = np.mean(metric_pd.loc[:,col_names[0]])\n",
    "        GT_metric_pd_NLL.loc[seed,col_names[1]] = np.mean(metric_pd.loc[:,col_names[1]])\n",
    "\n",
    "\n",
    "GT_metric_pd_NLL.reset_index(inplace=True)\n",
    "print(GT_metric_pd_NLL)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "GT_metric_pd_NLL"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "output_file = output_path+prefix +\"InferNet_metric_NLL.csv\"\n",
    "GT_metric_pd_NLL.to_csv(output_file)\n",
    "output_file"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
