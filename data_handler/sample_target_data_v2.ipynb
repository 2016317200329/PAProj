{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#-*- coding : utf-8 -*-\n",
    "# coding: utf-8\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 0. what for\n",
    "1. 用于生成人工数据集: target data\n",
    "2. v2是最终的版本\n",
    "# 1. preparations\n",
    "## 1.1 import and data path"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from GT_model.GT_2.SA_for_PT_funcs_delta_eq1 import *\n",
    "from matplotlib import pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "settings_small_NN_path = r\"../data/small_settings_NN.csv\"\n",
    "settings_large_NN_path = r'E:\\DATA\\large_dta\\large_settings_NN.csv'\n",
    "\n",
    "# Sampled params and k\n",
    "params_and_K_sampled_path = r\"../data/auction_assign.csv\"\n",
    "\n",
    "\n",
    "NOISE = True                    # 是否添加noise\n",
    "noise_pct = 0.05                # 噪音占比:我们希望生成的data总体上最多浮动的百分比noise_pct\n",
    "\n",
    "if NOISE:\n",
    "    target_root_path= \"../data/artificial_targets_v2_\"+\"noise=\"+str(noise_pct)+\"/\"\n",
    "    target_ls_T_root_path= \"../data/artificial_targets_v2_\"+\"noise=\"+str(noise_pct)+\"_ls_T\"+\"/\"\n",
    "else:\n",
    "    target_root_path= \"../data/artificial_targets_v2_noise=0/\"\n",
    "    target_ls_T_root_path= \"../data/artificial_targets_v2_noise=0_ls_T/\"\n",
    "\n",
    "target_file_head = \"target_data_NP_\"\n",
    "target_file_tail= \".csv\"\n",
    "\n",
    "bound_noise_duration = [0]      # no upper bound"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2 read in"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一共需要sample 1276 个不同的settings\n"
     ]
    }
   ],
   "source": [
    "data_key_small = pd.read_csv(settings_small_NN_path, encoding=\"utf-8\")\n",
    "data_key_large = pd.read_csv(settings_large_NN_path, encoding=\"utf-8\")\n",
    "data_key = pd.concat([data_key_small,data_key_large],axis=0,ignore_index=True)\n",
    "len_settings = data_key.shape[0]        # 一共要sample len_settings 这么多settings\n",
    "\n",
    "params_and_K = pd.read_csv(params_and_K_sampled_path, encoding=\"utf-8\")\n",
    "print(f\"一共需要sample {len_settings} 个不同的settings\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. sample"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def draw_hist(data, title ):\n",
    "    # create a histogram trace\n",
    "    trace = go.Histogram(x=data, nbinsx=300,histnorm='probability')\n",
    "    # create a layout\n",
    "    layout = go.Layout(\n",
    "        title= title,\n",
    "        xaxis=dict(title='N'),\n",
    "        yaxis=dict(title='Frequency')\n",
    "    )\n",
    "    # create a figure\n",
    "    fig = go.Figure(data=[trace], layout=layout)\n",
    "    # show the plot\n",
    "    return fig\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1276/1276 [02:35<00:00,  8.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len_settings)):\n",
    "# for i in tqdm(range(6)):\n",
    "# for i in tqdm(range(3,4)):\n",
    "\n",
    "    v = data_key.loc[i,'retail'].item()\n",
    "    b = data_key.loc[i,'bidfee'].item()\n",
    "    d = data_key.loc[i,'bidincrement'].item()\n",
    "\n",
    "    GT_choice = params_and_K.loc[i,'GT_choice'].item()\n",
    "    observations = params_and_K.loc[i,'observations'].item()    # 一共有这么多records\n",
    "\n",
    "    # d==0 suggests a fixed-price auction\n",
    "    if d == 0:\n",
    "        # T = np.inf                                             # duration limitation\n",
    "        T = int(observations)                                    # duration limitation\n",
    "    else:\n",
    "        T = int(np.floor((v-b)/d))                         # duration limitation\n",
    "\n",
    "    if GT_choice==0:\n",
    "        # for GT-1\n",
    "        U_1 = get_U_GT1(T,v,d,b,eps=0.)\n",
    "        P_1 = get_P(U_1,T)\n",
    "        P = P_1/P_1.sum()\n",
    "    else:\n",
    "        # for GT-2\n",
    "        alpha = params_and_K.loc[i,'alpha'].item()\n",
    "        labda = params_and_K.loc[i,'labda'].item()\n",
    "        U_2 = get_U_GT2(T,v,d,b,alpha,labda,eps=0.)\n",
    "        P = get_P(U_2,T)\n",
    "\n",
    "    # 生成N\n",
    "    # 1<= possible_duration <= T\n",
    "    possible_duration = np.arange(1,T+1)        # list of all possible N, 从这里sample out\n",
    "    assert len(P)==len(possible_duration),\"P和N不等长\"\n",
    "    # 根据P抽样observations个records\n",
    "    sampled_N = np.random.choice(possible_duration, size=observations, p=P)\n",
    "\n",
    "    # fig = draw_hist(sampled_N, \"without noise mu=\"+str(np.mean(sampled_N))+\" std=\" +str(np.std(sampled_N)))\n",
    "    # fig.show()\n",
    "\n",
    "    # Add some noises which are set between bound of 'bound_noise_duration'.\n",
    "    # Add Gaussian noise to each of the data point.\n",
    "    mu_tmp = noise_pct*np.mean(sampled_N)\n",
    "    # mu_tmp = 0\n",
    "    std_tmp = noise_pct*np.std(sampled_N)\n",
    "    # sampled_N_noise = np.maximum(np.random.normal(mu_tmp, std_tmp, size=observations),bound_noise_duration[0])\n",
    "    sampled_N_noise = np.random.normal(mu_tmp, std_tmp, size=observations)\n",
    "\n",
    "    sampled_N_noise = sampled_N_noise.astype(int)       # 设为int\n",
    "    sampled_N_wnoise = np.where((sampled_N + sampled_N_noise)>0, sampled_N + sampled_N_noise, sampled_N)\n",
    "    # 只保留加完可以保证整体>0的noise\n",
    "    # sampled_N += sampled_N_noise\n",
    "    # Sort out\n",
    "\n",
    "    # fig = draw_hist(sampled_N_wnoise, \"with noise mu=\"+str(np.mean(sampled_N_wnoise))+\" std=\" +str(np.std(sampled_N_wnoise)))\n",
    "    # fig.show()\n",
    "\n",
    "    # # Save\n",
    "    if NOISE:\n",
    "        sampled_N_wnoise.sort()\n",
    "        N_pd = pd.DataFrame(sampled_N_wnoise,columns=['N'])\n",
    "    else:\n",
    "        sampled_N.sort()\n",
    "        N_pd = pd.DataFrame(sampled_N,columns=['N'])\n",
    "\n",
    "    output_path = target_root_path + target_file_head + str(i).zfill(4) + target_file_tail\n",
    "    N_pd.to_csv(output_path,header=True,index=False,encoding=\"utf-8\")\n",
    "\n",
    "    # 只保留N<=T的target data\n",
    "    N_pd_ls_T = N_pd[N_pd.N<=T]\n",
    "    output_ls_T_path = target_ls_T_root_path + target_file_head + str(i).zfill(4) + target_file_tail\n",
    "    N_pd_ls_T.to_csv(output_ls_T_path, encoding=\"utf-8\", header=True, index=False)\n",
    "\n",
    "print(\"Done\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 只保留N<=T的target data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
