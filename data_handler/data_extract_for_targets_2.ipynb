{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2022/11/19 10:05\n",
    "# @Author  : Wang Yujia\n",
    "# @File    : data_extract_for_targets.ipynb\n",
    "# @Description : 为了target data提取信息，而且提取data_key. 然后重新设置一下粒度。"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Preparations\n",
    "## 1.1 全局设置\n",
    "1. input的data包括那些duration过长的结果\n",
    "2. output一共`data_key.shape[0]`+1个文件"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "data_path = \"../data/datawithnp_2_selected.csv\"\n",
    "prod_embedding_output_path = \"../data/prod_embedding.csv\"\n",
    "\n",
    "# output path\n",
    "# target_output_head= \"../data/targets_5/target_data_NP_\"\n",
    "target_output_head= \"../data/targets_5_DA/target_data_NP_\"\n",
    "target_output_tail= \".csv\"\n",
    "target_data_key_path = \"../data/target_datakey.csv\"\n",
    "\n",
    "features = ['id', 'bidincrement', 'bidfee','retail']\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from visdom import Visdom\n",
    "import csv\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2 data读取与保存data_key"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "(   auction_id  product_id                                      item  \\\n 0       86827    10009602  sony-ericsson-s500i-unlocked-mysterious-   \n 1       87964    10009881            psp-slim-lite-sony-piano-black   \n 2       87965    10009881            psp-slim-lite-sony-piano-black   \n 3       88638    10006115  sony-ericsson-s500i-unlocked-mysterious-   \n 4       88639    10006115  sony-ericsson-s500i-unlocked-mysterious-   \n \n                                             desc  retail  price  finalprice  \\\n 0  Sony Ericsson S500i Unlocked Mysterious Green  499.99  13.35       13.35   \n 1               PSP Slim & Lite Sony Piano Black  169.99  74.70       74.70   \n 2               PSP Slim & Lite Sony Piano Black  169.99  83.10       83.10   \n 3  Sony Ericsson S500i Unlocked Mysterious Green  499.99  19.65       19.65   \n 4  Sony Ericsson S500i Unlocked Mysterious Green  499.99  47.10       47.10   \n \n    bidincrement  bidfee        winner  ...           endtime_str  \\\n 0          0.15    0.75       Racer11  ...  19:52 PDT 09-16-2008   \n 1          0.15    0.75        Cemo23  ...  11:17 PDT 08-28-2008   \n 2          0.15    0.75  Jacobsonnich  ...  22:52 PDT 11-07-2008   \n 3          0.15    0.75        Mokkis  ...  22:02 PDT 08-23-2008   \n 4          0.15    0.75  Superloeffel  ...  14:23 PDT 08-24-2008   \n \n    flg_click_only flg_beginnerauction  flg_fixedprice  flg_endprice  id    N  \\\n 0               0                   0               0             0   0   89   \n 1               0                   0               0             0   1  498   \n 2               0                   1               0             0   1  554   \n 3               0                   0               0             0   0  131   \n 4               0                   0               0             0   0  314   \n \n    cnt_uniq  cnt_n_2         P  \n 0        69        1  0.014493  \n 1        60        1  0.016667  \n 2        60        1  0.016667  \n 3        69        1  0.014493  \n 4        69        1  0.014493  \n \n [5 rows x 22 columns],\n (68324, 22))"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(data_path, encoding=\"utf-8\")\n",
    "data.head(),data.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target data中，一共包括 *1196* 个data keys\n"
     ]
    },
    {
     "data": {
      "text/plain": "(   id  bidincrement  bidfee  retail\n 0   0          0.15    0.75  499.99\n 1   1          0.15    0.75  169.99\n 2   2          0.15    0.75  299.99\n 3   3          0.15    0.75   89.99\n 4   5          0.15    0.75   59.99,\n (1196, 4))"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_key = data[features].copy()\n",
    "data_key.drop_duplicates(inplace=True,ignore_index=True)\n",
    "# make sure int\n",
    "data_key['id'] = data_key['id'].astype(int)\n",
    "data_key.to_csv(target_data_key_path,header=True, encoding=\"utf-8\",index=False)\n",
    "print(f\"target data中，一共包括 *{data_key.shape[0]}* 个data keys\")\n",
    "data_key.head(),data_key.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.3 functions about 'key'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# get key from i in 'data_key'\n",
    "def get_key_from_index(i,flag=\"NotStr\"):\n",
    "    if(flag == \"str\"):\n",
    "        key_i = list(data_key.iloc[i,:])\n",
    "        key_i_str = (str(int(key_i[0])),str(key_i[1]),str(key_i[2]),str(key_i[3]))   # 'product_id'是int类型\n",
    "        return key_i_str\n",
    "    else:\n",
    "        key_i = data_key.iloc[i,:]\n",
    "        return key_i\n",
    "\n",
    "def select_data_fromkey(key_i_str):\n",
    "    \"\"\"\n",
    "        根据key_i_str从data中提取target data\n",
    "\n",
    "    \"\"\"\n",
    "    return data[(data['id'] == key_i_str[0]) & (data['bidincrement'] == key_i_str[1]) & (data['bidfee'] == key_i_str[2]) & (data['retail'] == key_i_str[3])].copy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. 整理与输出\n",
    "\n",
    "1. 整理成一个[key]对应一个“N” vector的格式\n",
    "    - 最后的data中不包括\"cnt_n_2\"这一列，\n",
    "2. 注意一定要按照`data_key`逐行保存csv，这样index可以对应\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "plot_flag = 0\n",
    "if(plot_flag):\n",
    "    env_str = 'N_targets'\n",
    "    viz = Visdom(env=env_str)\n",
    "\n",
    "# col_names = ['id','bidincrement','bidfee','retail','N','P','cnt_n_2']\n",
    "# Col we want to save in target file\n",
    "col_names_3 = ['N','cnt_n_2','P']\n",
    "col_names_2 = ['N', 'P']\n",
    "col_names_4 = ['N','cnt','P']\n",
    "\n",
    "data_key.shape[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.1 整理粒度\n",
    "1. 添加了“整理粒度”的代码，注意必须有'cnt'这个属性才可以进行粒度的整理"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# 复制training data文件夹下的第i个data到新路径\n",
    "def save_i_trainfile(i):\n",
    "    train_path = r\"../data/train\"\n",
    "    train_path_2 = r\"../data/train_2\"\n",
    "\n",
    "    train_all_path = os.listdir(train_path)\n",
    "\n",
    "    train_path_i_path = os.path.join(train_path,train_all_path[i])\n",
    "    train_path_i_path_2 = os.path.join(train_path_2,train_all_path[i])\n",
    "\n",
    "    train_df = pd.read_csv(train_path_i_path,encoding=\"utf-8\")\n",
    "    train_df.to_csv(train_path_i_path_2,header=True,index=False,encoding=\"utf-8\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 粒度为2：对于`data_lenth >= 60`的target data进行改动"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1196/1196 [00:10<00:00, 110.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 粒度为2\n",
    "# data_key.shape[0]\n",
    "for i in tqdm(range(0,data_key.shape[0])):\n",
    "# for i in tqdm(range(0,10)):\n",
    "\n",
    "    # Get i_th data_key\n",
    "    key_i = get_key_from_index(i)\n",
    "    # Get data according to the data_key\n",
    "    data_i = select_data_fromkey(key_i)\n",
    "    # Sort data according to 'N'\n",
    "    data_i.reset_index(drop=True,inplace=True)\n",
    "    data_i.sort_values(by='N',ignore_index=True,inplace=True)\n",
    "    # Only save col we need\n",
    "    data_i_df = data_i[col_names_3]\n",
    "\n",
    "    # 现在数据是无重复版本的，用'cnt_n_2'记录了这个record重复出现的次数\n",
    "    # New added: Rearrange the data according to their length\n",
    "    data_lenth = data_i_df.shape[0]         # Data length\n",
    "    dele_idx = []                           # Idx to be deleted\n",
    "    if(data_lenth >= 0):\n",
    "        j = 0\n",
    "        while (j < data_lenth):\n",
    "            # 如果N值是奇数\n",
    "            if(data_i_df.iloc[j,0]%2 != 0):\n",
    "                # i不是data最后一个（奇数）值并且i+1的N值紧挨着i\n",
    "                if( (j < data_lenth-1) and (data_i_df.iloc[j,0] == (data_i_df.iloc[j+1,0]-1))):\n",
    "                    # prob值和cnt值进行叠加\n",
    "                    data_i_df.iloc[j,1] += data_i_df.iloc[j+1,1]\n",
    "                    data_i_df.iloc[j,2] += data_i_df.iloc[j+1,2]\n",
    "                    # 删除[i+1]\n",
    "                    dele_idx.append(j+1)\n",
    "                    j += 2\n",
    "                # i是data最后一个（奇数）或者[i+1]的值没什么关系\n",
    "                else:\n",
    "                    j += 1\n",
    "            # 如果N值是偶数并且不存在[i-1]和[i]存在N值相邻的关系\n",
    "            else:\n",
    "                # 直接把N值改为奇数\n",
    "                data_i_df.iloc[j,0] -= 1\n",
    "                j += 1\n",
    "\n",
    "    ######### 如果只想保存改动的data，把下面都拿到上面的if里面来\n",
    "    # Save i_th training data file\n",
    "    # save_i_trainfile(i)\n",
    "    # Dele\n",
    "    data_i_df = data_i_df.drop(dele_idx,axis = 0).copy()\n",
    "\n",
    "    # Reconstruct and repeat data according to 'cnt_n_2'\n",
    "    data_i_df = data_i_df.loc[data_i_df.index.repeat(data_i_df['cnt_n_2'])]\n",
    "    data_i_df = data_i_df[col_names_2]\n",
    "\n",
    "    # Get the output path\n",
    "    target_output_path = target_output_head+str(i).zfill(4)+target_output_tail\n",
    "    data_i_df.to_csv(target_output_path,header=True,index=False,encoding=\"utf-8\")\n",
    "\n",
    "# clear_output()\n",
    "print(\"Done\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 粒度为4:\n",
    "- N值只会有3种情况：恰好是4倍且（一定）位于开头；不是4倍且被并入某一个开头；不是4倍且未被并入任何一个已存在的开头（此时需要create一个开头）"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1196/1196 [00:15<00:00, 76.76it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 粒度为4\n",
    "for i in tqdm(range(0,data_key.shape[0])):\n",
    "# for i in tqdm(range(0,10)):\n",
    "\n",
    "    # Get i_th data_key\n",
    "    key_i = get_key_from_index(i)\n",
    "    # Get data according to the data_key\n",
    "    data_i = select_data_fromkey(key_i)\n",
    "    # Sort data according to 'N'\n",
    "    data_i.reset_index(drop=True,inplace=True)\n",
    "    data_i.sort_values(by='N',ignore_index=True,inplace=True)\n",
    "    # Only save col we need\n",
    "    data_i_df = data_i[col_names_3]\n",
    "\n",
    "    # 现在数据是无重复版本的，用'cnt_n_2'记录了这个record重复出现的次数\n",
    "    # New added: Rearrange the data according to their length\n",
    "    data_lenth = data_i_df.shape[0]         # Data length\n",
    "    dele_idx = []                           # Idx to be deleted\n",
    "\n",
    "    if(data_lenth >= 0):\n",
    "        j = 0\n",
    "        while (j < data_lenth):\n",
    "            # N值-1恰好是4倍\n",
    "            if((data_i_df.iloc[j,0]-1)%4 == 0):\n",
    "                k = j+1    # 用k记录位置\n",
    "                # k不是data最后一个值 and [k]在+4的范围内\n",
    "                while((k < data_lenth) and (data_i_df.iloc[j,0]+4 > data_i_df.iloc[k,0])):\n",
    "                    # 更新[j]的prob值和cnt值：叠加\n",
    "                    data_i_df.iloc[j,1] += data_i_df.iloc[k,1]\n",
    "                    data_i_df.iloc[j,2] += data_i_df.iloc[k,2]\n",
    "                    # 删除[k]\n",
    "                    dele_idx.append(k)\n",
    "                    k += 1\n",
    "                # j 从 k（其实是k+1）的位置继续\n",
    "                j = k\n",
    "            # N值不是4倍且未被并入任何一个已存在的开头\n",
    "            else:\n",
    "                # 原地修改（减小）成一个新的区间的开头,\n",
    "                while((data_i_df.iloc[j,0]-1) %4 != 0):\n",
    "                    data_i_df.iloc[j,0] -= 1\n",
    "                # 注意不需要j+1，下一次循环从当前开始，check后面的n需不需要并进来\n",
    "                # j += 1\n",
    "\n",
    "    ######### 如果只想保存改动的data，把下面都拿到上面的if里面来\n",
    "    # Save i_th training data file\n",
    "    # save_i_trainfile(i)\n",
    "    # Dele\n",
    "    data_i_df = data_i_df.drop(dele_idx,axis = 0).copy()\n",
    "\n",
    "    # Reconstruct and repeat data according to 'cnt_n_2'\n",
    "    data_i_df = data_i_df.loc[data_i_df.index.repeat(data_i_df['cnt_n_2'])]\n",
    "    data_i_df = data_i_df[col_names_2]\n",
    "\n",
    "    # Get the output path\n",
    "    target_output_path = target_output_head+str(i).zfill(4)+target_output_tail\n",
    "    data_i_df.to_csv(target_output_path,header=True,index=False,encoding=\"utf-8\")\n",
    "\n",
    "# clear_output()\n",
    "print(\"Done\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1.2 粒度=5\n",
    "- 方法一：仿照4直接改"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1196/1196 [00:17<00:00, 68.23it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 粒度为5\n",
    "for i in tqdm(range(0,data_key.shape[0])):\n",
    "# for i in tqdm(range(0,10)):\n",
    "\n",
    "    # Get i_th data_key\n",
    "    key_i = get_key_from_index(i)\n",
    "    # Get data according to the data_key\n",
    "    data_i = select_data_fromkey(key_i)\n",
    "\n",
    "    # Sort data according to 'N'\n",
    "    data_i.reset_index(drop=True,inplace=True)\n",
    "    data_i.sort_values(by='N',ignore_index=True,inplace=True)\n",
    "    # Only save col we need\n",
    "    data_i_df = data_i[col_names_3]\n",
    "\n",
    "    # 现在数据是无重复版本的，用'cnt_n_2'记录了这个record重复出现的次数\n",
    "    # New added: Rearrange the data according to their length\n",
    "    data_lenth = data_i_df.shape[0]         # Data length\n",
    "    dele_idx = []                           # Idx to be deleted\n",
    "\n",
    "    if(data_lenth >= 0):\n",
    "        j = 0\n",
    "        while (j < data_lenth):\n",
    "            # N值-1恰好是4倍\n",
    "            if((data_i_df.iloc[j,0]-1)%5 == 0):\n",
    "                k = j+1    # 用k记录位置\n",
    "                # k不是data最后一个值 and [k]在+4的范围内\n",
    "                while((k < data_lenth) and (data_i_df.iloc[j,0]+5 > data_i_df.iloc[k,0])):\n",
    "                    # 更新[j]的prob值和cnt值：叠加\n",
    "                    data_i_df.iloc[j,1] += data_i_df.iloc[k,1]\n",
    "                    data_i_df.iloc[j,2] += data_i_df.iloc[k,2]\n",
    "                    # 删除[k]\n",
    "                    dele_idx.append(k)\n",
    "                    k += 1\n",
    "                # j 从 k（其实是k+1）的位置继续\n",
    "                j = k\n",
    "            # N值不是4倍且未被并入任何一个已存在的开头\n",
    "            else:\n",
    "                # 原地修改（减小）成一个新的区间的开头,\n",
    "                while((data_i_df.iloc[j,0]-1) %5 != 0):\n",
    "                    data_i_df.iloc[j,0] -= 1\n",
    "                # 注意不需要j+1，下一次循环从当前开始，check后面的n需不需要并进来\n",
    "                # j += 1\n",
    "\n",
    "    ######### 如果只想保存改动的data，把下面都拿到上面的if里面来\n",
    "    # Save i_th training data file\n",
    "    # save_i_trainfile(i)\n",
    "    # Dele\n",
    "    data_i_df = data_i_df.drop(dele_idx,axis = 0).copy()\n",
    "\n",
    "    # Reconstruct and repeat data according to 'cnt_n_2'\n",
    "    data_i_df = data_i_df.loc[data_i_df.index.repeat(data_i_df['cnt_n_2'])]\n",
    "    data_i_df = data_i_df[col_names_2]\n",
    "\n",
    "    # Get the output path\n",
    "    target_output_path = target_output_head+str(i).zfill(4)+target_output_tail\n",
    "    data_i_df.to_csv(target_output_path,header=True,index=False,encoding=\"utf-8\")\n",
    "\n",
    "# clear_output()\n",
    "print(\"Done\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 方法二：read in DA后的data （with 'cnt'）"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# Read in\n",
    "target_path_DA = r\"../data/targets_DA\"\n",
    "target_all_path = os.listdir(target_path_DA)\n",
    "\n",
    "def get_data_i_path(index):\n",
    "    return os.path.join(target_path_DA,target_all_path[index])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1196/1196 [00:09<00:00, 121.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 粒度为5\n",
    "for i in tqdm(range(len(target_all_path))):\n",
    "# for i in tqdm(range(0,10)):\n",
    "\n",
    "    # Get i_th data path\n",
    "    path_i = get_data_i_path(i)\n",
    "    # Get the data\n",
    "    data_i = pd.read_csv(path_i,encoding=\"utf-8\")\n",
    "    # Sort data according to 'N'\n",
    "    data_i.sort_values(by='N',ignore_index=True,inplace=True)\n",
    "    # Drop duplicates\n",
    "    data_i_df = data_i.drop_duplicates(inplace = False,ignore_index=True)\n",
    "\n",
    "    # 现在数据是无重复版本的，'cnt'记录了这个record重复出现的次数\n",
    "    # New added: Rearrange the data according to their length\n",
    "    data_lenth = data_i_df.shape[0]         # Data length\n",
    "    dele_idx = []                           # Idx to be deleted\n",
    "\n",
    "    if(data_lenth >= 0):\n",
    "        j = 0\n",
    "        while (j < data_lenth):\n",
    "            # N值-1恰好是5倍\n",
    "            if((data_i_df.iloc[j,0]-1)%5 == 0):\n",
    "                k = j+1    # 用k记录位置\n",
    "                # k不是data最后一个值 and [k]在+5的范围内\n",
    "                while((k < data_lenth) and (data_i_df.iloc[j,0]+5 > data_i_df.iloc[k,0])):\n",
    "                    # 更新[j]的prob值和cnt值：叠加\n",
    "                    data_i_df.iloc[j,1] += data_i_df.iloc[k,1]\n",
    "                    data_i_df.iloc[j,2] += data_i_df.iloc[k,2]\n",
    "                    # 删除[k]\n",
    "                    dele_idx.append(k)\n",
    "                    k += 1\n",
    "                # j 从 k（其实是k+1）的位置继续\n",
    "                j = k\n",
    "            # N值不是5倍且未被并入任何一个已存在的开头\n",
    "            else:\n",
    "                # 原地修改（减小）成一个新的区间的开头,\n",
    "                while((data_i_df.iloc[j,0]-1) %5 != 0):\n",
    "                    data_i_df.iloc[j,0] -= 1\n",
    "                # 注意不需要j+1，下一次循环从当前开始，check后面的n需不需要并进来\n",
    "                # j += 1\n",
    "\n",
    "    ######### 如果只想保存改动的data，把下面都拿到上面的if里面来\n",
    "    # Save i_th training data file\n",
    "    # save_i_trainfile(i)\n",
    "    # Dele\n",
    "    data_i_df = data_i_df.drop(dele_idx,axis = 0).copy()\n",
    "\n",
    "    # Reconstruct and repeat data according to 'cnt_n_2'\n",
    "    data_i_df = data_i_df.loc[data_i_df.index.repeat(data_i_df['cnt'])]\n",
    "    data_i_df = data_i_df[col_names_2]\n",
    "\n",
    "    # Get the output path\n",
    "    target_output_path = target_output_head+str(i).zfill(4)+target_output_tail\n",
    "    data_i_df.to_csv(target_output_path,header=True,index=False,encoding=\"utf-8\")\n",
    "\n",
    "# clear_output()\n",
    "print(\"Done\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2 写成cdf\n",
    "1. 先读入某个targets data，然后写成cdf"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1196/1196 [00:06<00:00, 197.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Read in\n",
    "target_path = r\"../data/targets_5\"\n",
    "target_all_path = os.listdir(target_path)\n",
    "len_target = len(target_all_path)\n",
    "# Output path\n",
    "target_output_head= \"../data/targets_5_cdf/target_data_NP_\"\n",
    "\n",
    "for i in tqdm(range(0,len_target)):\n",
    "        target_path_i_path = os.path.join(target_path,target_all_path[i])\n",
    "        target_df = pd.read_csv(target_path_i_path,encoding=\"utf-8\")\n",
    "\n",
    "        # Drop the duplicate\n",
    "        target_df.drop_duplicates(inplace=True)\n",
    "        # Add and transform P into cdf value\n",
    "        for j in range(1,target_df.shape[0]):\n",
    "            target_df.iloc[j,1] += target_df.iloc[j-1,1]\n",
    "\n",
    "        # Get the output path\n",
    "        target_output_path = target_output_head+str(i).zfill(4)+target_output_tail\n",
    "        target_df.to_csv(target_output_path,header=True,index=False,encoding=\"utf-8\")\n",
    "print(\"Done\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# 3 save\n",
    "1. 保存结果以及viz环境"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "[0, 2, 4, 6, 8]"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(0,10,2))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 保存整个环境\n",
    "if(plot_flag):\n",
    "    viz.save(envs=[env_str])"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
