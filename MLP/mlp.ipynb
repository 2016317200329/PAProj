{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2022/6/7 15:17\n",
    "# @Author  : Wang Yujia\n",
    "# @File    : mlp.ipynb\n",
    "# @Description : 搭一个基本的mlp，用于测试思路\n",
    "# @TODO: 画图细化一下training的流程：怎么用target data/ NN的规模/ batch size等\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 0. what for\n",
    "1. 搭一个基本的mlp"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Preparations\n",
    "## 1.1 global settings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-29-ca6b61ced272>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[1;31m# import\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 18\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mBasicInfo\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcommon_settings\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[1;33m*\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     19\u001B[0m \u001B[1;31m# from torchsummary import summary\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mutils\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mDataLoader\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Desktop\\PROJ\\PAProj\\BasicInfo\\common_settings.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mos\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mpandas\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 10\u001B[1;33m \u001B[1;32mimport\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     11\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     12\u001B[0m \u001B[1;31m# print输出在:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# nums of Gaussian kernels\n",
    "N_gaussians = 3\n",
    "\n",
    "# dataset划分\n",
    "batch_size = 1\n",
    "train_percentage = 0.8\n",
    "vali_percentage = 0.2\n",
    "\n",
    "# train and optim.\n",
    "learning_rate = 0.01\n",
    "total_train_step = 0\n",
    "total_test_step = 0\n",
    "epoch = 5\n",
    "\n",
    "# import\n",
    "from BasicInfo.common_settings import *\n",
    "# from torchsummary import summary\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import torch.utils.data\n",
    "from mydataset import *\n",
    "# from tensorboardX import SummaryWriter"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2 the data path\n",
    "1. 注意target data和PT的data一样：drop掉duration>T的samples"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "# input data\n",
    "GT_1_data_path = \"../data/info_asymm/results/asc_symmetry/GT_asc_symmetry_P2_K=300.csv\"\n",
    "GT_2_data_path = \"../data/SA_PT/results/PT_oneforall_P_K=300.csv\"\n",
    "\n",
    "# target data\n",
    "target_data_path = \"../data/targets/target_data_NP.csv\"\n",
    "target_output_head= \"../data/targets/target_data_NP_\"\n",
    "target_output_tail= \".csv\"\n",
    "\n",
    "# data keys (for target)\n",
    "data_key_path = \"../data/targets/target_datakey.csv\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Dataset read and split\n",
    "1. 80%是training data？\n",
    "2. 划分是按照target_data的data_key来划分的\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "(2, 303)"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1 = pd.read_csv(GT_1_data_path)\n",
    "data_i = data_1[(data_1['bidincrement'] == 0.15) & (data_1['bidfee'] == 0.75) &(data_1['retail'] == 169.99)]\n",
    "data_i.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "   product_id  bidincrement  bidfee  retail\n0    10009881          0.15    0.75  169.99\n1    10006115          0.15    0.75  499.99\n2    10007148          0.15    0.75  299.99\n3    10007263          0.15    0.75   89.99\n4    10010575          0.15    0.75   59.99",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>product_id</th>\n      <th>bidincrement</th>\n      <th>bidfee</th>\n      <th>retail</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10009881</td>\n      <td>0.15</td>\n      <td>0.75</td>\n      <td>169.99</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10006115</td>\n      <td>0.15</td>\n      <td>0.75</td>\n      <td>499.99</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10007148</td>\n      <td>0.15</td>\n      <td>0.75</td>\n      <td>299.99</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10007263</td>\n      <td>0.15</td>\n      <td>0.75</td>\n      <td>89.99</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10010575</td>\n      <td>0.15</td>\n      <td>0.75</td>\n      <td>59.99</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GT_1_data = mydataset([GT_1_data_path,GT_2_data_path],target_data_path,data_key_path)\n",
    "data_key = pd.read_csv(data_key_path)\n",
    "data_key.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.1 Dataloader"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "data = myDataset([GT_1_data_path, GT_2_data_path, target_output_head, data_key_path])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "train_size = int(train_percentage * data.__len__())\n",
    "vali_size = data.__len__() - train_size\n",
    "train_data, vali_data= torch.utils.data.random_split(data, [train_size, vali_size])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Desktop\\PROJ\\PAProj\\MLP\\mydataset.py:120: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # select target data with the key\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot change data-type for object array.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_17336\\630742423.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__getitem__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mD:\\Desktop\\PROJ\\PAProj\\MLP\\mydataset.py\u001B[0m in \u001B[0;36m__getitem__\u001B[1;34m(self, index)\u001B[0m\n\u001B[0;32m    135\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    136\u001B[0m         \u001B[1;31m# transform P into array vector\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 137\u001B[1;33m         \u001B[0mp_1_i\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtransform_P\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_data_i_1_df\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mloc\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'P'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    138\u001B[0m         \u001B[0mp_2_i\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtransform_P\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_data_i_2_df\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mloc\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'P'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    139\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Desktop\\PROJ\\PAProj\\MLP\\mydataset.py\u001B[0m in \u001B[0;36mtransform_P\u001B[1;34m(self, str_p)\u001B[0m\n\u001B[0;32m     99\u001B[0m         \"\"\"\n\u001B[0;32m    100\u001B[0m         \u001B[0ma\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstr_p\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 101\u001B[1;33m         \u001B[0ma\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtype\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfloat64\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    102\u001B[0m         \u001B[0ma_vec\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0ma\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mflatten\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    103\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0ma_vec\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda\\Lib\\site-packages\\numpy\\core\\_internal.py\u001B[0m in \u001B[0;36m_view_is_safe\u001B[1;34m(oldtype, newtype)\u001B[0m\n\u001B[0;32m    492\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    493\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mnewtype\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhasobject\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0moldtype\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhasobject\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 494\u001B[1;33m         \u001B[1;32mraise\u001B[0m \u001B[0mTypeError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Cannot change data-type for object array.\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    495\u001B[0m     \u001B[1;32mreturn\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    496\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: Cannot change data-type for object array."
     ]
    }
   ],
   "source": [
    "data.__getitem__(0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 1.2 加载dataloader\n",
    "train_iter = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=0, drop_last=False)\n",
    "vali_iter = DataLoader(vali_data, batch_size=batch_size, shuffle=True, num_workers=0, drop_last=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# data keys (for target)\n",
    "import pandas as pd\n",
    "data_key_path = \"../data/targets/target_datakey.csv\"\n",
    "data_key_all = pd.read_csv(data_key_path)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "data_key_all = data_key_all.copy()\n",
    "data_key_all.loc[:,'product_id'] = data_key_all['product_id'].values.astype(\"int64\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10009881\n",
      "<class 'numpy.float64'>\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "data_key_i = data_key_all.iloc[0,:]\n",
    "data_key_i = data_key_i.copy()\n",
    "data_key_i[0] = data_key_i[0].astype(\"int64\")\n",
    "print(int(data_key_i[0]))\n",
    "print(type(data_key_i[0]))\n",
    "print(data_key_i[0] == 10009881)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
