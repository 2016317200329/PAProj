{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2022/6/7 15:17\n",
    "# @Author  : Wang Yujia\n",
    "# @File    : mlp.ipynb\n",
    "# @Description : 搭一个基本的mlp，用于测试思路\n",
    "# @TODO: 画图细化一下training的流程：怎么用target data/ NN的规模/ batch size等\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 0. what for\n",
    "1. 搭一个基本的mlp"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Preparations\n",
    "## 1.1 global settings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "\n",
    "# nums of Gaussian kernels\n",
    "N_gaussians = 3\n",
    "\n",
    "# dataset划分\n",
    "batch_size = 5\n",
    "train_pct = 0.7\n",
    "vali_pct = 0.2\n",
    "test_pct = 0.1\n",
    "\n",
    "# train and optim.\n",
    "learning_rate = 0.01\n",
    "total_train_step = 0\n",
    "total_test_step = 0\n",
    "epoch = 5\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.utils.data\n",
    "from mydataset import *\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "# from tensorboardX import SummaryWriter"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2 the data path\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# training data\n",
    "train_path = r\"../data/train\"\n",
    "# target data\n",
    "target_path = r\"../data/targets\"\n",
    "# data keys\n",
    "data_key_path = \"../data/target_datakey.csv\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Dataloader and Split\n",
    "1. DataLoader中的shuffer=True表示在每一次epoch中都打乱所有数据的顺序，然后以batch为单位从头到尾按顺序取用数据。这样的结果就是不同epoch中的数据都是乱序的,设置随机种子的作用就是让你的每一次训练都乱的一样，\n",
    "\n",
    "## 2.1 Dataset and split it\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 设置随机数种子"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    # torch.backends.cudnn.deterministic = True\n",
    "\n",
    "setup_seed(7)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 读取data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "dataset = myDataset(train_path, target_path, data_key_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 产生index的乱序排列"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "shuffled_indices = np.random.permutation(dataset.__len__())\n",
    "\n",
    "train_idx = shuffled_indices[:int(train_pct*dataset.__len__())]\n",
    "\n",
    "tmp = int((train_pct+vali_pct)*dataset.__len__())\n",
    "val_idx = shuffled_indices[int(train_pct*dataset.__len__()):tmp]\n",
    "\n",
    "test_idx = shuffled_indices[tmp:]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 根据这个乱序排列抽取dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2 Dataloader and collate it\n",
    "1. 主要是对label数据进行collate\n",
    "    - 按照batch中的最大target data长度进行padding，padding with 0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "def my_collate_fn(data):\n",
    "# 这里的data是一个list， list的元素是元组: (self.data, self.label)\n",
    "# collate_fn的作用是把[(data, label),(data, label)...]转化成([data, data...],[label,label...])\n",
    "# 假设self.data的一个data的shape为(channels, length), 每一个channel的length相等,\n",
    "# data[索引到index(batch)][索引到data或者label][索引到channel]\n",
    "\n",
    "    data.sort(key=lambda x: len(x[1]), reverse=False)   # 按照targets数据长度升序排序\n",
    "    max_len = len(data[-1][1])                         # 选取最长的targets数据长度\n",
    "    print(max_len) # 157\n",
    "\n",
    "    data_list = []\n",
    "    target_list = []\n",
    "\n",
    "    # padding with 0\n",
    "    for batch in range(0, len(data)):\n",
    "        data_list.append(data[batch][0])                # 原样保存training data\n",
    "        target_list.append(torch.concat(\n",
    "            [data[batch][1],torch.tensor([[0,0]]* (max_len - len(data[batch][1])))],\n",
    "            dim = 0 ))     #\n",
    "\n",
    "    # into tensor\n",
    "    data_tensor = torch.tensor([item.cpu().detach().numpy() for item in data_list]).cuda()\n",
    "    target_tensor = torch.tensor([item.cpu().detach().numpy() for item in target_list]).cuda()\n",
    "\n",
    "    data_copy = (data_tensor, target_tensor)\n",
    "    return data_copy\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset = dataset,batch_size = batch_size, shuffle=False, num_workers=0, drop_last=False, sampler=SubsetRandomSampler(train_idx), collate_fn = my_collate_fn)\n",
    "val_loader = DataLoader(dataset = dataset,batch_size = batch_size, shuffle=False, num_workers=0, drop_last=False, sampler=SubsetRandomSampler(val_idx),collate_fn = my_collate_fn)\n",
    "\n",
    "test_loader = DataLoader(dataset = dataset,batch_size = batch_size, shuffle=False, num_workers=0, drop_last=False, sampler=SubsetRandomSampler(test_idx),collate_fn = my_collate_fn)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. The Net"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Mlp(nn.Module):\n",
    "    # code->generate->override methods\n",
    "    def __init__(self, n_gaussians) -> None:\n",
    "        super().__init__()\n",
    "        self.mlp_call = nn.Sequential(\n",
    "            # 因为input只有5个features\n",
    "            # nn.Flatten(start_dim=0),\n",
    "            nn.Linear(5, 25),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(25, 225),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(225, 9),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        # π μ σ for MDN\n",
    "        self.z_pi = nn.Sequential(\n",
    "            nn.Linear(9, n_gaussians),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "        self.z_mu = nn.Linear(9, n_gaussians)\n",
    "        self.z_sigma = nn.Linear(9, n_gaussians)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.squeeze(x)\n",
    "        mlp_output = self.mlp_call(x)\n",
    "        # 输出n_gaussians个高斯的参数\n",
    "        tmp = self.z_pi(mlp_output)\n",
    "        pi = torch.mean(tmp,dim=0)\n",
    "        tmp = self.z_mu(mlp_output)\n",
    "        mu = torch.mean(tmp,dim=0)\n",
    "        tmp = torch.exp(self.z_sigma(mlp_output))\n",
    "        # sigma has to be positive, 如果tmp有任何<0的元素，Assert\n",
    "        torch._assert((torch.nonzero(tmp<0, as_tuple=False).shape[0]<=0),\"Sigma is less than zero!\")\n",
    "        sigma = torch.mean(tmp,dim=0)\n",
    "        del(tmp)\n",
    "        return pi, mu, sigma"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
