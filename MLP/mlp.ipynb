{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2022/6/7 15:17\n",
    "# @Author  : Wang Yujia\n",
    "# @File    : mlp.ipynb\n",
    "# @Description : 把mlp的写法变成非sequential版的\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 0. what for\n",
    "1. 搭一个基本的mlp"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Preparations\n",
    "## 1.1 global settings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "\n",
    "# nums of Gaussian kernels\n",
    "N_gaussians = 3\n",
    "\n",
    "# dataset划分\n",
    "batch_size = 50\n",
    "train_pct = 0.7\n",
    "vali_pct = 0.2\n",
    "test_pct = 0.1\n",
    "\n",
    "# train and optim.\n",
    "learning_rate = 0.0001\n",
    "total_train_step = 0\n",
    "total_test_step = 0\n",
    "EPOCH_NUM = 5\n",
    "MIN_LOSS = 1e-7\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import random\n",
    "import torch.utils.data\n",
    "from mydataset import *\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "from tensorboardX import SummaryWriter\n",
    "from visdom import Visdom\n",
    "from torchviz import make_dot\n",
    "import math\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2 the data path\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "# training data\n",
    "train_path = r\"../data/train\"\n",
    "# target data\n",
    "target_path = r\"../data/targets\"\n",
    "# data keys\n",
    "data_key_path = \"../data/target_datakey.csv\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Dataset and Dataloader\n",
    "1. DataLoader中的shuffer=True表示在每一次epoch中都打乱所有数据的顺序，然后以batch为单位从头到尾按顺序取用数据。这样的结果就是不同epoch中的数据都是乱序的,设置随机种子的作用就是让你的每一次训练都乱的一样，\n",
    "\n",
    "## 2.1 Dataset and spliting\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 设置随机数种子"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    # torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    # torch.backends.cudnn.deterministic = True\n",
    "\n",
    "setup_seed(7)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 读取data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "dataset = myDataset(train_path, target_path, data_key_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 产生index的乱序排列"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 807  305  455  939  508  594  835 1082  598 1102   46  761  841  141\n",
      "  407  334  253  500  734  936  698  446  907 1087 1009  140  463  547\n",
      " 1155  856   34 1156  703 1121  751  587 1100  509  473  128  788   97\n",
      "  471  385 1085  525  679 1135  284 1146  186  318 1088 1113    9  457\n",
      " 1047  451  569 1120 1074  326  377  809  109   98  620 1194  825  828\n",
      "   83  113  556  674  568  853  351  558   54  656  804 1149  101  344\n",
      "  851  544  955   40 1021  489  626  664  657  868 1169  151  179 1130\n",
      "  564  713  743 1014  966  861 1132  146  610  408  662  551  172 1020\n",
      "  982 1148  431  517  270  858  170  374  816  618  205   17   53 1003\n",
      "  263  857  716  843  498  228  339  725  752  278  649 1017  108  642\n",
      " 1195 1174   99  530  632  888  189  961  358 1078  663  757 1051  204\n",
      "  409  283  562   23  619  216  474  921  950 1162  123  785  769  621\n",
      "  262  586 1178  541  795   70 1189  396  171  845  168 1125  361  224\n",
      "  125  706  164  231  264   42  746  872  998  132 1035  430   38  522\n",
      "  880  325  285  367  870  418   13  166  513  901  617  740  680 1126\n",
      "   20  372   71 1038  355   60  220  110    4 1115  572  415  336  316\n",
      "  449  412 1066  768 1055  704  869   94   95 1163 1145  648  884  885\n",
      " 1170  848   58  207  306 1067  729   24  644  633  252  832  244   25\n",
      " 1094   63  222 1070  996 1063  130  153 1180  922  399  997   75  894\n",
      " 1048  308  280  934  721  199  820  134  289  259 1159    3  510  492\n",
      "  196  565  563   26  913  483 1141  653   61  623  984  652  609  739\n",
      "  824 1018  891  467  842    8  503  714 1015  447  783  992   74 1184\n",
      "   57  978  484  297 1039  217  681 1027  960  350 1129 1045 1183  906\n",
      "  813  660  266    6  379  526  611  138  163  701 1031 1050   43  733\n",
      "  720  319 1158 1153  877  294  432  531  578  523   19  426  830  927\n",
      "  781 1033 1013  420  137  488  185  920  702 1134 1124  454  327  317\n",
      "  799  655  878  699  981  806  953  750  148  591  915  731  937  365\n",
      "  557  397 1173  779 1185  459  232  389 1147 1011  158  315  256  863\n",
      "   96 1157  445  384  511  817  328  314  357  347  452  298  899  887\n",
      " 1034  839  778  747  249  766   15  159  696  585  360   48  478  330\n",
      "  893  112  338  307  528  422 1142  971  506  504 1049  791  395  669\n",
      "  540  127 1160  902  507  980  237  167  602  983   80  414  640  300\n",
      "  977  324 1117  215 1058   30  242  697  860  951  209  671  742 1072\n",
      "  435   27 1060  518  122 1086  462 1028 1118  603  929  732  722  493\n",
      "  202  403 1089 1179  362  271  466  641 1061  744  272  277 1177   12\n",
      "  597  668  210  651  952  147  442  299  115  375  635  767  748 1080\n",
      "  755  177  472  685   51  810 1079  571  388   22  650  965  423  938\n",
      " 1112  643 1193  142   50  666 1143   81  482  321  948  687 1138   66\n",
      "  909  534  738  417 1005   64  895  886  918  491  700  790   65  968\n",
      "  627  999  296  419  438  261  837  281  631  677  188  881  251  694\n",
      "  514  590  487  273  943 1073  448  411 1131  933 1191  935  149  218\n",
      "  239  718  192  191  945  754  665  705  595  926  708  582 1046  323\n",
      " 1026 1071  658  437  770  833  341    2  229 1098 1152   76 1103  371\n",
      "  180  889  577  736  758 1019 1105 1010  589 1167  812  956  882   37\n",
      "  353 1095  236  928  499  553   55  302  286  800  219  789  387  737\n",
      "  390  352  193  235 1110  480  567  116 1057  957 1106  890  777  120\n",
      "  815  990  773   62  667  453  515  570  223  613  221  673  794  465\n",
      "   52 1093  485 1140 1053  155  912  600 1023  248  441  975 1164  542\n",
      "  117  724  628  712  916  291 1041  381  954  200  596  976 1137 1187\n",
      "  691  505  348 1190  340  615  154 1104  879  995  287  322  819  818\n",
      "  796   82  793  464  797  756 1168  771  333   10  470   32  782  413\n",
      "  580  382  930  760 1133  840 1139  378   89  792  601  213  332  133\n",
      "  346  855    7  941  320 1044  187  972  552  304   31  831  684 1065\n",
      "  240  993  174  245   56  630  583 1025  145   90 1114  392  682  310\n",
      "  359   93  947 1024  376  243 1076   87  214  444  173  425 1040  118\n",
      "  119 1151  905    0  394  401  404  836 1091  162  114  670  150  798\n",
      "  875 1064  368  543  477 1128  532  625  967  512  801   72  258  624\n",
      "  234  135  616  516  866  802  592 1056  501  538  897  728  581  343\n",
      "  925 1002  293  364  883  659   14  686   86  370  165  131  335   59\n",
      "  709  676  354  959  424  292   41  329  614  429   79]\n"
     ]
    }
   ],
   "source": [
    "shuffled_indices = np.random.permutation(dataset.__len__())\n",
    "# shuffled_indices = np.arange(0,dataset.__len__())\n",
    "train_idx = shuffled_indices[:int(train_pct*dataset.__len__())]\n",
    "# train_idx = shuffled_indices\n",
    "tmp = int((train_pct+vali_pct)*dataset.__len__())\n",
    "val_idx = shuffled_indices[int(train_pct*dataset.__len__()):tmp]\n",
    "\n",
    "test_idx = shuffled_indices[tmp:]\n",
    "print(train_idx)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 根据这个乱序排列抽取dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2 Dataloader and collating\n",
    "1. 主要是对label数据进行collate\n",
    "    - 按照batch中的最大target data长度进行padding，padding with 0\n",
    "2. 返回的结果多一个batch dim,比如下面的`5`\n",
    "    - After collating:\n",
    "        - `torch.Size([5, 3, 300]),torch.Size([5, 87, 2])`\n",
    "        - `87`是最长的targets data长度"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "def my_collate_fn(data):\n",
    "# 这里的data是一个list， list的元素是元组: (self.data, self.label)\n",
    "# collate_fn的作用是把[(data, label),(data, label)...]转化成([data, data...],[label,label...])\n",
    "# 假设self.data的一个data的shape为(channels, length), 每一个channel的length相等,\n",
    "# data[索引到index(batch)][索引到data或者label][索引到channel]\n",
    "\n",
    "    data.sort(key=lambda x: len(x[1]), reverse=False)   # 按照targets数据长度升序排序\n",
    "    max_len = len(data[-1][1])                          # 选取最长的targets数据长度\n",
    "\n",
    "    data_list = []\n",
    "    target_list = []\n",
    "\n",
    "    # target_data_record_num = 0\n",
    "    padding_cnt = 0   # 数一下padding了多少\n",
    "\n",
    "    # padding with 0 for those target data small in amount\n",
    "    batch = 0\n",
    "    while data[batch][1].shape[0] < max_len:\n",
    "        padding_cnt += max_len - data[batch][1].shape[0]\n",
    "        tmp = np.array([[0,0]]* (max_len - data[batch][1].shape[0]))\n",
    "        data_list.append(data[batch][0])                # 原样保存training data\n",
    "        # print(f\"compare {data[batch][1].shape} with {tmp.shape}\")\n",
    "        target_list.append(np.concatenate([data[batch][1], tmp], axis=0 ))\n",
    "        batch += 1\n",
    "\n",
    "    while batch < len(data):                           # 避免出现2个max长度的data\n",
    "        data_list.append(data[-1][0])\n",
    "        target_list.append(data[-1][1])\n",
    "        batch += 1\n",
    "\n",
    "    data_tensor = torch.from_numpy(np.stack(data_list)).float()\n",
    "    target_tensor = torch.from_numpy(np.stack(target_list)).float()\n",
    "\n",
    "    # print(\"[PADDING in collating]：一共padding的0个个数：\",padding_cnt)\n",
    "    return (data_tensor, target_tensor)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset = dataset,batch_size = batch_size, shuffle=False, num_workers=0, drop_last=False, sampler=SubsetRandomSampler(train_idx), collate_fn = my_collate_fn)\n",
    "val_loader = DataLoader(dataset = dataset,batch_size = batch_size, shuffle=False, num_workers=0, drop_last=False, sampler=SubsetRandomSampler(val_idx),collate_fn = my_collate_fn)\n",
    "\n",
    "test_loader = DataLoader(dataset = dataset,batch_size = batch_size, shuffle=False, num_workers=0, drop_last=False, sampler=SubsetRandomSampler(test_idx),collate_fn = my_collate_fn)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. The Net and Init\n",
    "1. BatchNorm1d: The mean and std are calculated per-dimension over the mini-batches\n",
    "2."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "### BatchNorm2d测试\n",
    "def test_BN():\n",
    "    m = nn.BatchNorm2d(3, affine=False)  # affine: With Learnable Parameters or not\n",
    "    print('m:', m)\n",
    "    # The mean and std are calculated per-dimension over the mini-batches\n",
    "    input = torch.tensor([\n",
    "        [[1.,2.,3.,4.],[1.,2.,3.,4.],[-1.,-2.,-3.,-4.]],\n",
    "        [[0.,0.,0.,0.],[0.,0.,0.,0.],[0.,0.,0.,0.]]\n",
    "    ], requires_grad=True)\n",
    "\n",
    "    print('input:', input.shape)\n",
    "    input = input.unsqueeze(dim=2)\n",
    "    print('input:', input.shape)\n",
    "    output = m(input) # 归一化\n",
    "    print('output:', output.shape)\n",
    "    print('output:', output)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[-0.1690,  0.5071,  1.1832,  1.8593]],\n\n        [[-0.8452, -0.8452, -0.8452, -0.8452]]])"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 复现batchNorm2d在input shape为3维的情况\n",
    "input = torch.tensor([[[1.,2.,3.,4.]],[[0.,0.,0.,0.]]])\n",
    "# print(input.shape)\n",
    "# torch.mean(input),torch.var(input,unbiased = False)\n",
    "(input-torch.mean(input))/ torch.sqrt(torch.var(input,unbiased = False))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 设置网络初始权重: 不太work"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "\n",
    "class model_param_init(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        assert isinstance(model, nn.Module), 'model not a class nn.Module'\n",
    "        self.net = model\n",
    "        self.initParam()\n",
    "\n",
    "    def initParam(self):\n",
    "        for param in self.net.parameters():\n",
    "            # nn.init.zeros_(param)\n",
    "            # nn.init.ones_(param)\n",
    "            # nn.init.normal_(param, mean=0, std=1)\n",
    "            # nn.init.uniform_(param, a=0, b=1)\n",
    "            # nn.init.constant_(param, val=1)   # 将所有权重初始化为1\n",
    "            # nn.init.eye_(param)  # 只能将二维的tensor初始化为单位矩阵\n",
    "            # nn.init.xavier_uniform_(param, gain=1)  # Glorot初始化  得到的张量是从-a——a中采用的\n",
    "            # nn.init.xavier_normal_(param, gain=1)   # 得到的张量是从0-std采样的\n",
    "            nn.init.kaiming_normal_(param, a=0, mode='fan_in', nonlinearity='relu') # he初始化方法\n",
    "            # nn.init.kaiming_uniform_(param)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- print网络每层结构"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "class PrintLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        if(DEBUG):\n",
    "            print(\"This layer: \")\n",
    "            print(x)      #print(x.shape)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Sequential结构"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "# Sequential\n",
    "class MLP(nn.Module):\n",
    "    # code->generate->override methods\n",
    "    def __init__(self, n_gaussians) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.mlp_call = nn.Sequential(\n",
    "            nn.BatchNorm2d(num_features=3,affine=False),\n",
    "            nn.Conv2d(in_channels=3, out_channels=3, kernel_size=(1,3), stride=(1,3), padding=0,bias=False),\n",
    "            # PrintLayer(),\n",
    "            nn.Softplus(),\n",
    "\n",
    "            nn.BatchNorm2d(num_features=3,affine=False),\n",
    "            nn.Conv2d(in_channels=3, out_channels=3, kernel_size=(1,2), stride=(1,2), padding=0,bias=False),\n",
    "            #nn.ReLU(inplace=True),\n",
    "            # PrintLayer(),\n",
    "            nn.Softplus(),\n",
    "\n",
    "            nn.BatchNorm2d(num_features=3,affine=False),\n",
    "            nn.Conv2d(in_channels=3, out_channels=3, kernel_size=(1,5), stride=(1,5), padding=0,bias=False),\n",
    "            # nn.ReLU(inplace=True),\n",
    "            # PrintLayer(),\n",
    "            nn.Softplus(),\n",
    "\n",
    "            # nn.BatchNorm2d(num_features=3,affine=False),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(30, 9)\n",
    "        )\n",
    "        # π μ σ for MDN\n",
    "        self.z_pi = nn.Sequential(\n",
    "            nn.Linear(9, n_gaussians),  # 30个params要learn\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        self.z_mu = nn.Linear(9, n_gaussians)\n",
    "        self.z_sigma = nn.Linear(9, n_gaussians)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 加一个height维度\n",
    "        x.unsqueeze_(dim=2)\n",
    "        mlp_output = self.mlp_call(x)\n",
    "        # print(\"mlp_output is :\", mlp_output)\n",
    "        # 输出n_gaussians个高斯的参数\n",
    "\n",
    "        # # print the output of every layer\n",
    "        # x = input\n",
    "        # for i in range(len(list(self.mlp_call))):\n",
    "        #     # 循环读入上一层的输出\n",
    "        #     x = self.mlp_call[i](x)\n",
    "        #     if i == 1:\n",
    "        #         print(f\"In layer {i}, the output is:\\n\",x)\n",
    "        #\n",
    "        tmp = self.z_pi(mlp_output)\n",
    "        pi = torch.mean(tmp,dim=0)\n",
    "        tmp = self.z_mu(mlp_output)\n",
    "        mu = torch.mean(tmp,dim=0)\n",
    "        tmp = torch.exp(self.z_sigma(mlp_output))\n",
    "        # sigma has to be positive\n",
    "        torch._assert((torch.nonzero(tmp<0, as_tuple=False).shape[0]<=0),\"Sigma is less than zero!\")\n",
    "        sigma = torch.mean(tmp,dim=0)\n",
    "        return pi, mu, sigma\n",
    "        # return mlp_output"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 非Sequential结构"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "# Not Sequential\n",
    "class MLP(nn.Module):\n",
    "    # code->generate->override methods\n",
    "    def __init__(self, n_gaussians) -> None:\n",
    "        super().__init__()\n",
    "        self.BN = nn.BatchNorm2d(num_features=3,affine=False)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=(1,3), stride=(1,3), padding=0,bias=False)\n",
    "        # PrintLayer(),\n",
    "        self.ac_func1 = nn.Softplus()\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=(1,2), stride=(1,2), padding=0,bias=False)\n",
    "        #nn.ReLU(inplace=True),\n",
    "        # PrintLayer(),\n",
    "        self.ac_func2 = nn.Softplus()\n",
    "        self.conv3 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=(1,5), stride=(1,5), padding=0,bias=False)\n",
    "        # nn.ReLU(inplace=True),\n",
    "        # PrintLayer(),\n",
    "        self.ac_func3 = nn.Softplus()\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear1 = nn.Linear(30, 9)\n",
    "\n",
    "        self.z_pi = nn.Sequential(\n",
    "            nn.Linear(9, n_gaussians),  # 30个params要learn\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        self.z_mu = nn.Linear(9, n_gaussians)\n",
    "        self.z_sigma = nn.Linear(9, n_gaussians)\n",
    "\n",
    "        self.weight_after_bp = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 加一个height维度\n",
    "        x.unsqueeze_(dim=2)\n",
    "        x = self.BN(x)\n",
    "        # print(\"The conv1's input is : \",x)\n",
    "        # self.weight_after_bp.append(param.clone())\n",
    "        x = self.conv1(x)\n",
    "        # print(\"After the conv1: \",x)\n",
    "        x = self.ac_func1(x)\n",
    "\n",
    "        x = self.BN(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.ac_func2(x)\n",
    "\n",
    "        x = self.BN(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.ac_func3(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear1(x)\n",
    "        # print(\"after linear1, the output shape is: \",x.shape)\n",
    "\n",
    "        # pi = torch.mean(self.z_pi(x))\n",
    "        pi = self.z_pi(x)\n",
    "        print(\"pi's shape: \",pi.shape)\n",
    "        mu = self.z_mu(x)\n",
    "        print(\"mu's shape: \",mu.shape)\n",
    "        sigma = torch.exp(self.z_sigma(x))\n",
    "        print(\"sigma's shape: \",sigma.shape)\n",
    "\n",
    "        # # print the output of every layer\n",
    "        # x = input\n",
    "        # for i in range(len(list(self.mlp_call))):\n",
    "        #     # 循环读入上一层的输出\n",
    "        #     x = self.mlp_call[i](x)\n",
    "        #     if i == 1:\n",
    "        #         print(f\"In layer {i}, the output is:\\n\",x)\n",
    "        #\n",
    "\n",
    "        return pi, mu, sigma\n",
    "        # return mlp_output"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input's shape is torch.Size([2, 3, 1, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": "torch.Size([2, 12])"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.tensor([\n",
    "    [[1.,2.,3.,4.],[1.,2.,3.,4.],[-1.,-2.,-3.,-4.]],\n",
    "    [[0.,0.,0.,0.],[0.,0.,0.,0.],[0.,0.,0.,0.]]\n",
    "], requires_grad=True)\n",
    "input = input.unsqueeze(dim=2)\n",
    "print(f\"input's shape is {input.shape}\")\n",
    "flt = nn.Flatten(start_dim=1)\n",
    "flt(input).shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. The Loss\n",
    "- `loss_preparation`用来做loss的前期data准备：\n",
    "    - 去掉dataloader传输时padding的那些0\n",
    "    - 计算混合模型的分布`m`以及target data中的`duration`\n",
    "- `loss_fn`用来计算\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "class MLELoss(nn.Module):\n",
    "\n",
    "    def __init__(self, pi, mu, sigma):\n",
    "        super().__init__()\n",
    "        self.pi = pi\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "\n",
    "\n",
    "    def forward(self,y_pred,y_true):\n",
    "        bce = torch.nn.BCELoss(reduction = \"none\")(y_pred,y_true)\n",
    "        p_t = (y_true * y_pred) + ((1 - y_true) * (1 - y_pred))\n",
    "\n",
    "        return loss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 构造直接计算prob的函数\n",
    "- 输出50个GMM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "ONEOVERSQRT2PI = 1.0 / math.sqrt(2 * math.pi)\n",
    "\n",
    "def gaussian_probability(mu, sigma, target):\n",
    "    \"\"\"Returns the probability of `target` given MoG parameters `sigma` and `mu`.\n",
    "\n",
    "    Arguments:\n",
    "        sigma (BxGxO): The standard deviation of the Gaussians. B is the batch\n",
    "            size, G is the number of Gaussians, and O is the number of\n",
    "            dimensions per Gaussian.\n",
    "        mu (BxGxO): The means of the Gaussians. B is the batch size, G is the\n",
    "            number of Gaussians, and O is the number of dimensions per Gaussian.\n",
    "        target (BxI): A batch of target. B is the batch size and I is the number of\n",
    "            input dimensions.\n",
    "\n",
    "    Returns:\n",
    "        probabilities (BxG): The probability of each point in the probability\n",
    "            of the distribution in the corresponding sigma/mu index.\n",
    "    \"\"\"\n",
    "    # target_unpadded = torch.repeat_interleave(target.unsqueeze(1), repeats=3, dim=1)\n",
    "    # print(f\"target_unpadded is:{target_unpadded}\")\n",
    "    ret = ONEOVERSQRT2PI * torch.exp(-0.5 * ((target - mu) / sigma)**2) / sigma\n",
    "    # ret = target_unpadded - mu\n",
    "    # prod(): 返回输入张量给定维度dim=2上每行的积。 输出形状与输入相同，除了给定维度上为1\n",
    "    #return torch.prod(ret, 2)\n",
    "    return ret"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [88], line 9\u001B[0m\n\u001B[0;32m      7\u001B[0m     result \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msum(prob,dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;28mprint\u001B[39m(result)\n\u001B[1;32m----> 9\u001B[0m \u001B[43mtest_gaussian_probability\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn [88], line 6\u001B[0m, in \u001B[0;36mtest_gaussian_probability\u001B[1;34m()\u001B[0m\n\u001B[0;32m      4\u001B[0m target \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor([\u001B[38;5;241m0\u001B[39m,\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m1\u001B[39m])\n\u001B[0;32m      5\u001B[0m pi \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor([\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m1\u001B[39m])\n\u001B[1;32m----> 6\u001B[0m prob \u001B[38;5;241m=\u001B[39m pi\u001B[38;5;241m*\u001B[39m\u001B[43mgaussian_probability\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmu\u001B[49m\u001B[43m,\u001B[49m\u001B[43msigma\u001B[49m\u001B[43m,\u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      7\u001B[0m result \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msum(prob,dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28mprint\u001B[39m(result)\n",
      "Cell \u001B[1;32mIn [87], line 21\u001B[0m, in \u001B[0;36mgaussian_probability\u001B[1;34m(mu, sigma, target)\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;124;03m\"\"\"Returns the probability of `target` given MoG parameters `sigma` and `mu`.\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \n\u001B[0;32m      6\u001B[0m \u001B[38;5;124;03mArguments:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;124;03m        of the distribution in the corresponding sigma/mu index.\u001B[39;00m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;66;03m# target_unpadded = torch.repeat_interleave(target.unsqueeze(1), repeats=3, dim=1)\u001B[39;00m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;66;03m# print(f\"target_unpadded is:{target_unpadded}\")\u001B[39;00m\n\u001B[1;32m---> 21\u001B[0m ret \u001B[38;5;241m=\u001B[39m ONEOVERSQRT2PI \u001B[38;5;241m*\u001B[39m torch\u001B[38;5;241m.\u001B[39mexp(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m0.5\u001B[39m \u001B[38;5;241m*\u001B[39m ((\u001B[43mtarget\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mmu\u001B[49m) \u001B[38;5;241m/\u001B[39m sigma)\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m2\u001B[39m) \u001B[38;5;241m/\u001B[39m sigma\n\u001B[0;32m     22\u001B[0m \u001B[38;5;66;03m# ret = target_unpadded - mu\u001B[39;00m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;66;03m# prod(): 返回输入张量给定维度dim=2上每行的积。 输出形状与输入相同，除了给定维度上为1\u001B[39;00m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;66;03m#return torch.prod(ret, 2)\u001B[39;00m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m ret\n",
      "\u001B[1;31mRuntimeError\u001B[0m: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "def test_gaussian_probability():\n",
    "    mu = torch.tensor([0,0])\n",
    "    sigma = torch.tensor([1,1])\n",
    "    target = torch.tensor([0,-1,1])\n",
    "    pi = torch.tensor([1,1])\n",
    "    prob = pi*gaussian_probability(mu,sigma,target)\n",
    "    result = torch.sum(prob,dim=1)\n",
    "    print(result)\n",
    "test_gaussian_probability()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 当input的shape是[50,3]时，输出应该是50个GMM\n",
    "def loss_preparation(pi, mu, sigma, target):\n",
    "\n",
    "    m=[]\n",
    "    for i in range(pi.shape[0]):\n",
    "        m.append(torch.distributions.Normal(loc=mu[i,:].T, scale=sigma[i,:].T))\n",
    "\n",
    "    duration = target[:,:,0].squeeze_()\n",
    "    # # target_drop_padding.cpu().data.numpy()\n",
    "    # # target_drop_padding.to_csv()\n",
    "    # print(\"target_drop_padding shape:\",target_drop_padding.shape)\n",
    "    #\n",
    "    # duration = torch.flatten(target[:,:,0])\n",
    "    # print(\"duration shape:\",duration.shape)\n",
    "    # print(\"[PADDING]: drop 了多少个padded 0：\",duration.shape[0] - target_drop_padding.shape[0])\n",
    "    #\n",
    "    # duration = torch.repeat_interleave(duration.unsqueeze(dim=1), repeats=3, dim=1).to(device)\n",
    "\n",
    "    # # 统计一下target data的利用率\n",
    "    # loss_1 = torch.exp(m.log_prob(duration))\n",
    "    # #print(\"m.log_prob(duration): \",m.log_prob(duration))\n",
    "    # loss_2 = torch.sum(loss_1 * pi, dim=1)\n",
    "    # len_0 = len(loss_2)\n",
    "    # print(\"non zero 占比：\",len(loss_2[torch.nonzero(loss_2)])/len_0)\n",
    "    return duration,m"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 测试gaussian_probability函数"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # 当input的shape是[50,3]时，输出应该是50个GMM\n",
    "# # 对这50个GMM看能生成什么output\n",
    "# # 测试gaussian_probability函数\n",
    "# def loss_fn(Pi,duration,m,Mu,Sigma):\n",
    "#     loss = torch.zeros(1,device=device)\n",
    "#     # padding_cnt = 0\n",
    "#     for i in range(len(m)):\n",
    "#         target = duration[i,:]\n",
    "#         pi = Pi[i,:]\n",
    "#         mu = Mu[i,:]\n",
    "#         sigma = Sigma[i,:]\n",
    "#\n",
    "#         # repeat and copy non-zero target data\n",
    "#         target_unpadded = target[torch.nonzero(target)].squeeze_()\n",
    "#         target_unpadded = torch.repeat_interleave(target_unpadded.unsqueeze(dim=1), repeats=3, dim=1).to(device)\n",
    "#\n",
    "#         print(f\"-{i}:target_unpadded shape: {target_unpadded.shape}\")\n",
    "#         loss_1 = torch.exp(m[i].log_prob(target_unpadded))\n",
    "#         # print(f\"-{i}:loss_1 shape: {loss_1.shape}\")\n",
    "#         # print(f\"-{i}:the pi is : {pi}\")\n",
    "#         print(f\"-{i}:the m[i].log_prob(target_unpadded) is : {m[i].log_prob(target_unpadded)}\")\n",
    "#         print(f\"-{i}:the loss_1 is : {loss_1}\")\n",
    "#         loss_2 = torch.sum(loss_1 * pi, dim=1)\n",
    "#\n",
    "#         prob = pi*gaussian_probability(mu,sigma,target_unpadded)\n",
    "#         # result = torch.sum(prob,dim=1)\n",
    "#         # print(f\"--{i}: the result of GMM by hand: {result}\")\n",
    "#         # print(f\"-{i}:loss_2 shape: {loss_2.shape}\")\n",
    "#         print(f\"-{i}:the loss_2 is : {loss_2}\")\n",
    "#         # print(\"Is there any 0 in loss_2? \", ( len(torch.nonzero(loss_2)) < len(loss_2)))\n",
    "#         loss_3 = loss_2[torch.nonzero(loss_2)].squeeze_()         # 去掉所有的log(0)\n",
    "#         # print(f\"-{i}:loss_3 shape: {loss_3.shape}\")\n",
    "#         # print(f\"-{i}:the loss_3 is :{loss_3}\")\n",
    "#         loss += torch.mean(-torch.log(loss_3))\n",
    "#         print(f\"-{i}:the loss is : {loss}\")\n",
    "#\n",
    "#     return loss.to(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # 当input的shape是[50,3]时，输出应该是50个GMM\n",
    "# # 对这50个GfMM看能生成什么output\n",
    "\n",
    "def loss_fn(Pi,duration,m):\n",
    "    loss = torch.zeros(1,device=device)\n",
    "    # padding_cnt = 0\n",
    "    for i in range(len(m)):\n",
    "        target = duration[i,:]\n",
    "        pi = Pi[i,:]\n",
    "\n",
    "        # repeat and copy target data\n",
    "        target_unpadded = target[torch.nonzero(target)].squeeze_()\n",
    "        # padding_cnt += len(target)-len(target_unpadded)\n",
    "        target_unpadded = torch.repeat_interleave(target_unpadded.unsqueeze(dim=1), repeats=3, dim=1).to(device)\n",
    "\n",
    "        # print(f\"-{i}:target_unpadded shape: {target_unpadded.shape}\")\n",
    "        loss_1 = torch.exp(m[i].log_prob(target_unpadded))\n",
    "\n",
    "        # loss_1 = m[i].log_prob(target_unpadded)            # loss_1这里取消torch.exp的操作直接用pi*log_prob\n",
    "        print(f\"-{i}:loss_1 shape: {loss_1.shape}\")\n",
    "        print(f\"-{i}:the pi is : {pi}\")\n",
    "        print(f\"-{i}:the m[i].log_prob(target_unpadded) is : {m[i].log_prob(target_unpadded)}\")\n",
    "        print(f\"-{i}:the loss_1 is : {loss_1}\")\n",
    "        loss_2 = torch.sum(loss_1 * pi, dim=1)\n",
    "        #print(f\"-{i}:loss_2 shape: {loss_2.shape}\")\n",
    "        print(f\"-{i}:the loss_2 is : {loss_2}\")\n",
    "        # print(\"Is there any 0 in loss_2? \", ( len(torch.nonzero(loss_2)) < len(loss_2)))\n",
    "        loss_3 = loss_2[torch.nonzero(loss_2)].squeeze_()         # 去掉所有的log(0)\n",
    "        #print(f\"-{i}:loss_3 shape: {loss_3.shape}\")\n",
    "        print(f\"-{i}:the loss_3 is :{loss_3}\")\n",
    "        loss += torch.mean(-(loss_3))\n",
    "        print(f\"-{i}:the loss is : {loss}\")\n",
    "\n",
    "    # print(f\"[UNPADDING in loss] There is {padding_cnt} zero unpadded\")\n",
    "    return loss.to(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- test for logsumexp的放缩思想\n",
    "- didn't work here 因为exp会放大差值，这里的“差值”尤其大，不管指数上对x加减什么都无法拉回来"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-228.4900) tensor(-803660.) tensor(-31024.)\n",
      "tensor(803431.5000)\n",
      "input2:  tensor([[-8.4241e+02, -1.9443e+03,  0.0000e+00],\n",
      "        [-1.0261e+03, -2.3189e+03, -3.8380e+01],\n",
      "        [-1.7838e+03, -3.8644e+03, -1.9637e+02],\n",
      "        [-7.7564e+03, -1.6064e+04, -1.4363e+03],\n",
      "        [-9.5326e+03, -1.9694e+04, -1.8043e+03],\n",
      "        [-1.2532e+04, -2.5823e+04, -2.4253e+03],\n",
      "        [-2.9925e+04, -6.1386e+04, -6.0235e+03],\n",
      "        [-3.6321e+04, -7.4466e+04, -7.3458e+03],\n",
      "        [-5.5001e+04, -1.1267e+05, -1.1207e+04],\n",
      "        [-9.1242e+04, -1.8680e+05, -1.8693e+04],\n",
      "        [-1.0302e+05, -2.1089e+05, -2.1125e+04],\n",
      "        [-1.4985e+05, -3.0670e+05, -3.0796e+04],\n",
      "        [-1.7598e+05, -3.6015e+05, -3.6190e+04],\n",
      "        [-1.8924e+05, -3.8729e+05, -3.8928e+04],\n",
      "        [-2.6000e+05, -5.3206e+05, -5.3535e+04],\n",
      "        [-3.9263e+05, -8.0343e+05, -8.0909e+04]])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([inf])"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.tensor([[-1.0709e+03, -2.1728e+03, -2.2849e+02],\n",
    "        [-1.2546e+03, -2.5474e+03, -2.6687e+02],\n",
    "        [-2.0123e+03, -4.0929e+03, -4.2486e+02],\n",
    "        [-7.9849e+03, -1.6292e+04, -1.6648e+03],\n",
    "        [-9.7611e+03, -1.9922e+04, -2.0328e+03],\n",
    "        [-1.2760e+04, -2.6051e+04, -2.6538e+03],\n",
    "        [-3.0153e+04, -6.1614e+04, -6.2520e+03],\n",
    "        [-3.6549e+04, -7.4694e+04, -7.5743e+03],\n",
    "        [-5.5229e+04, -1.1290e+05, -1.1435e+04],\n",
    "        [-9.1470e+04, -1.8703e+05, -1.8921e+04],\n",
    "        [-1.0325e+05, -2.1112e+05, -2.1353e+04],\n",
    "        [-1.5008e+05, -3.0693e+05, -3.1024e+04],\n",
    "        [-1.7621e+05, -3.6038e+05, -3.6418e+04],\n",
    "        [-1.8947e+05, -3.8752e+05, -3.9156e+04],\n",
    "        [-2.6023e+05, -5.3229e+05, -5.3763e+04],\n",
    "        [-3.9286e+05, -8.0366e+05, -8.1137e+04]])\n",
    "c_max = torch.max(input)\n",
    "c_min = torch.min(input)\n",
    "c_mid = torch.median(input)\n",
    "c_test = torch.tensor([90])\n",
    "# c_test = torch.tensor([-100])\n",
    "print(c_max,c_min,c_mid)\n",
    "print(c_max-c_min)\n",
    "input2 = input - c_max\n",
    "print(\"input2: \",input2)\n",
    "\n",
    "# exp本来就会放大差值\n",
    "torch.exp(c_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. Training\n",
    "## 5.1 preparations\n",
    "1. 初始化Visdom环境\n",
    "2.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter(\"logs-MLP\")\n",
    "viz = Visdom(env=\"001\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5.2 Draw\n",
    "1. draw:\n",
    "    - mdn的图（visdom）以及mdn的test draw\n",
    "    - loss图以及初始化（visdom）\n",
    "    - MLP的网络结构（.png）"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "outputs": [],
   "source": [
    "#### Test for drawing\n",
    "def test_draw():\n",
    "    viz = Visdom(env=\"001\")\n",
    "\n",
    "    mu = torch.tensor([0,10,20])\n",
    "    sigma = torch.tensor([1,1,1])\n",
    "    duration = torch.tensor([0,1,2,0])\n",
    "    duration = torch.repeat_interleave(duration.unsqueeze(dim=1), repeats=3, dim=1)\n",
    "    m = torch.distributions.Normal(loc=mu, scale=sigma)\n",
    "    pi = torch.tensor([0.2,0.3,0.5])\n",
    "\n",
    "    # draw\n",
    "    x_0 = torch.tensor(np.arange(0,1000))\n",
    "    x = torch.repeat_interleave(x_0.unsqueeze(dim=1), repeats=3, dim=1)\n",
    "    y = torch.exp(m.log_prob(x))\n",
    "    y_sum = torch.unsqueeze(torch.sum(pi*y,dim=1),dim=1)\n",
    "    viz.line(X = x_0,Y= torch.cat([y,y_sum],dim = 1), env=\"001\", win=\"test_draw_2\",\n",
    "            opts= dict(title='test_draw', legend=['N1', 'N2', 'N3','NNN']))\n",
    "# test_draw()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "outputs": [],
   "source": [
    "def draw_mdn(pi,duration,m,total_train_step):\n",
    "    # draw the distrb.\n",
    "    x_0 = torch.arange(0,torch.max(duration).item()).to(device)\n",
    "    x = torch.repeat_interleave(x_0.unsqueeze(dim=1), repeats=3, dim=1)\n",
    "    y = torch.exp(m.log_prob(x)).to(device)\n",
    "    y_sum = torch.unsqueeze(torch.sum(pi*y,dim=1),dim=1)   # 维度相等才能cat\n",
    "    win_str = \"total_train_step-\"+str(total_train_step)\n",
    "    viz.line(X = x_0,Y= torch.cat([y,y_sum],dim = 1), env=\"001\", win=win_str,\n",
    "        opts= dict(title=win_str, legend=['N1', 'N2', 'N3','NNN']))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "outputs": [],
   "source": [
    "def draw_the_net():\n",
    "\n",
    "    x = torch.randn([5, 3, 300])  # 定义一个网络的输入值\n",
    "    mlp = MLP(N_gaussians)\n",
    "    y = mlp(x)    # 获取网络的预测值\n",
    "\n",
    "    MyConvNetVis = make_dot(y, params=dict(list(mlp.named_parameters()) + [('x', x)]))\n",
    "    MyConvNetVis.format = \"png\"\n",
    "    # 指定文件生成的文件夹\n",
    "    MyConvNetVis.directory = \"data_pic\"\n",
    "    # 生成文件\n",
    "    # MyConvNetVis.view()\n",
    "# draw_the_net()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "outputs": [],
   "source": [
    "viz.line(X = [0.],Y = [0.], env=\"001\", win=\"The Loss\", opts= dict(title=\"The Loss\"))\n",
    "def draw_loss(total_train_step, loss):\n",
    "    viz.line(X = [total_train_step], Y = [loss],win=\"The Loss\", update=\"append\",\n",
    "        opts= dict(title=\"The Loss\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5.3 Training\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pi's shape:  torch.Size([2, 3])\n",
      "mu's shape:  torch.Size([2, 3])\n",
      "sigma's shape:  torch.Size([2, 3])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "       BatchNorm2d-1            [-1, 3, 1, 300]               0\n",
      "            Conv2d-2            [-1, 3, 1, 100]              27\n",
      "          Softplus-3            [-1, 3, 1, 100]               0\n",
      "       BatchNorm2d-4            [-1, 3, 1, 100]               0\n",
      "            Conv2d-5             [-1, 3, 1, 50]              18\n",
      "          Softplus-6             [-1, 3, 1, 50]               0\n",
      "       BatchNorm2d-7             [-1, 3, 1, 50]               0\n",
      "            Conv2d-8             [-1, 3, 1, 10]              45\n",
      "          Softplus-9             [-1, 3, 1, 10]               0\n",
      "          Flatten-10                   [-1, 30]               0\n",
      "           Linear-11                    [-1, 9]             279\n",
      "           Linear-12                    [-1, 3]              30\n",
      "          Softmax-13                    [-1, 3]               0\n",
      "           Linear-14                    [-1, 3]              30\n",
      "           Linear-15                    [-1, 3]              30\n",
      "================================================================\n",
      "Total params: 459\n",
      "Trainable params: 459\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.02\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.02\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mlp = MLP(N_gaussians)\n",
    "# # mlp = model_param_init(mlp)\n",
    "\n",
    "# # save the init params\n",
    "torch.save(mlp.state_dict(), 'mlp_init.pth')\n",
    "\n",
    "# read the saved model\n",
    "# model_data = torch.load('mlp_init_1epoch.pth')\n",
    "# mlp.load_state_dict(model_data)\n",
    "\n",
    "mlp = mlp.to(device=device)\n",
    "summary(mlp, (3,300))\n",
    "# optimizer = torch.optim.SGD(mlp.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.Adagrad(mlp.parameters(),lr=learning_rate, lr_decay=learning_rate, weight_decay=learning_rate)\n",
    "#"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PADDING]：一共padding的0个个数： 27917\n",
      "---- 0 batch----\n",
      "pi's shape:  torch.Size([50, 3])\n",
      "mu's shape:  torch.Size([50, 3])\n",
      "sigma's shape:  torch.Size([50, 3])\n",
      "The [pi,mu,sigma] is : \n",
      "\n",
      "tensor([[0.2820, 0.2052, 0.5129],\n",
      "        [0.2660, 0.2228, 0.5112],\n",
      "        [0.2515, 0.1976, 0.5509],\n",
      "        [0.2458, 0.2040, 0.5502],\n",
      "        [0.2618, 0.2265, 0.5117],\n",
      "        [0.2531, 0.1984, 0.5485],\n",
      "        [0.2698, 0.2099, 0.5202],\n",
      "        [0.2772, 0.2058, 0.5170],\n",
      "        [0.2835, 0.2441, 0.4723],\n",
      "        [0.2671, 0.2227, 0.5102],\n",
      "        [0.2730, 0.2051, 0.5219],\n",
      "        [0.2980, 0.2112, 0.4908],\n",
      "        [0.2826, 0.1965, 0.5209],\n",
      "        [0.2567, 0.1945, 0.5488],\n",
      "        [0.2729, 0.2046, 0.5224],\n",
      "        [0.2970, 0.2168, 0.4862],\n",
      "        [0.2914, 0.2333, 0.4753],\n",
      "        [0.2827, 0.2174, 0.4999],\n",
      "        [0.2612, 0.2104, 0.5284],\n",
      "        [0.3016, 0.1940, 0.5044],\n",
      "        [0.2364, 0.2021, 0.5614],\n",
      "        [0.2920, 0.2309, 0.4771],\n",
      "        [0.2493, 0.2055, 0.5452],\n",
      "        [0.2413, 0.1980, 0.5607],\n",
      "        [0.2670, 0.2064, 0.5266],\n",
      "        [0.2612, 0.2142, 0.5245],\n",
      "        [0.2604, 0.2013, 0.5382],\n",
      "        [0.2662, 0.2083, 0.5255],\n",
      "        [0.2777, 0.2142, 0.5081],\n",
      "        [0.2561, 0.2159, 0.5280],\n",
      "        [0.2642, 0.1946, 0.5412],\n",
      "        [0.2702, 0.2153, 0.5144],\n",
      "        [0.2607, 0.2010, 0.5384],\n",
      "        [0.2953, 0.2073, 0.4974],\n",
      "        [0.2753, 0.2108, 0.5139],\n",
      "        [0.2773, 0.2015, 0.5212],\n",
      "        [0.2679, 0.2188, 0.5133],\n",
      "        [0.2598, 0.2061, 0.5341],\n",
      "        [0.2641, 0.2007, 0.5352],\n",
      "        [0.2516, 0.2071, 0.5413],\n",
      "        [0.2706, 0.1925, 0.5369],\n",
      "        [0.2895, 0.2074, 0.5031],\n",
      "        [0.2978, 0.2094, 0.4928],\n",
      "        [0.2626, 0.1968, 0.5406],\n",
      "        [0.2689, 0.2099, 0.5212],\n",
      "        [0.2544, 0.2087, 0.5368],\n",
      "        [0.2821, 0.1885, 0.5294],\n",
      "        [0.2757, 0.2168, 0.5075],\n",
      "        [0.3011, 0.1944, 0.5045],\n",
      "        [0.2612, 0.2067, 0.5321]], device='cuda:0', grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[ 0.4978,  0.6776, -0.2529],\n",
      "        [ 0.5178,  0.7832,  0.0533],\n",
      "        [ 0.5679,  0.9000, -0.1518],\n",
      "        [ 0.4924,  0.7876, -0.0912],\n",
      "        [ 0.4038,  0.6678, -0.0647],\n",
      "        [ 0.5291,  0.7629, -0.1102],\n",
      "        [ 0.4648,  0.7099, -0.1697],\n",
      "        [ 0.4927,  0.6856, -0.1714],\n",
      "        [ 0.4265,  0.4429, -0.0499],\n",
      "        [ 0.4684,  0.6772, -0.0957],\n",
      "        [ 0.4805,  0.6733, -0.2388],\n",
      "        [ 0.5646,  0.5679, -0.2427],\n",
      "        [ 0.5588,  0.6888, -0.1822],\n",
      "        [ 0.5787,  0.7786, -0.2231],\n",
      "        [ 0.6450,  0.7194, -0.1964],\n",
      "        [ 0.5561,  0.5951, -0.1857],\n",
      "        [ 0.4842,  0.5353, -0.1165],\n",
      "        [ 0.5168,  0.6464, -0.1485],\n",
      "        [ 0.5003,  0.7702, -0.0909],\n",
      "        [ 0.6022,  0.5420, -0.4130],\n",
      "        [ 0.4311,  0.7279, -0.1407],\n",
      "        [ 0.4669,  0.5273, -0.1229],\n",
      "        [ 0.4604,  0.7410, -0.1965],\n",
      "        [ 0.6245,  0.8572, -0.1441],\n",
      "        [ 0.5281,  0.7771, -0.2134],\n",
      "        [ 0.4287,  0.7431, -0.0757],\n",
      "        [ 0.5785,  0.8116, -0.0893],\n",
      "        [ 0.5365,  0.6544, -0.1631],\n",
      "        [ 0.5826,  0.6692, -0.2033],\n",
      "        [ 0.4903,  0.6629, -0.1045],\n",
      "        [ 0.5676,  0.6984, -0.3007],\n",
      "        [ 0.5040,  0.6571, -0.0932],\n",
      "        [ 0.5808,  0.8123, -0.0927],\n",
      "        [ 0.4588,  0.5165, -0.2923],\n",
      "        [ 0.6081,  0.6506, -0.1719],\n",
      "        [ 0.5369,  0.7121, -0.1987],\n",
      "        [ 0.5517,  0.7381, -0.0192],\n",
      "        [ 0.5602,  0.7852, -0.1581],\n",
      "        [ 0.7481,  0.8131,  0.0365],\n",
      "        [ 0.5171,  0.7671, -0.0604],\n",
      "        [ 0.6332,  0.7896, -0.2104],\n",
      "        [ 0.5328,  0.6015, -0.2576],\n",
      "        [ 0.5976,  0.6429, -0.2564],\n",
      "        [ 0.5880,  0.7160, -0.1968],\n",
      "        [ 0.4667,  0.6517, -0.1965],\n",
      "        [ 0.5256,  0.7492, -0.1758],\n",
      "        [ 0.5706,  0.6263, -0.4007],\n",
      "        [ 0.5748,  0.5447, -0.1315],\n",
      "        [ 0.5973,  0.5412, -0.4119],\n",
      "        [ 0.6140,  0.7100, -0.1392]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>) \n",
      " tensor([[1.0389, 0.7117, 2.3822],\n",
      "        [1.1383, 0.8641, 2.1360],\n",
      "        [1.1749, 0.7914, 2.4405],\n",
      "        [0.9859, 0.7024, 2.3219],\n",
      "        [0.9057, 0.6802, 2.3818],\n",
      "        [0.9886, 0.7156, 2.2311],\n",
      "        [1.0717, 0.7413, 2.2869],\n",
      "        [1.0486, 0.7330, 2.3091],\n",
      "        [1.0108, 0.7055, 1.8893],\n",
      "        [1.0881, 0.7747, 2.0489],\n",
      "        [1.0084, 0.7224, 2.1661],\n",
      "        [1.1529, 0.6982, 2.2954],\n",
      "        [1.2360, 0.7725, 2.1931],\n",
      "        [1.1164, 0.7029, 2.3304],\n",
      "        [1.1968, 0.6810, 2.5569],\n",
      "        [1.2420, 0.7976, 2.0421],\n",
      "        [1.0903, 0.7380, 2.0897],\n",
      "        [1.0947, 0.8002, 2.0051],\n",
      "        [1.0078, 0.7609, 2.2749],\n",
      "        [1.2620, 0.6626, 2.2468],\n",
      "        [0.9775, 0.6101, 2.4206],\n",
      "        [1.1232, 0.6901, 2.2980],\n",
      "        [0.9352, 0.6615, 2.3546],\n",
      "        [1.1175, 0.6935, 2.4886],\n",
      "        [1.1610, 0.7641, 2.3394],\n",
      "        [0.9984, 0.7754, 2.1917],\n",
      "        [1.0410, 0.7378, 2.4625],\n",
      "        [1.0873, 0.6981, 2.1606],\n",
      "        [1.1512, 0.7419, 2.1671],\n",
      "        [1.0943, 0.6887, 2.1670],\n",
      "        [1.1050, 0.6224, 2.5580],\n",
      "        [1.0760, 0.7340, 2.1345],\n",
      "        [1.0450, 0.7386, 2.4613],\n",
      "        [0.9417, 0.6284, 2.3292],\n",
      "        [1.2171, 0.7427, 2.0914],\n",
      "        [1.1741, 0.7677, 2.2295],\n",
      "        [1.0679, 0.8253, 2.0426],\n",
      "        [1.1395, 0.7731, 2.2215],\n",
      "        [1.0024, 0.7331, 2.4864],\n",
      "        [1.0981, 0.7385, 2.2364],\n",
      "        [1.2138, 0.7504, 2.3927],\n",
      "        [1.1295, 0.7273, 2.1395],\n",
      "        [1.1479, 0.7323, 2.3975],\n",
      "        [1.2252, 0.7501, 2.0532],\n",
      "        [0.9357, 0.6418, 2.4558],\n",
      "        [1.1531, 0.7181, 2.2521],\n",
      "        [1.1538, 0.6303, 2.4251],\n",
      "        [1.1424, 0.6865, 2.0160],\n",
      "        [1.2535, 0.6598, 2.2529],\n",
      "        [1.1642, 0.7252, 2.1550]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "-0:target_unpadded shape: torch.Size([10, 3])\n",
      "-0:the m[i].log_prob(target_unpadded) is : tensor([[  -1.0740,   -0.6814,   -1.9253],\n",
      "        [  -2.0025,   -2.3049,   -2.2342],\n",
      "        [  -3.8575,   -5.9027,   -2.7193],\n",
      "        [  -6.6390,  -11.4746,   -3.3806],\n",
      "        [ -10.3469,  -19.0207,   -4.2181],\n",
      "        [ -14.9813,  -28.5410,   -5.2318],\n",
      "        [ -42.7836,  -86.3642,  -11.0489],\n",
      "        [ -73.3632, -150.4607,  -17.2619],\n",
      "        [ -98.3819, -203.0627,  -22.2850],\n",
      "        [-279.0633, -584.5247,  -57.9732]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "-0:the loss_1 is : tensor([[3.4165e-01, 5.0589e-01, 1.4584e-01],\n",
      "        [1.3499e-01, 9.9765e-02, 1.0708e-01],\n",
      "        [2.1120e-02, 2.7322e-03, 6.5924e-02],\n",
      "        [1.3083e-03, 1.0391e-05, 3.4028e-02],\n",
      "        [3.2091e-05, 5.4882e-09, 1.4727e-02],\n",
      "        [3.1166e-07, 4.0254e-13, 5.3438e-03],\n",
      "        [2.6262e-19, 3.1082e-38, 1.5905e-05],\n",
      "        [1.3765e-32, 0.0000e+00, 3.1859e-08],\n",
      "        [1.8777e-43, 0.0000e+00, 2.0977e-10],\n",
      "        [0.0000e+00, 0.0000e+00, 6.6457e-26]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>)\n",
      "--0: the result of GMM by hand: tensor([2.7493e-01, 1.1345e-01, 4.0325e-02, 1.7822e-02, 7.5617e-03, 2.7406e-03,\n",
      "        8.1567e-06, 1.6339e-08, 1.0758e-10, 3.4083e-26], device='cuda:0',\n",
      "       grad_fn=<SumBackward1>)\n",
      "-0:the loss_2 is : tensor([2.7493e-01, 1.1345e-01, 4.0325e-02, 1.7822e-02, 7.5617e-03, 2.7406e-03,\n",
      "        8.1567e-06, 1.6339e-08, 1.0758e-10, 3.4083e-26], device='cuda:0',\n",
      "       grad_fn=<SumBackward1>)\n",
      "-0:the loss is : tensor([13.2730], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-1:target_unpadded shape: torch.Size([14, 3])\n",
      "-1:the m[i].log_prob(target_unpadded) is : tensor([[-1.2646e+01, -1.8998e+01, -5.5535e+00],\n",
      "        [-4.3448e+01, -7.0676e+01, -1.4811e+01],\n",
      "        [-7.1191e+01, -1.1775e+02, -2.2995e+01],\n",
      "        [-1.6294e+02, -2.7448e+02, -4.9764e+01],\n",
      "        [-1.7913e+02, -3.0223e+02, -5.4465e+01],\n",
      "        [-2.7167e+02, -4.6106e+02, -8.1257e+01],\n",
      "        [-4.3365e+02, -7.3967e+02, -1.2797e+02],\n",
      "        [-4.5988e+02, -7.8483e+02, -1.3552e+02],\n",
      "        [-6.6507e+02, -1.1384e+03, -1.9451e+02],\n",
      "        [-9.8447e+02, -1.6895e+03, -2.8614e+02],\n",
      "        [-1.3209e+03, -2.2704e+03, -3.8249e+02],\n",
      "        [-1.5562e+03, -2.6771e+03, -4.4983e+02],\n",
      "        [-6.5710e+03, -1.1356e+04, -1.8809e+03],\n",
      "        [-9.0913e+03, -1.5722e+04, -2.5990e+03]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "-1:the loss_1 is : tensor([[3.2204e-06, 5.6140e-09, 3.8739e-03],\n",
      "        [1.3510e-19, 2.0227e-31, 3.6968e-07],\n",
      "        [1.2083e-31, 0.0000e+00, 1.0312e-10],\n",
      "        [0.0000e+00, 0.0000e+00, 2.4421e-22],\n",
      "        [0.0000e+00, 0.0000e+00, 2.2192e-24],\n",
      "        [0.0000e+00, 0.0000e+00, 5.1345e-36],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>)\n",
      "--1: the result of GMM by hand: tensor([1.9813e-03, 1.8899e-07, 5.2715e-11, 1.2485e-22, 1.1345e-24, 2.6249e-36,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-1:the loss_2 is : tensor([1.9813e-03, 1.8899e-07, 5.2715e-11, 1.2485e-22, 1.1345e-24, 2.6249e-36,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-1:the loss is : tensor([52.0848], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-2:target_unpadded shape: torch.Size([15, 3])\n",
      "-2:the m[i].log_prob(target_unpadded) is : tensor([[-1.8230e+00, -1.6509e+00, -2.1998e+00],\n",
      "        [-5.3467e+00, -8.3562e+00, -3.2582e+00],\n",
      "        [-2.6834e+01, -5.3059e+01, -8.8423e+00],\n",
      "        [-3.3304e+01, -6.6789e+01, -1.0463e+01],\n",
      "        [-9.8883e+01, -2.0760e+02, -2.6508e+01],\n",
      "        [-1.1115e+02, -2.3410e+02, -2.9471e+01],\n",
      "        [-1.8335e+02, -3.9056e+02, -4.6808e+01],\n",
      "        [-2.1730e+02, -4.6432e+02, -5.4919e+01],\n",
      "        [-2.9389e+02, -6.3100e+02, -7.3154e+01],\n",
      "        [-4.3051e+02, -9.2891e+02, -1.0554e+02],\n",
      "        [-5.0860e+02, -1.0994e+03, -1.2400e+02],\n",
      "        [-7.4872e+02, -1.6244e+03, -1.8062e+02],\n",
      "        [-8.5071e+02, -1.8475e+03, -2.0462e+02],\n",
      "        [-4.0274e+03, -8.8183e+03, -9.4777e+02],\n",
      "        [-1.8083e+04, -3.9733e+04, -4.2198e+03]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "-2:the loss_1 is : tensor([[1.6154e-01, 1.9188e-01, 1.1082e-01],\n",
      "        [4.7637e-03, 2.3494e-04, 3.8458e-02],\n",
      "        [2.2199e-12, 9.0565e-24, 1.4449e-04],\n",
      "        [3.4368e-15, 9.8646e-30, 2.8579e-05],\n",
      "        [1.1351e-43, 0.0000e+00, 3.0752e-12],\n",
      "        [0.0000e+00, 0.0000e+00, 1.5876e-13],\n",
      "        [0.0000e+00, 0.0000e+00, 4.6921e-21],\n",
      "        [0.0000e+00, 0.0000e+00, 1.4099e-24],\n",
      "        [0.0000e+00, 0.0000e+00, 1.6976e-32],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>)\n",
      "--2: the result of GMM by hand: tensor([1.3960e-01, 2.2430e-02, 7.9594e-05, 1.5743e-05, 1.6940e-12, 8.7457e-14,\n",
      "        2.5847e-21, 7.7668e-25, 9.3514e-33, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00], device='cuda:0',\n",
      "       grad_fn=<SumBackward1>)\n",
      "-2:the loss_2 is : tensor([1.3960e-01, 2.2430e-02, 7.9594e-05, 1.5743e-05, 1.6940e-12, 8.7457e-14,\n",
      "        2.5847e-21, 7.7667e-25, 9.3514e-33, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00], device='cuda:0',\n",
      "       grad_fn=<SumBackward1>)\n",
      "-2:the loss is : tensor([80.9853], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-3:target_unpadded shape: torch.Size([15, 3])\n",
      "-3:the m[i].log_prob(target_unpadded) is : tensor([[-1.6509e+01, -2.8100e+01, -5.2024e+00],\n",
      "        [-6.9028e+01, -1.2798e+02, -1.5320e+01],\n",
      "        [-9.4765e+01, -1.7748e+02, -2.0177e+01],\n",
      "        [-3.6237e+02, -6.9691e+02, -6.9830e+01],\n",
      "        [-3.9016e+02, -7.5105e+02, -7.4948e+01],\n",
      "        [-1.1136e+03, -2.1649e+03, -2.0743e+02],\n",
      "        [-1.7619e+03, -3.4349e+03, -3.2561e+02],\n",
      "        [-1.9471e+03, -3.7980e+03, -3.5932e+02],\n",
      "        [-2.6314e+03, -5.1401e+03, -4.8377e+02],\n",
      "        [-3.5029e+03, -6.8504e+03, -6.4209e+02],\n",
      "        [-5.1976e+03, -1.0178e+04, -9.4957e+02],\n",
      "        [-6.8645e+03, -1.3453e+04, -1.2517e+03],\n",
      "        [-9.1703e+03, -1.7985e+04, -1.6694e+03],\n",
      "        [-9.3082e+03, -1.8256e+04, -1.6943e+03],\n",
      "        [-1.2123e+04, -2.3791e+04, -2.2039e+03]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "-3:the loss_1 is : tensor([[6.7629e-08, 6.2554e-13, 5.5033e-03],\n",
      "        [1.0507e-30, 0.0000e+00, 2.2205e-07],\n",
      "        [6.9813e-42, 0.0000e+00, 1.7269e-09],\n",
      "        [0.0000e+00, 0.0000e+00, 4.7116e-31],\n",
      "        [0.0000e+00, 0.0000e+00, 2.8216e-33],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>)\n",
      "--3: the result of GMM by hand: tensor([3.0278e-03, 1.2216e-07, 9.5006e-10, 2.5922e-31, 1.5523e-33, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00], device='cuda:0',\n",
      "       grad_fn=<SumBackward1>)\n",
      "-3:the loss_2 is : tensor([3.0278e-03, 1.2216e-07, 9.5006e-10, 2.5922e-31, 1.5523e-33, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00], device='cuda:0',\n",
      "       grad_fn=<SumBackward1>)\n",
      "-3:the loss is : tensor([118.6784], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-4:target_unpadded shape: torch.Size([15, 3])\n",
      "-4:the m[i].log_prob(target_unpadded) is : tensor([[-2.3730e+00, -2.4517e+00, -2.1625e+00],\n",
      "        [-4.9286e+00, -6.4121e+00, -2.6146e+00],\n",
      "        [-1.9910e+01, -3.1262e+01, -5.0285e+00],\n",
      "        [-2.7343e+01, -4.3868e+01, -6.1857e+00],\n",
      "        [-3.5994e+01, -5.8636e+01, -7.5191e+00],\n",
      "        [-4.5865e+01, -7.5565e+01, -9.0288e+00],\n",
      "        [-8.2792e+01, -1.3932e+02, -1.4616e+01],\n",
      "        [-9.7539e+01, -1.6490e+02, -1.6830e+01],\n",
      "        [-1.3069e+02, -2.2253e+02, -2.1789e+01],\n",
      "        [-1.8956e+02, -3.2519e+02, -3.0548e+01],\n",
      "        [-3.6960e+02, -6.4039e+02, -5.7157e+01],\n",
      "        [-4.0020e+02, -6.9407e+02, -6.1663e+01],\n",
      "        [-2.5444e+03, -4.4733e+03, -3.7490e+02],\n",
      "        [-3.2134e+03, -5.6549e+03, -4.7229e+02],\n",
      "        [-4.8942e+03, -8.6251e+03, -7.1671e+02]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "-4:the loss_1 is : tensor([[9.3202e-02, 8.6145e-02, 1.1503e-01],\n",
      "        [7.2366e-03, 1.6416e-03, 7.3196e-02],\n",
      "        [2.2543e-09, 2.6492e-14, 6.5487e-03],\n",
      "        [1.3342e-12, 8.8779e-20, 2.0588e-03],\n",
      "        [2.3331e-16, 3.4260e-26, 5.4263e-04],\n",
      "        [1.2056e-20, 1.5225e-33, 1.1991e-04],\n",
      "        [1.1068e-36, 0.0000e+00, 4.4932e-07],\n",
      "        [4.3580e-43, 0.0000e+00, 4.9055e-08],\n",
      "        [0.0000e+00, 0.0000e+00, 3.4458e-10],\n",
      "        [0.0000e+00, 0.0000e+00, 5.4080e-14],\n",
      "        [0.0000e+00, 0.0000e+00, 1.5035e-25],\n",
      "        [0.0000e+00, 0.0000e+00, 1.6597e-27],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>)\n",
      "--4: the result of GMM by hand: tensor([1.0277e-01, 3.9719e-02, 3.3508e-03, 1.0534e-03, 2.7765e-04, 6.1353e-05,\n",
      "        2.2990e-07, 2.5100e-08, 1.7631e-10, 2.7671e-14, 7.6929e-26, 8.4924e-28,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00], device='cuda:0',\n",
      "       grad_fn=<SumBackward1>)\n",
      "-4:the loss_2 is : tensor([1.0277e-01, 3.9719e-02, 3.3508e-03, 1.0534e-03, 2.7765e-04, 6.1353e-05,\n",
      "        2.2990e-07, 2.5100e-08, 1.7631e-10, 2.7671e-14, 7.6929e-26, 8.4924e-28,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00], device='cuda:0',\n",
      "       grad_fn=<SumBackward1>)\n",
      "-4:the loss is : tensor([138.8923], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-5:target_unpadded shape: torch.Size([16, 3])\n",
      "-5:the m[i].log_prob(target_unpadded) is : tensor([[  -1.0209,   -0.6392,   -1.8452],\n",
      "        [  -2.0142,   -2.0787,   -2.1687],\n",
      "        [  -4.0307,   -5.4711,   -2.6931],\n",
      "        [  -7.0702,  -10.8164,   -3.4183],\n",
      "        [ -11.1328,  -18.1146,   -4.3445],\n",
      "        [ -16.2185,  -27.3658,   -5.4715],\n",
      "        [ -22.3273,  -38.5698,   -6.7994],\n",
      "        [ -29.4592,  -51.7268,   -8.3282],\n",
      "        [ -37.6142,  -66.8367,  -10.0579],\n",
      "        [ -46.7923,  -83.8995,  -11.9885],\n",
      "        [ -68.2178, -123.8838,  -16.4523],\n",
      "        [ -80.4652, -146.8053,  -18.9856],\n",
      "        [ -93.7357, -171.6798,  -21.7197],\n",
      "        [-123.3460, -227.2874,  -27.7907],\n",
      "        [-175.4347, -325.3456,  -38.4037],\n",
      "        [-194.8438, -361.9376,  -42.3432]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "-5:the loss_1 is : tensor([[3.6026e-01, 5.2773e-01, 1.5799e-01],\n",
      "        [1.3342e-01, 1.2510e-01, 1.1432e-01],\n",
      "        [1.7763e-02, 4.2067e-03, 6.7672e-02],\n",
      "        [8.5010e-04, 2.0067e-05, 3.2767e-02],\n",
      "        [1.4625e-05, 1.3580e-08, 1.2978e-02],\n",
      "        [9.0451e-08, 1.3037e-12, 4.2049e-03],\n",
      "        [2.0109e-10, 1.7755e-17, 1.1144e-03],\n",
      "        [1.6071e-13, 3.4303e-23, 2.4160e-04],\n",
      "        [4.6171e-17, 9.4014e-30, 4.2845e-05],\n",
      "        [4.7684e-21, 3.6553e-37, 6.2152e-06],\n",
      "        [2.3626e-30, 0.0000e+00, 7.1588e-08],\n",
      "        [1.1335e-35, 0.0000e+00, 5.6841e-09],\n",
      "        [1.9548e-41, 0.0000e+00, 3.6918e-10],\n",
      "        [0.0000e+00, 0.0000e+00, 8.5244e-13],\n",
      "        [0.0000e+00, 0.0000e+00, 2.0964e-17],\n",
      "        [0.0000e+00, 0.0000e+00, 4.0792e-19]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>)\n",
      "--5: the result of GMM by hand: tensor([2.8254e-01, 1.2129e-01, 4.2447e-02, 1.8191e-02, 7.1220e-03, 2.3063e-03,\n",
      "        6.1123e-04, 1.3251e-04, 2.3499e-05, 3.4089e-06, 3.9264e-08, 3.1176e-09,\n",
      "        2.0249e-10, 4.6754e-13, 1.1498e-17, 2.2373e-19], device='cuda:0',\n",
      "       grad_fn=<SumBackward1>)\n",
      "-5:the loss_2 is : tensor([2.8254e-01, 1.2129e-01, 4.2447e-02, 1.8191e-02, 7.1220e-03, 2.3063e-03,\n",
      "        6.1123e-04, 1.3251e-04, 2.3499e-05, 3.4089e-06, 3.9264e-08, 3.1176e-09,\n",
      "        2.0249e-10, 4.6755e-13, 1.1498e-17, 2.2373e-19], device='cuda:0',\n",
      "       grad_fn=<SumBackward1>)\n",
      "-5:the loss is : tensor([153.2943], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-6:target_unpadded shape: torch.Size([16, 3])\n",
      "-6:the m[i].log_prob(target_unpadded) is : tensor([[   -80.7422,   -161.3311,    -20.9419],\n",
      "        [  -120.0144,   -242.0759,    -29.9306],\n",
      "        [  -150.5492,   -305.0046,    -36.8791],\n",
      "        [  -184.5667,   -375.2126,    -44.5925],\n",
      "        [  -355.4639,   -728.8364,    -83.0945],\n",
      "        [  -614.3298,  -1265.8773,   -141.0370],\n",
      "        [  -647.4460,  -1334.6476,   -148.4311],\n",
      "        [  -681.4330,  -1405.2375,   -156.0164],\n",
      "        [  -716.2906,  -1477.6475,   -163.7929],\n",
      "        [  -943.7205,  -1950.3220,   -214.4676],\n",
      "        [  -984.6728,  -2035.4703,   -223.5826],\n",
      "        [ -1544.0133,  -3199.1951,   -347.8775],\n",
      "        [ -1703.4387,  -3531.0713,   -383.2534],\n",
      "        [ -1870.7004,  -3879.3264,   -420.3504],\n",
      "        [ -2966.5300,  -6162.1357,   -663.0722],\n",
      "        [ -5612.5894, -11678.8320,  -1247.9442]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "-6:the loss_1 is : tensor([[8.5924e-36, 0.0000e+00, 8.0361e-10],\n",
      "        [0.0000e+00, 0.0000e+00, 1.0030e-13],\n",
      "        [0.0000e+00, 0.0000e+00, 9.6294e-17],\n",
      "        [0.0000e+00, 0.0000e+00, 4.3025e-20],\n",
      "        [0.0000e+00, 0.0000e+00, 8.1756e-37],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>)\n",
      "--6: the result of GMM by hand: tensor([4.1807e-10, 5.2180e-14, 5.0095e-17, 2.2383e-20, 4.2532e-37, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00], device='cuda:0',\n",
      "       grad_fn=<SumBackward1>)\n",
      "-6:the loss_2 is : tensor([4.1807e-10, 5.2180e-14, 5.0095e-17, 2.2383e-20, 4.2532e-37, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00], device='cuda:0',\n",
      "       grad_fn=<SumBackward1>)\n",
      "-6:the loss is : tensor([197.0355], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-7:target_unpadded shape: torch.Size([16, 3])\n",
      "-7:the m[i].log_prob(target_unpadded) is : tensor([[-1.0709e+03, -2.1728e+03, -2.2849e+02],\n",
      "        [-1.2546e+03, -2.5474e+03, -2.6687e+02],\n",
      "        [-2.0123e+03, -4.0929e+03, -4.2486e+02],\n",
      "        [-7.9849e+03, -1.6292e+04, -1.6648e+03],\n",
      "        [-9.7611e+03, -1.9922e+04, -2.0328e+03],\n",
      "        [-1.2760e+04, -2.6051e+04, -2.6538e+03],\n",
      "        [-3.0153e+04, -6.1614e+04, -6.2520e+03],\n",
      "        [-3.6549e+04, -7.4694e+04, -7.5743e+03],\n",
      "        [-5.5229e+04, -1.1290e+05, -1.1435e+04],\n",
      "        [-9.1470e+04, -1.8703e+05, -1.8921e+04],\n",
      "        [-1.0325e+05, -2.1112e+05, -2.1353e+04],\n",
      "        [-1.5008e+05, -3.0693e+05, -3.1024e+04],\n",
      "        [-1.7621e+05, -3.6038e+05, -3.6418e+04],\n",
      "        [-1.8947e+05, -3.8752e+05, -3.9156e+04],\n",
      "        [-2.6023e+05, -5.3229e+05, -5.3763e+04],\n",
      "        [-3.9286e+05, -8.0366e+05, -8.1137e+04]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "-7:the loss_1 is : tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "--7: the result of GMM by hand: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-7:the loss_2 is : tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-7:the loss is : tensor([nan], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-8:target_unpadded shape: torch.Size([17, 3])\n",
      "-8:the m[i].log_prob(target_unpadded) is : tensor([[-7.2900e+02, -1.4939e+03, -2.1515e+02],\n",
      "        [-8.4666e+02, -1.7354e+03, -2.4923e+02],\n",
      "        [-1.2525e+03, -2.5681e+03, -3.6660e+02],\n",
      "        [-2.5782e+03, -5.2888e+03, -7.4903e+02],\n",
      "        [-1.3742e+04, -2.8203e+04, -3.9573e+03],\n",
      "        [-1.5085e+04, -3.0960e+04, -4.3429e+03],\n",
      "        [-1.5780e+04, -3.2387e+04, -4.5424e+03],\n",
      "        [-1.7401e+04, -3.5715e+04, -5.0077e+03],\n",
      "        [-3.3737e+04, -6.9248e+04, -9.6939e+03],\n",
      "        [-5.8437e+04, -1.1995e+05, -1.6775e+04],\n",
      "        [-5.9797e+04, -1.2274e+05, -1.7165e+04],\n",
      "        [-8.4508e+04, -1.7347e+05, -2.4248e+04],\n",
      "        [-9.0298e+04, -1.8535e+05, -2.5907e+04],\n",
      "        [-1.2507e+05, -2.5674e+05, -3.5872e+04],\n",
      "        [-1.8242e+05, -3.7446e+05, -5.2302e+04],\n",
      "        [-1.9519e+05, -4.0066e+05, -5.5959e+04],\n",
      "        [-3.3270e+05, -6.8296e+05, -9.5350e+04]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "-8:the loss_1 is : tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "--8: the result of GMM by hand: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-8:the loss_2 is : tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-8:the loss is : tensor([nan], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-9:target_unpadded shape: torch.Size([18, 3])\n",
      "-9:the m[i].log_prob(target_unpadded) is : tensor([[-1.9941e+00, -2.1215e+00, -2.1594e+00],\n",
      "        [-9.6766e+00, -1.6233e+01, -4.7289e+00],\n",
      "        [-1.3927e+01, -2.4269e+01, -6.0618e+00],\n",
      "        [-1.9022e+01, -3.3972e+01, -7.6330e+00],\n",
      "        [-4.7848e+01, -8.9447e+01, -1.6300e+01],\n",
      "        [-1.1643e+02, -2.2265e+02, -3.6446e+01],\n",
      "        [-1.7904e+02, -3.4478e+02, -5.4640e+01],\n",
      "        [-1.9681e+02, -3.7948e+02, -5.9785e+01],\n",
      "        [-3.9471e+02, -7.6675e+02, -1.1680e+02],\n",
      "        [-4.7588e+02, -9.2583e+02, -1.4010e+02],\n",
      "        [-5.3422e+02, -1.0402e+03, -1.5682e+02],\n",
      "        [-8.7659e+02, -1.7121e+03, -2.5471e+02],\n",
      "        [-1.0372e+03, -2.0276e+03, -3.0053e+02],\n",
      "        [-1.6001e+03, -3.1338e+03, -4.6088e+02],\n",
      "        [-2.6725e+03, -5.2431e+03, -7.6572e+02],\n",
      "        [-2.8085e+03, -5.5108e+03, -8.0435e+02],\n",
      "        [-5.3494e+03, -1.0512e+04, -1.5250e+03],\n",
      "        [-6.2391e+03, -1.2264e+04, -1.7771e+03]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "-9:the loss_1 is : tensor([[1.3613e-01, 1.1985e-01, 1.1540e-01],\n",
      "        [6.2735e-05, 8.9162e-08, 8.8361e-03],\n",
      "        [8.9467e-07, 2.8839e-11, 2.3301e-03],\n",
      "        [5.4824e-09, 1.7623e-15, 4.8422e-04],\n",
      "        [1.6585e-21, 1.4242e-39, 8.3404e-08],\n",
      "        [0.0000e+00, 0.0000e+00, 1.4855e-16],\n",
      "        [0.0000e+00, 0.0000e+00, 1.8619e-24],\n",
      "        [0.0000e+00, 0.0000e+00, 1.0861e-26],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>)\n",
      "--9: the result of GMM by hand: tensor([1.2193e-01, 4.5250e-03, 1.1891e-03, 2.4705e-04, 4.2553e-08, 7.5790e-17,\n",
      "        9.4996e-25, 5.5412e-27, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "       device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-9:the loss_2 is : tensor([1.2193e-01, 4.5250e-03, 1.1891e-03, 2.4705e-04, 4.2553e-08, 7.5790e-17,\n",
      "        9.4996e-25, 5.5412e-27, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "       device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-9:the loss is : tensor([nan], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-10:target_unpadded shape: torch.Size([18, 3])\n",
      "-10:the m[i].log_prob(target_unpadded) is : tensor([[-1.1935e+02, -2.2566e+02, -2.9794e+01],\n",
      "        [-2.7290e+02, -5.2194e+02, -6.4303e+01],\n",
      "        [-3.2112e+02, -6.1517e+02, -7.5062e+01],\n",
      "        [-4.5888e+02, -8.8178e+02, -1.0569e+02],\n",
      "        [-8.0815e+02, -1.5587e+03, -1.8293e+02],\n",
      "        [-9.3211e+02, -1.7992e+03, -2.1026e+02],\n",
      "        [-1.1584e+03, -2.2382e+03, -2.6007e+02],\n",
      "        [-1.4092e+03, -2.7252e+03, -3.1520e+02],\n",
      "        [-1.9227e+03, -3.7225e+03, -4.2788e+02],\n",
      "        [-3.0322e+03, -5.8787e+03, -6.7082e+02],\n",
      "        [-3.1886e+03, -6.1827e+03, -7.0502e+02],\n",
      "        [-4.4868e+03, -8.7072e+03, -9.8873e+02],\n",
      "        [-5.8982e+03, -1.1452e+04, -1.2968e+03],\n",
      "        [-6.4489e+03, -1.2524e+04, -1.4169e+03],\n",
      "        [-9.5715e+03, -1.8600e+04, -2.0976e+03],\n",
      "        [-1.1892e+04, -2.3117e+04, -2.6031e+03],\n",
      "        [-1.9183e+04, -3.7308e+04, -4.1897e+03],\n",
      "        [-1.9573e+04, -3.8068e+04, -4.2747e+03]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "-10:the loss_1 is : tensor([[0.0000e+00, 0.0000e+00, 1.1497e-13],\n",
      "        [0.0000e+00, 0.0000e+00, 1.1840e-28],\n",
      "        [0.0000e+00, 0.0000e+00, 2.5171e-33],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>)\n",
      "--10: the result of GMM by hand: tensor([6.0002e-14, 6.1790e-29, 1.3136e-33, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "       device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-10:the loss_2 is : tensor([6.0002e-14, 6.1791e-29, 1.3136e-33, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "       device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-10:the loss is : tensor([nan], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-11:target_unpadded shape: torch.Size([19, 3])\n",
      "-11:the m[i].log_prob(target_unpadded) is : tensor([[-9.5796e+02, -2.6090e+03, -2.5092e+02],\n",
      "        [-1.1158e+03, -3.0392e+03, -2.9134e+02],\n",
      "        [-3.6461e+03, -9.9374e+03, -9.3637e+02],\n",
      "        [-4.0258e+03, -1.0973e+04, -1.0329e+03],\n",
      "        [-8.2895e+03, -2.2596e+04, -2.1153e+03],\n",
      "        [-2.3783e+04, -6.4836e+04, -6.0395e+03],\n",
      "        [-2.3207e+05, -6.3269e+05, -5.8663e+04],\n",
      "        [-2.4102e+05, -6.5709e+05, -6.0922e+04],\n",
      "        [-2.6193e+05, -7.1410e+05, -6.6202e+04],\n",
      "        [-2.7143e+05, -7.4000e+05, -6.8601e+04],\n",
      "        [-3.4412e+05, -9.3817e+05, -8.6954e+04],\n",
      "        [-4.0800e+05, -1.1123e+06, -1.0308e+05],\n",
      "        [-5.2152e+05, -1.4218e+06, -1.3174e+05],\n",
      "        [-6.2449e+05, -1.7025e+06, -1.5773e+05],\n",
      "        [-8.3789e+05, -2.2844e+06, -2.1159e+05],\n",
      "        [-1.0598e+06, -2.8892e+06, -2.6759e+05],\n",
      "        [-1.0775e+06, -2.9376e+06, -2.7207e+05],\n",
      "        [-1.1992e+06, -3.2693e+06, -3.0277e+05],\n",
      "        [-1.2316e+06, -3.3578e+06, -3.1097e+05]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "-11:the loss_1 is : tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "--11: the result of GMM by hand: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-11:the loss_2 is : tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-11:the loss is : tensor([nan], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-12:target_unpadded shape: torch.Size([19, 3])\n",
      "-12:the m[i].log_prob(target_unpadded) is : tensor([[-7.9163e+01, -1.9710e+02, -2.8928e+01],\n",
      "        [-2.6586e+02, -6.7228e+02, -9.0237e+01],\n",
      "        [-1.6250e+03, -4.1431e+03, -5.2846e+02],\n",
      "        [-1.7663e+03, -4.5042e+03, -5.7380e+02],\n",
      "        [-2.3347e+03, -5.9570e+03, -7.5604e+02],\n",
      "        [-3.1085e+03, -7.9355e+03, -1.0039e+03],\n",
      "        [-3.1726e+03, -8.0994e+03, -1.0244e+03],\n",
      "        [-3.3689e+03, -8.6012e+03, -1.0872e+03],\n",
      "        [-3.5710e+03, -9.1181e+03, -1.1518e+03],\n",
      "        [-4.6701e+03, -1.1929e+04, -1.5033e+03],\n",
      "        [-4.9075e+03, -1.2536e+04, -1.5792e+03],\n",
      "        [-7.4081e+03, -1.8933e+04, -2.3778e+03],\n",
      "        [-1.2630e+04, -3.2293e+04, -4.0438e+03],\n",
      "        [-1.2759e+04, -3.2623e+04, -4.0849e+03],\n",
      "        [-1.5905e+04, -4.0672e+04, -5.0876e+03],\n",
      "        [-1.7080e+04, -4.3679e+04, -5.4622e+03],\n",
      "        [-1.7989e+04, -4.6005e+04, -5.7518e+03],\n",
      "        [-2.6480e+04, -6.7733e+04, -8.4567e+03],\n",
      "        [-3.4877e+04, -8.9223e+04, -1.1130e+04]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "-12:the loss_1 is : tensor([[4.1682e-35, 0.0000e+00, 2.7345e-13],\n",
      "        [0.0000e+00, 0.0000e+00, 6.4650e-40],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>)\n",
      "--12: the result of GMM by hand: tensor([1.4243e-13, 3.3674e-40, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-12:the loss_2 is : tensor([1.4243e-13, 3.3675e-40, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-12:the loss is : tensor([nan], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-13:target_unpadded shape: torch.Size([20, 3])\n",
      "-13:the m[i].log_prob(target_unpadded) is : tensor([[-1.1003e+00, -6.1603e-01, -1.9027e+00],\n",
      "        [-1.8394e+00, -2.0762e+00, -2.2200e+00],\n",
      "        [-3.3809e+00, -5.5604e+00, -2.7214e+00],\n",
      "        [-5.7246e+00, -1.1068e+01, -3.4069e+00],\n",
      "        [-8.8707e+00, -1.8601e+01, -4.2766e+00],\n",
      "        [-1.2819e+01, -2.8157e+01, -5.3304e+00],\n",
      "        [-1.7570e+01, -3.9737e+01, -6.5684e+00],\n",
      "        [-2.3123e+01, -5.3341e+01, -7.9904e+00],\n",
      "        [-2.9478e+01, -6.8969e+01, -9.5966e+00],\n",
      "        [-3.6635e+01, -8.6621e+01, -1.1387e+01],\n",
      "        [-4.4595e+01, -1.0630e+02, -1.3361e+01],\n",
      "        [-5.3357e+01, -1.2800e+02, -1.5520e+01],\n",
      "        [-9.6428e+01, -2.3504e+02, -2.5996e+01],\n",
      "        [-1.0920e+02, -2.6686e+02, -2.9075e+01],\n",
      "        [-1.2278e+02, -3.0070e+02, -3.2338e+01],\n",
      "        [-1.5234e+02, -3.7446e+02, -3.9418e+01],\n",
      "        [-2.2108e+02, -5.4627e+02, -5.5786e+01],\n",
      "        [-4.4910e+02, -1.1175e+03, -1.0960e+02],\n",
      "        [-6.8928e+02, -1.7201e+03, -1.6590e+02],\n",
      "        [-2.7261e+03, -6.8420e+03, -6.3943e+02]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "-13:the loss_1 is : tensor([[3.3278e-01, 5.4008e-01, 1.4916e-01],\n",
      "        [1.5891e-01, 1.2540e-01, 1.0861e-01],\n",
      "        [3.4017e-02, 3.8474e-03, 6.5783e-02],\n",
      "        [3.2645e-03, 1.5596e-05, 3.3143e-02],\n",
      "        [1.4045e-04, 8.3534e-09, 1.3890e-02],\n",
      "        [2.7088e-06, 5.9117e-13, 4.8421e-03],\n",
      "        [2.3421e-08, 5.5280e-18, 1.4041e-03],\n",
      "        [9.0784e-11, 6.8299e-24, 3.3869e-04],\n",
      "        [1.5775e-13, 1.1150e-30, 6.7957e-05],\n",
      "        [1.2289e-16, 2.4050e-38, 1.1342e-05],\n",
      "        [4.2918e-20, 0.0000e+00, 1.5747e-06],\n",
      "        [6.7191e-24, 0.0000e+00, 1.8186e-07],\n",
      "        [1.3228e-42, 0.0000e+00, 5.1305e-12],\n",
      "        [0.0000e+00, 0.0000e+00, 2.3597e-13],\n",
      "        [0.0000e+00, 0.0000e+00, 9.0276e-15],\n",
      "        [0.0000e+00, 0.0000e+00, 7.6052e-18],\n",
      "        [0.0000e+00, 0.0000e+00, 5.9234e-25],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>)\n",
      "--13: the result of GMM by hand: tensor([2.7233e-01, 1.2479e-01, 4.5582e-02, 1.9030e-02, 7.6588e-03, 2.6580e-03,\n",
      "        7.7059e-04, 1.8587e-04, 3.7295e-05, 6.2247e-06, 8.6420e-07, 9.9803e-08,\n",
      "        2.8157e-12, 1.2950e-13, 4.9544e-15, 4.1738e-18, 3.2508e-25, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-13:the loss_2 is : tensor([2.7233e-01, 1.2479e-01, 4.5582e-02, 1.9030e-02, 7.6588e-03, 2.6580e-03,\n",
      "        7.7059e-04, 1.8587e-04, 3.7295e-05, 6.2247e-06, 8.6420e-07, 9.9803e-08,\n",
      "        2.8157e-12, 1.2950e-13, 4.9544e-15, 4.1738e-18, 3.2508e-25, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-13:the loss is : tensor([nan], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-14:target_unpadded shape: torch.Size([20, 3])\n",
      "-14:the m[i].log_prob(target_unpadded) is : tensor([[-6.3358e+01, -1.9068e+02, -1.7272e+01],\n",
      "        [-2.0816e+02, -6.3611e+02, -5.0413e+01],\n",
      "        [-2.2551e+02, -6.8954e+02, -5.4343e+01],\n",
      "        [-3.6653e+02, -1.1239e+03, -8.6140e+01],\n",
      "        [-5.9810e+02, -1.8377e+03, -1.3804e+02],\n",
      "        [-1.7290e+03, -5.3255e+03, -3.8954e+02],\n",
      "        [-1.8794e+03, -5.7899e+03, -4.2290e+02],\n",
      "        [-2.1993e+03, -6.7767e+03, -4.9375e+02],\n",
      "        [-4.6461e+03, -1.4328e+04, -1.0345e+03],\n",
      "        [-8.4261e+03, -2.5995e+04, -1.8678e+03],\n",
      "        [-9.0894e+03, -2.8043e+04, -2.0139e+03],\n",
      "        [-9.8950e+03, -3.0530e+04, -2.1913e+03],\n",
      "        [-1.0981e+04, -3.3883e+04, -2.4305e+03],\n",
      "        [-1.2254e+04, -3.7813e+04, -2.7107e+03],\n",
      "        [-1.2385e+04, -3.8218e+04, -2.7395e+03],\n",
      "        [-1.5447e+04, -4.7671e+04, -3.4132e+03],\n",
      "        [-2.9633e+04, -9.1469e+04, -6.5318e+03],\n",
      "        [-3.2336e+04, -9.9816e+04, -7.1257e+03],\n",
      "        [-3.2763e+04, -1.0113e+05, -7.2194e+03],\n",
      "        [-3.6953e+04, -1.1407e+05, -8.1398e+03]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "-14:the loss_1 is : tensor([[3.0474e-28, 0.0000e+00, 3.1554e-08],\n",
      "        [0.0000e+00, 0.0000e+00, 1.2767e-22],\n",
      "        [0.0000e+00, 0.0000e+00, 2.5065e-24],\n",
      "        [0.0000e+00, 0.0000e+00, 3.8880e-38],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>)\n",
      "--14: the result of GMM by hand: tensor([1.6485e-08, 6.6700e-23, 1.3094e-24, 2.0312e-38, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-14:the loss_2 is : tensor([1.6485e-08, 6.6700e-23, 1.3094e-24, 2.0312e-38, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-14:the loss is : tensor([nan], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-15:target_unpadded shape: torch.Size([21, 3])\n",
      "-15:the m[i].log_prob(target_unpadded) is : tensor([[-9.9768e+01, -2.3876e+02, -4.1287e+01],\n",
      "        [-1.1140e+02, -2.6690e+02, -4.5768e+01],\n",
      "        [-1.2368e+02, -2.9661e+02, -5.0489e+01],\n",
      "        [-3.6368e+02, -8.7764e+02, -1.4176e+02],\n",
      "        [-1.7495e+03, -4.2352e+03, -6.6152e+02],\n",
      "        [-2.9539e+03, -7.1538e+03, -1.1109e+03],\n",
      "        [-1.1757e+04, -2.8492e+04, -4.3843e+03],\n",
      "        [-1.7214e+04, -4.1720e+04, -6.4100e+03],\n",
      "        [-2.4952e+04, -6.0477e+04, -9.2806e+03],\n",
      "        [-1.1686e+05, -2.8330e+05, -4.3337e+04],\n",
      "        [-1.4788e+05, -3.5850e+05, -5.4824e+04],\n",
      "        [-1.5587e+05, -3.7786e+05, -5.7782e+04],\n",
      "        [-1.8450e+05, -4.4726e+05, -6.8383e+04],\n",
      "        [-2.1872e+05, -5.3024e+05, -8.1054e+04],\n",
      "        [-2.2950e+05, -5.5637e+05, -8.5046e+04],\n",
      "        [-2.3389e+05, -5.6700e+05, -8.6669e+04],\n",
      "        [-2.4616e+05, -5.9675e+05, -9.1212e+04],\n",
      "        [-4.6633e+05, -1.1305e+06, -1.7271e+05],\n",
      "        [-5.4901e+05, -1.3310e+06, -2.0332e+05],\n",
      "        [-8.0452e+05, -1.9505e+06, -2.9788e+05],\n",
      "        [-1.2868e+06, -3.1197e+06, -4.7635e+05]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "-15:the loss_1 is : tensor([[4.6243e-44, 0.0000e+00, 1.1730e-18],\n",
      "        [0.0000e+00, 0.0000e+00, 1.3282e-20],\n",
      "        [0.0000e+00, 0.0000e+00, 1.1832e-22],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>)\n",
      "--15: the result of GMM by hand: tensor([5.7034e-19, 6.4579e-21, 5.7532e-23, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00], device='cuda:0',\n",
      "       grad_fn=<SumBackward1>)\n",
      "-15:the loss_2 is : tensor([5.7034e-19, 6.4580e-21, 5.7532e-23, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00], device='cuda:0',\n",
      "       grad_fn=<SumBackward1>)\n",
      "-15:the loss is : tensor([nan], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-16:target_unpadded shape: torch.Size([21, 3])\n",
      "-16:the m[i].log_prob(target_unpadded) is : tensor([[-5.3153e+02, -1.1552e+03, -1.5101e+02],\n",
      "        [-3.0768e+03, -6.7056e+03, -8.5079e+02],\n",
      "        [-4.1663e+03, -9.0823e+03, -1.1493e+03],\n",
      "        [-1.2958e+04, -2.8263e+04, -3.5531e+03],\n",
      "        [-3.9259e+04, -8.5655e+04, -1.0731e+04],\n",
      "        [-4.4294e+04, -9.6642e+04, -1.2104e+04],\n",
      "        [-5.5580e+04, -1.2127e+05, -1.5182e+04],\n",
      "        [-7.1921e+04, -1.5693e+05, -1.9637e+04],\n",
      "        [-9.7519e+04, -2.1279e+05, -2.6615e+04],\n",
      "        [-1.0286e+05, -2.2444e+05, -2.8070e+04],\n",
      "        [-1.1838e+05, -2.5831e+05, -3.2300e+04],\n",
      "        [-1.3690e+05, -2.9873e+05, -3.7348e+04],\n",
      "        [-1.6039e+05, -3.4999e+05, -4.3748e+04],\n",
      "        [-1.7256e+05, -3.7655e+05, -4.7064e+04],\n",
      "        [-1.9997e+05, -4.3637e+05, -5.4533e+04],\n",
      "        [-2.6684e+05, -5.8232e+05, -7.2754e+04],\n",
      "        [-3.0140e+05, -6.5772e+05, -8.2167e+04],\n",
      "        [-4.1349e+05, -9.0236e+05, -1.1270e+05],\n",
      "        [-4.2356e+05, -9.2434e+05, -1.1545e+05],\n",
      "        [-4.9378e+05, -1.0776e+06, -1.3457e+05],\n",
      "        [-6.6617e+05, -1.4538e+06, -1.8153e+05]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "-16:the loss_1 is : tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "--16: the result of GMM by hand: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-16:the loss_2 is : tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-16:the loss is : tensor([nan], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-17:target_unpadded shape: torch.Size([23, 3])\n",
      "-17:the m[i].log_prob(target_unpadded) is : tensor([[-1.6109e+04, -3.0109e+04, -4.8352e+03],\n",
      "        [-6.1681e+04, -1.1537e+05, -1.8449e+04],\n",
      "        [-3.4134e+05, -6.3869e+05, -1.0189e+05],\n",
      "        [-4.0030e+05, -7.4902e+05, -1.1947e+05],\n",
      "        [-1.0475e+06, -1.9603e+06, -3.1248e+05],\n",
      "        [-2.0057e+06, -3.7535e+06, -5.9817e+05],\n",
      "        [-4.2712e+06, -7.9935e+06, -1.2736e+06],\n",
      "        [-4.5121e+06, -8.4444e+06, -1.3454e+06],\n",
      "        [-5.5146e+06, -1.0321e+07, -1.6443e+06],\n",
      "        [-1.0164e+07, -1.9022e+07, -3.0301e+06],\n",
      "        [-1.0375e+07, -1.9417e+07, -3.0931e+06],\n",
      "        [-2.6321e+07, -4.9262e+07, -7.8464e+06],\n",
      "        [-2.8512e+07, -5.3363e+07, -8.4996e+06],\n",
      "        [-4.4649e+07, -8.3564e+07, -1.3309e+07],\n",
      "        [-4.4718e+07, -8.3693e+07, -1.3330e+07],\n",
      "        [-5.8486e+07, -1.0946e+08, -1.7434e+07],\n",
      "        [-6.4316e+07, -1.2037e+08, -1.9172e+07],\n",
      "        [-6.8548e+07, -1.2829e+08, -2.0433e+07],\n",
      "        [-7.9731e+07, -1.4922e+08, -2.3766e+07],\n",
      "        [-1.0081e+08, -1.8867e+08, -3.0048e+07],\n",
      "        [-1.6833e+08, -3.1504e+08, -5.0174e+07],\n",
      "        [-2.5885e+08, -4.8447e+08, -7.7156e+07],\n",
      "        [-2.6164e+08, -4.8970e+08, -7.7988e+07]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "-17:the loss_1 is : tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "--17: the result of GMM by hand: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-17:the loss_2 is : tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-17:the loss is : tensor([nan], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-18:target_unpadded shape: torch.Size([23, 3])\n",
      "-18:the m[i].log_prob(target_unpadded) is : tensor([[-2.0340e+00, -1.9520e+00, -2.1632e+00],\n",
      "        [-1.0894e+01, -1.6098e+01, -4.2448e+00],\n",
      "        [-2.1724e+01, -3.4166e+01, -6.5987e+00],\n",
      "        [-2.8616e+01, -4.5792e+01, -8.0655e+00],\n",
      "        [-4.5353e+01, -7.4224e+01, -1.1579e+01],\n",
      "        [-5.5198e+01, -9.1031e+01, -1.3625e+01],\n",
      "        [-7.7842e+01, -1.2983e+02, -1.8298e+01],\n",
      "        [-9.0641e+01, -1.5182e+02, -2.0924e+01],\n",
      "        [-1.0442e+02, -1.7553e+02, -2.3744e+01],\n",
      "        [-1.3495e+02, -2.2815e+02, -2.9962e+01],\n",
      "        [-1.6940e+02, -2.8767e+02, -3.6954e+01],\n",
      "        [-2.2848e+02, -3.8992e+02, -4.8890e+01],\n",
      "        [-2.5014e+02, -4.2745e+02, -5.3255e+01],\n",
      "        [-2.9641e+02, -5.0771e+02, -6.2566e+01],\n",
      "        [-3.4662e+02, -5.9487e+02, -7.2649e+01],\n",
      "        [-5.2089e+02, -8.9782e+02, -1.0754e+02],\n",
      "        [-5.8685e+02, -1.0126e+03, -1.2071e+02],\n",
      "        [-6.2131e+02, -1.0726e+03, -1.2759e+02],\n",
      "        [-1.0201e+03, -1.7675e+03, -2.0699e+02],\n",
      "        [-1.5173e+03, -2.6352e+03, -3.0571e+02],\n",
      "        [-1.5724e+03, -2.7315e+03, -3.1665e+02],\n",
      "        [-1.7437e+03, -3.0306e+03, -3.5061e+02],\n",
      "        [-3.1122e+03, -5.4224e+03, -6.2149e+02]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "-18:the loss_1 is : tensor([[1.3082e-01, 1.4199e-01, 1.1495e-01],\n",
      "        [1.8565e-05, 1.0198e-07, 1.4338e-02],\n",
      "        [3.6766e-10, 1.4511e-15, 1.3621e-03],\n",
      "        [3.7362e-13, 1.2972e-20, 3.1418e-04],\n",
      "        [2.0121e-20, 5.8212e-33, 9.3622e-06],\n",
      "        [1.0663e-24, 2.9223e-40, 1.2095e-06],\n",
      "        [1.5615e-34, 0.0000e+00, 1.1305e-08],\n",
      "        [4.3151e-40, 0.0000e+00, 8.1796e-10],\n",
      "        [0.0000e+00, 0.0000e+00, 4.8784e-11],\n",
      "        [0.0000e+00, 0.0000e+00, 9.7184e-14],\n",
      "        [0.0000e+00, 0.0000e+00, 8.9379e-17],\n",
      "        [0.0000e+00, 0.0000e+00, 5.8520e-22],\n",
      "        [0.0000e+00, 0.0000e+00, 7.4385e-24],\n",
      "        [0.0000e+00, 0.0000e+00, 6.7312e-28],\n",
      "        [0.0000e+00, 0.0000e+00, 2.8120e-32],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>)\n",
      "--18: the result of GMM by hand: tensor([1.2478e-01, 7.5815e-03, 7.1977e-04, 1.6602e-04, 4.9473e-06, 6.3912e-07,\n",
      "        5.9740e-09, 4.3224e-10, 2.5779e-11, 5.1355e-14, 4.7231e-17, 3.0924e-22,\n",
      "        3.9308e-24, 3.5570e-28, 1.4860e-32, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "       device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-18:the loss_2 is : tensor([1.2478e-01, 7.5815e-03, 7.1977e-04, 1.6602e-04, 4.9473e-06, 6.3912e-07,\n",
      "        5.9740e-09, 4.3224e-10, 2.5779e-11, 5.1355e-14, 4.7231e-17, 3.0924e-22,\n",
      "        3.9308e-24, 3.5570e-28, 1.4860e-32, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "       device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-18:the loss is : tensor([nan], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-19:target_unpadded shape: torch.Size([24, 3])\n",
      "-19:the m[i].log_prob(target_unpadded) is : tensor([[-4.4026e+02, -1.5987e+03, -1.4788e+02],\n",
      "        [-1.4700e+03, -5.3385e+03, -4.7897e+02],\n",
      "        [-2.3448e+03, -8.5146e+03, -7.5858e+02],\n",
      "        [-1.0106e+04, -3.6682e+04, -3.2257e+03],\n",
      "        [-2.3469e+04, -8.5175e+04, -7.4605e+03],\n",
      "        [-2.3987e+04, -8.7054e+04, -7.6245e+03],\n",
      "        [-2.9862e+04, -1.0837e+05, -9.4845e+03],\n",
      "        [-9.1011e+04, -3.3024e+05, -2.8822e+04],\n",
      "        [-1.5314e+05, -5.5566e+05, -4.8455e+04],\n",
      "        [-1.8828e+05, -6.8316e+05, -5.9558e+04],\n",
      "        [-2.2439e+05, -8.1416e+05, -7.0964e+04],\n",
      "        [-2.4724e+05, -8.9706e+05, -7.8181e+04],\n",
      "        [-4.2715e+05, -1.5498e+06, -1.3499e+05],\n",
      "        [-4.3746e+05, -1.5872e+06, -1.3825e+05],\n",
      "        [-5.3256e+05, -1.9322e+06, -1.6828e+05],\n",
      "        [-6.4959e+05, -2.3568e+06, -2.0523e+05],\n",
      "        [-8.2641e+05, -2.9983e+06, -2.6105e+05],\n",
      "        [-1.0462e+06, -3.7955e+06, -3.3042e+05],\n",
      "        [-1.4491e+06, -5.2575e+06, -4.5762e+05],\n",
      "        [-1.5396e+06, -5.5855e+06, -4.8615e+05],\n",
      "        [-1.6817e+06, -6.1013e+06, -5.3103e+05],\n",
      "        [-2.5259e+06, -9.1639e+06, -7.9745e+05],\n",
      "        [-3.0258e+06, -1.0977e+07, -9.5521e+05],\n",
      "        [-1.5567e+07, -5.6474e+07, -4.9125e+06]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "-19:the loss_1 is : tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "--19: the result of GMM by hand: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-19:the loss_2 is : tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-19:the loss is : tensor([nan], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-20:target_unpadded shape: torch.Size([24, 3])\n",
      "-20:the m[i].log_prob(target_unpadded) is : tensor([[-7.5617e+00, -1.4809e+01, -3.2661e+00],\n",
      "        [-1.7125e+01, -3.7766e+01, -5.0208e+00],\n",
      "        [-2.3477e+01, -5.3275e+01, -6.1541e+00],\n",
      "        [-4.8812e+01, -1.1592e+02, -1.0578e+01],\n",
      "        [-5.9350e+01, -1.4218e+02, -1.2394e+01],\n",
      "        [-8.3567e+01, -2.0275e+02, -1.6538e+01],\n",
      "        [-1.1197e+02, -2.7407e+02, -2.1365e+01],\n",
      "        [-2.0129e+02, -4.9939e+02, -3.6418e+01],\n",
      "        [-2.2230e+02, -5.5252e+02, -3.9941e+01],\n",
      "        [-2.9159e+02, -7.2801e+02, -5.1533e+01],\n",
      "        [-4.8990e+02, -1.2315e+03, -8.4555e+01],\n",
      "        [-5.2242e+02, -1.3142e+03, -8.9955e+01],\n",
      "        [-5.9059e+02, -1.4876e+03, -1.0127e+02],\n",
      "        [-1.0875e+03, -2.7539e+03, -1.8348e+02],\n",
      "        [-1.3391e+03, -3.3956e+03, -2.2498e+02],\n",
      "        [-1.3925e+03, -3.5321e+03, -2.3380e+02],\n",
      "        [-1.7960e+03, -4.5622e+03, -3.0027e+02],\n",
      "        [-2.1826e+03, -5.5500e+03, -3.6390e+02],\n",
      "        [-2.5336e+03, -6.4470e+03, -4.2162e+02],\n",
      "        [-3.3978e+03, -8.6569e+03, -5.6362e+02],\n",
      "        [-4.5825e+03, -1.1688e+04, -7.5807e+02],\n",
      "        [-6.9902e+03, -1.7851e+04, -1.1528e+03],\n",
      "        [-7.4824e+03, -1.9112e+04, -1.2335e+03],\n",
      "        [-1.0787e+04, -2.7577e+04, -1.7747e+03]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "-20:the loss_1 is : tensor([[5.2001e-04, 3.7041e-07, 3.8156e-02],\n",
      "        [3.6520e-08, 3.9674e-17, 6.5994e-03],\n",
      "        [6.3677e-11, 7.2963e-24, 2.1247e-03],\n",
      "        [6.3262e-22, 0.0000e+00, 2.5465e-05],\n",
      "        [1.6767e-26, 0.0000e+00, 4.1424e-06],\n",
      "        [5.0991e-37, 0.0000e+00, 6.5692e-08],\n",
      "        [0.0000e+00, 0.0000e+00, 5.2638e-10],\n",
      "        [0.0000e+00, 0.0000e+00, 1.5263e-16],\n",
      "        [0.0000e+00, 0.0000e+00, 4.5057e-18],\n",
      "        [0.0000e+00, 0.0000e+00, 4.1628e-23],\n",
      "        [0.0000e+00, 0.0000e+00, 1.8980e-37],\n",
      "        [0.0000e+00, 0.0000e+00, 8.5723e-40],\n",
      "        [0.0000e+00, 0.0000e+00, 9.8091e-45],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>)\n",
      "--20: the result of GMM by hand: tensor([2.1545e-02, 3.7052e-03, 1.1929e-03, 1.4297e-05, 2.3257e-06, 3.6882e-08,\n",
      "        2.9553e-10, 8.5695e-17, 2.5297e-18, 2.3371e-23, 1.0656e-37, 4.8128e-40,\n",
      "        5.6052e-45, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "       device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-20:the loss_2 is : tensor([2.1545e-02, 3.7052e-03, 1.1929e-03, 1.4297e-05, 2.3257e-06, 3.6882e-08,\n",
      "        2.9553e-10, 8.5695e-17, 2.5297e-18, 2.3371e-23, 1.0656e-37, 4.8128e-40,\n",
      "        5.6052e-45, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "       device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-20:the loss is : tensor([nan], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-21:target_unpadded shape: torch.Size([28, 3])\n",
      "-21:the m[i].log_prob(target_unpadded) is : tensor([[-1.8626e+03, -4.9226e+03, -4.5415e+02],\n",
      "        [-2.2028e+03, -5.8230e+03, -5.3609e+02],\n",
      "        [-4.5156e+04, -1.1956e+05, -1.0827e+04],\n",
      "        [-6.7126e+04, -1.7774e+05, -1.6083e+04],\n",
      "        [-1.2100e+05, -3.2043e+05, -2.8970e+04],\n",
      "        [-4.3078e+05, -1.1409e+06, -1.0303e+05],\n",
      "        [-7.2827e+05, -1.9288e+06, -1.7413e+05],\n",
      "        [-8.6761e+05, -2.2979e+06, -2.0743e+05],\n",
      "        [-1.2327e+06, -3.2647e+06, -2.9467e+05],\n",
      "        [-1.5328e+06, -4.0596e+06, -3.6639e+05],\n",
      "        [-1.6069e+06, -4.2560e+06, -3.8410e+05],\n",
      "        [-1.8364e+06, -4.8639e+06, -4.3895e+05],\n",
      "        [-1.8415e+06, -4.8775e+06, -4.4017e+05],\n",
      "        [-2.0577e+06, -5.4500e+06, -4.9183e+05],\n",
      "        [-2.1694e+06, -5.7457e+06, -5.1850e+05],\n",
      "        [-2.2066e+06, -5.8444e+06, -5.2741e+05],\n",
      "        [-2.3937e+06, -6.3400e+06, -5.7211e+05],\n",
      "        [-3.2818e+06, -8.6922e+06, -7.8432e+05],\n",
      "        [-3.3184e+06, -8.7892e+06, -7.9306e+05],\n",
      "        [-5.0557e+06, -1.3391e+07, -1.2082e+06],\n",
      "        [-5.3370e+06, -1.4136e+07, -1.2754e+06],\n",
      "        [-5.4216e+06, -1.4360e+07, -1.2956e+06],\n",
      "        [-5.7761e+06, -1.5299e+07, -1.3803e+06],\n",
      "        [-8.2651e+06, -2.1891e+07, -1.9750e+06],\n",
      "        [-9.6469e+06, -2.5551e+07, -2.3051e+06],\n",
      "        [-1.0604e+07, -2.8087e+07, -2.5338e+06],\n",
      "        [-1.2356e+07, -3.2728e+07, -2.9525e+06],\n",
      "        [-2.3858e+07, -6.3192e+07, -5.7003e+06]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "-21:the loss_1 is : tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "--21: the result of GMM by hand: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-21:the loss_2 is : tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-21:the loss is : tensor([nan], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-22:target_unpadded shape: torch.Size([29, 3])\n",
      "-22:the m[i].log_prob(target_unpadded) is : tensor([[-3.7377e+02, -7.2961e+02, -6.3665e+01],\n",
      "        [-5.3407e+02, -1.0468e+03, -8.9544e+01],\n",
      "        [-1.4039e+03, -2.7734e+03, -2.2901e+02],\n",
      "        [-1.7644e+03, -3.4900e+03, -2.8658e+02],\n",
      "        [-2.3822e+03, -4.7192e+03, -3.8511e+02],\n",
      "        [-5.6655e+03, -1.1259e+04, -9.0716e+02],\n",
      "        [-1.0044e+04, -1.9990e+04, -1.6018e+03],\n",
      "        [-1.3832e+04, -2.7547e+04, -2.2020e+03],\n",
      "        [-2.1638e+04, -4.3124e+04, -3.4379e+03],\n",
      "        [-2.6071e+04, -5.1972e+04, -4.1394e+03],\n",
      "        [-2.8060e+04, -5.5945e+04, -4.4543e+03],\n",
      "        [-2.8314e+04, -5.6452e+04, -4.4944e+03],\n",
      "        [-3.1719e+04, -6.3248e+04, -5.0330e+03],\n",
      "        [-3.1989e+04, -6.3787e+04, -5.0757e+03],\n",
      "        [-3.4469e+04, -6.8740e+04, -5.4681e+03],\n",
      "        [-4.8594e+04, -9.6943e+04, -7.7016e+03],\n",
      "        [-5.1985e+04, -1.0371e+05, -8.2376e+03],\n",
      "        [-5.7285e+04, -1.1430e+05, -9.0755e+03],\n",
      "        [-6.1711e+04, -1.2314e+05, -9.7750e+03],\n",
      "        [-8.9446e+04, -1.7853e+05, -1.4158e+04],\n",
      "        [-9.1265e+04, -1.8216e+05, -1.4445e+04],\n",
      "        [-1.1864e+05, -2.3685e+05, -1.8770e+04],\n",
      "        [-1.1916e+05, -2.3789e+05, -1.8853e+04],\n",
      "        [-1.8092e+05, -3.6127e+05, -2.8607e+04],\n",
      "        [-2.0894e+05, -4.1725e+05, -3.3033e+04],\n",
      "        [-2.1311e+05, -4.2558e+05, -3.3691e+04],\n",
      "        [-2.4047e+05, -4.8023e+05, -3.8010e+04],\n",
      "        [-2.4195e+05, -4.8320e+05, -3.8245e+04],\n",
      "        [-3.6914e+05, -7.3734e+05, -5.8327e+04]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "-22:the loss_1 is : tensor([[0.0000e+00, 0.0000e+00, 2.2426e-28],\n",
      "        [0.0000e+00, 0.0000e+00, 1.2923e-39],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>)\n",
      "--22: the result of GMM by hand: tensor([1.2226e-28, 7.0452e-40, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "       device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-22:the loss_2 is : tensor([1.2226e-28, 7.0452e-40, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "       device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-22:the loss is : tensor([nan], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-23:target_unpadded shape: torch.Size([29, 3])\n",
      "-23:the m[i].log_prob(target_unpadded) is : tensor([[-1.7875e+00, -1.9107e+00, -2.2018e+00],\n",
      "        [-3.2894e+00, -5.3264e+00, -2.6287e+00],\n",
      "        [-5.5919e+00, -1.0821e+01, -3.2171e+00],\n",
      "        [-8.6952e+00, -1.8395e+01, -3.9670e+00],\n",
      "        [-1.2599e+01, -2.8048e+01, -4.8784e+00],\n",
      "        [-4.4131e+01, -1.0750e+02, -1.1857e+01],\n",
      "        [-9.5681e+01, -2.3893e+02, -2.2873e+01],\n",
      "        [-1.2191e+02, -3.0606e+02, -2.8409e+01],\n",
      "        [-1.6725e+02, -4.2234e+02, -3.7925e+01],\n",
      "        [-1.8397e+02, -4.6526e+02, -4.1420e+01],\n",
      "        [-2.1980e+02, -5.5734e+02, -4.8894e+01],\n",
      "        [-3.0108e+02, -7.6644e+02, -6.5780e+01],\n",
      "        [-3.4652e+02, -8.8347e+02, -7.5191e+01],\n",
      "        [-4.4702e+02, -1.1425e+03, -9.5953e+01],\n",
      "        [-5.9065e+02, -1.5130e+03, -1.2554e+02],\n",
      "        [-1.0578e+03, -2.7197e+03, -2.2135e+02],\n",
      "        [-1.0993e+03, -2.8270e+03, -2.2985e+02],\n",
      "        [-1.1848e+03, -3.0480e+03, -2.4733e+02],\n",
      "        [-1.7122e+03, -4.4121e+03, -3.5505e+02],\n",
      "        [-1.8185e+03, -4.6871e+03, -3.7673e+02],\n",
      "        [-2.0407e+03, -5.2622e+03, -4.2204e+02],\n",
      "        [-2.3365e+03, -6.0277e+03, -4.8230e+02],\n",
      "        [-2.5236e+03, -6.5120e+03, -5.2040e+02],\n",
      "        [-3.1992e+03, -8.2615e+03, -6.5788e+02],\n",
      "        [-4.0349e+03, -1.0426e+04, -8.2776e+02],\n",
      "        [-4.6171e+03, -1.1934e+04, -9.4604e+02],\n",
      "        [-4.7907e+03, -1.2384e+04, -9.8128e+02],\n",
      "        [-8.9346e+03, -2.3124e+04, -1.8219e+03],\n",
      "        [-9.6667e+03, -2.5022e+04, -1.9702e+03]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "-23:the loss_1 is : tensor([[1.6737e-01, 1.4798e-01, 1.1060e-01],\n",
      "        [3.7278e-02, 4.8615e-03, 7.2170e-02],\n",
      "        [3.7279e-03, 1.9971e-05, 4.0070e-02],\n",
      "        [1.6739e-04, 1.0258e-08, 1.8930e-02],\n",
      "        [3.3746e-06, 6.5879e-13, 7.6095e-03],\n",
      "        [6.8280e-20, 0.0000e+00, 7.0879e-06],\n",
      "        [2.7942e-42, 0.0000e+00, 1.1656e-10],\n",
      "        [0.0000e+00, 0.0000e+00, 4.5929e-13],\n",
      "        [0.0000e+00, 0.0000e+00, 3.3841e-17],\n",
      "        [0.0000e+00, 0.0000e+00, 1.0272e-18],\n",
      "        [0.0000e+00, 0.0000e+00, 5.8301e-22],\n",
      "        [0.0000e+00, 0.0000e+00, 2.7054e-29],\n",
      "        [0.0000e+00, 0.0000e+00, 2.2118e-33],\n",
      "        [0.0000e+00, 0.0000e+00, 2.1300e-42],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>)\n",
      "--23: the result of GMM by hand: tensor([1.3170e-01, 5.0426e-02, 2.3372e-02, 1.0655e-02, 4.2678e-03, 3.9745e-06,\n",
      "        6.5359e-11, 2.5754e-13, 1.8976e-17, 5.7598e-19, 3.2691e-22, 1.5170e-29,\n",
      "        1.2403e-33, 1.1939e-42, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "       device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-23:the loss_2 is : tensor([1.3170e-01, 5.0426e-02, 2.3372e-02, 1.0655e-02, 4.2678e-03, 3.9745e-06,\n",
      "        6.5360e-11, 2.5754e-13, 1.8976e-17, 5.7598e-19, 3.2691e-22, 1.5170e-29,\n",
      "        1.2403e-33, 1.1939e-42, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "       device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-23:the loss is : tensor([nan], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-24:target_unpadded shape: torch.Size([31, 3])\n",
      "-24:the m[i].log_prob(target_unpadded) is : tensor([[-2.1779e+01, -4.5333e+01, -7.9321e+00],\n",
      "        [-6.8395e+01, -1.5040e+02, -2.0226e+01],\n",
      "        [-8.9869e+01, -1.9913e+02, -2.5786e+01],\n",
      "        [-1.2764e+02, -2.8506e+02, -3.5496e+01],\n",
      "        [-2.0544e+02, -4.6255e+02, -5.5334e+01],\n",
      "        [-2.6102e+02, -5.8960e+02, -6.9430e+01],\n",
      "        [-3.9222e+02, -8.8994e+02, -1.0255e+02],\n",
      "        [-6.0870e+02, -1.3863e+03, -1.5695e+02],\n",
      "        [-1.1426e+03, -2.6125e+03, -2.9047e+02],\n",
      "        [-1.8960e+03, -4.3453e+03, -4.7821e+02],\n",
      "        [-2.3440e+03, -5.3761e+03, -5.8962e+02],\n",
      "        [-2.5858e+03, -5.9326e+03, -6.4971e+02],\n",
      "        [-2.6481e+03, -6.0760e+03, -6.6519e+02],\n",
      "        [-2.7111e+03, -6.2212e+03, -6.8085e+02],\n",
      "        [-2.7749e+03, -6.3680e+03, -6.9669e+02],\n",
      "        [-3.3119e+03, -7.6044e+03, -8.3003e+02],\n",
      "        [-3.8964e+03, -8.9504e+03, -9.7506e+02],\n",
      "        [-4.1278e+03, -9.4834e+03, -1.0325e+03],\n",
      "        [-4.2064e+03, -9.6645e+03, -1.0520e+03],\n",
      "        [-4.4467e+03, -1.0218e+04, -1.1116e+03],\n",
      "        [-4.5283e+03, -1.0406e+04, -1.1318e+03],\n",
      "        [-5.6565e+03, -1.3005e+04, -1.4114e+03],\n",
      "        [-5.9347e+03, -1.3646e+04, -1.4803e+03],\n",
      "        [-7.3210e+03, -1.6841e+04, -1.8237e+03],\n",
      "        [-1.0405e+04, -2.3951e+04, -2.5870e+03],\n",
      "        [-1.0655e+04, -2.4527e+04, -2.6488e+03],\n",
      "        [-1.0908e+04, -2.5110e+04, -2.7114e+03],\n",
      "        [-1.2762e+04, -2.9384e+04, -3.1698e+03],\n",
      "        [-1.5059e+04, -3.4680e+04, -3.7376e+03],\n",
      "        [-1.6591e+04, -3.8212e+04, -4.1163e+03],\n",
      "        [-3.0232e+04, -6.9676e+04, -7.4861e+03]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "-24:the loss_1 is : tensor([[3.4801e-10, 2.0523e-20, 3.5902e-04],\n",
      "        [1.9789e-30, 0.0000e+00, 1.6442e-09],\n",
      "        [9.3393e-40, 0.0000e+00, 6.3294e-12],\n",
      "        [0.0000e+00, 0.0000e+00, 3.8398e-16],\n",
      "        [0.0000e+00, 0.0000e+00, 9.3057e-25],\n",
      "        [0.0000e+00, 0.0000e+00, 7.0326e-31],\n",
      "        [0.0000e+00, 0.0000e+00, 2.8026e-45],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>)\n",
      "--24: the result of GMM by hand: tensor([1.8907e-04, 8.6587e-10, 3.3333e-12, 2.0222e-16, 4.9006e-25, 3.7036e-31,\n",
      "        1.4013e-45, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-24:the loss_2 is : tensor([1.8907e-04, 8.6586e-10, 3.3333e-12, 2.0222e-16, 4.9006e-25, 3.7036e-31,\n",
      "        1.4013e-45, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-24:the loss is : tensor([nan], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-25:target_unpadded shape: torch.Size([31, 3])\n",
      "-25:the m[i].log_prob(target_unpadded) is : tensor([[-1.6488e+01, -2.3648e+01, -5.5460e+00],\n",
      "        [-2.2579e+01, -3.3224e+01, -6.9150e+00],\n",
      "        [-4.6873e+01, -7.1932e+01, -1.2271e+01],\n",
      "        [-9.3310e+01, -1.4683e+02, -2.2327e+01],\n",
      "        [-2.3434e+02, -3.7647e+02, -5.2431e+01],\n",
      "        [-3.2894e+02, -5.3121e+02, -7.2480e+01],\n",
      "        [-4.3959e+02, -7.1256e+02, -9.5859e+01],\n",
      "        [-4.6976e+02, -7.6206e+02, -1.0222e+02],\n",
      "        [-7.8643e+02, -1.2824e+03, -1.6888e+02],\n",
      "        [-8.2664e+02, -1.3485e+03, -1.7733e+02],\n",
      "        [-1.0427e+03, -1.7041e+03, -2.2269e+02],\n",
      "        [-1.0889e+03, -1.7802e+03, -2.3238e+02],\n",
      "        [-1.4948e+03, -2.4490e+03, -3.1745e+02],\n",
      "        [-1.5501e+03, -2.5401e+03, -3.2902e+02],\n",
      "        [-1.6063e+03, -2.6328e+03, -3.4080e+02],\n",
      "        [-1.7219e+03, -2.8233e+03, -3.6498e+02],\n",
      "        [-2.0925e+03, -3.4347e+03, -4.4252e+02],\n",
      "        [-4.1160e+03, -6.7758e+03, -8.6512e+02],\n",
      "        [-4.4875e+03, -7.3897e+03, -9.4263e+02],\n",
      "        [-4.7766e+03, -7.8675e+03, -1.0029e+03],\n",
      "        [-5.2786e+03, -8.6972e+03, -1.1076e+03],\n",
      "        [-5.8057e+03, -9.5684e+03, -1.2175e+03],\n",
      "        [-6.1340e+03, -1.0111e+04, -1.2860e+03],\n",
      "        [-6.2455e+03, -1.0295e+04, -1.3092e+03],\n",
      "        [-6.8177e+03, -1.1241e+04, -1.4285e+03],\n",
      "        [-8.8174e+03, -1.4548e+04, -1.8451e+03],\n",
      "        [-9.7730e+03, -1.6129e+04, -2.0441e+03],\n",
      "        [-1.0631e+04, -1.7549e+04, -2.2228e+03],\n",
      "        [-1.2456e+04, -2.0568e+04, -2.6027e+03],\n",
      "        [-1.3920e+04, -2.2990e+04, -2.9073e+03],\n",
      "        [-1.4087e+04, -2.3267e+04, -2.9422e+03]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "-25:the loss_1 is : tensor([[6.9074e-08, 5.3664e-11, 3.9030e-03],\n",
      "        [1.5628e-10, 3.7233e-15, 9.9282e-04],\n",
      "        [4.3991e-21, 5.7585e-32, 4.6862e-06],\n",
      "        [2.9914e-41, 0.0000e+00, 2.0121e-10],\n",
      "        [0.0000e+00, 0.0000e+00, 1.6962e-23],\n",
      "        [0.0000e+00, 0.0000e+00, 3.3303e-32],\n",
      "        [0.0000e+00, 0.0000e+00, 2.3388e-42],\n",
      "        [0.0000e+00, 0.0000e+00, 4.2039e-45],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>)\n",
      "--25: the result of GMM by hand: tensor([2.0473e-03, 5.2077e-04, 2.4581e-06, 1.0554e-10, 8.8971e-24, 1.7468e-32,\n",
      "        1.2261e-42, 2.8026e-45, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-25:the loss_2 is : tensor([2.0473e-03, 5.2077e-04, 2.4581e-06, 1.0554e-10, 8.8971e-24, 1.7468e-32,\n",
      "        1.2261e-42, 2.8026e-45, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-25:the loss is : tensor([nan], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-26:target_unpadded shape: torch.Size([32, 3])\n",
      "-26:the m[i].log_prob(target_unpadded) is : tensor([[-1.4520e+01, -2.5343e+01, -4.8775e+00],\n",
      "        [-3.3681e+01, -6.2206e+01, -8.6320e+00],\n",
      "        [-4.1913e+01, -7.8169e+01, -1.0213e+01],\n",
      "        [-1.4099e+02, -2.7201e+02, -2.8800e+01],\n",
      "        [-1.5753e+02, -3.0450e+02, -3.1866e+01],\n",
      "        [-1.7499e+02, -3.3884e+02, -3.5096e+01],\n",
      "        [-1.9337e+02, -3.7501e+02, -3.8491e+01],\n",
      "        [-2.9912e+02, -5.8342e+02, -5.7941e+01],\n",
      "        [-4.8594e+02, -9.5236e+02, -9.2097e+01],\n",
      "        [-6.1299e+02, -1.2036e+03, -1.1524e+02],\n",
      "        [-8.3124e+02, -1.6356e+03, -1.5491e+02],\n",
      "        [-9.9520e+02, -1.9603e+03, -1.8465e+02],\n",
      "        [-1.3674e+03, -2.6980e+03, -2.5205e+02],\n",
      "        [-1.6300e+03, -3.2187e+03, -2.9953e+02],\n",
      "        [-1.6853e+03, -3.3284e+03, -3.0952e+02],\n",
      "        [-2.4881e+03, -4.9211e+03, -4.5442e+02],\n",
      "        [-2.9850e+03, -5.9073e+03, -5.4398e+02],\n",
      "        [-3.0596e+03, -6.0556e+03, -5.5743e+02],\n",
      "        [-4.3799e+03, -8.6773e+03, -7.9513e+02],\n",
      "        [-5.7288e+03, -1.1357e+04, -1.0377e+03],\n",
      "        [-6.2544e+03, -1.2401e+04, -1.1322e+03],\n",
      "        [-6.6915e+03, -1.3270e+04, -1.2108e+03],\n",
      "        [-7.9697e+03, -1.5810e+04, -1.4404e+03],\n",
      "        [-8.8412e+03, -1.7542e+04, -1.5969e+03],\n",
      "        [-9.2285e+03, -1.8312e+04, -1.6665e+03],\n",
      "        [-9.8925e+03, -1.9632e+04, -1.7857e+03],\n",
      "        [-1.0302e+04, -2.0446e+04, -1.8592e+03],\n",
      "        [-1.1146e+04, -2.2124e+04, -2.0107e+03],\n",
      "        [-1.7084e+04, -3.3930e+04, -3.0759e+03],\n",
      "        [-2.4074e+04, -4.7832e+04, -4.3290e+03],\n",
      "        [-2.6228e+04, -5.2116e+04, -4.7151e+03],\n",
      "        [-2.9632e+04, -5.8886e+04, -5.3250e+03]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "-26:the loss_1 is : tensor([[4.9431e-07, 9.8562e-12, 7.6164e-03],\n",
      "        [2.3590e-15, 9.6399e-28, 1.7831e-04],\n",
      "        [6.2730e-19, 1.1266e-34, 3.6679e-05],\n",
      "        [0.0000e+00, 0.0000e+00, 3.1057e-13],\n",
      "        [0.0000e+00, 0.0000e+00, 1.4483e-14],\n",
      "        [0.0000e+00, 0.0000e+00, 5.7271e-16],\n",
      "        [0.0000e+00, 0.0000e+00, 1.9204e-17],\n",
      "        [0.0000e+00, 0.0000e+00, 6.8619e-26],\n",
      "        [0.0000e+00, 0.0000e+00, 1.0065e-40],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>)\n",
      "--26: the result of GMM by hand: tensor([4.0994e-03, 9.5969e-05, 1.9741e-05, 1.6715e-13, 7.7949e-15, 3.0824e-16,\n",
      "        1.0336e-17, 3.6931e-26, 5.4170e-41, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-26:the loss_2 is : tensor([4.0994e-03, 9.5969e-05, 1.9741e-05, 1.6716e-13, 7.7950e-15, 3.0824e-16,\n",
      "        1.0336e-17, 3.6932e-26, 5.4170e-41, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-26:the loss is : tensor([nan], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-27:target_unpadded shape: torch.Size([32, 3])\n",
      "-27:the m[i].log_prob(target_unpadded) is : tensor([[-1.8673e+01, -4.1876e+01, -7.1853e+00],\n",
      "        [-8.9483e+01, -2.1172e+02, -2.6317e+01],\n",
      "        [-1.0214e+02, -2.4219e+02, -2.9672e+01],\n",
      "        [-1.1564e+02, -2.7471e+02, -3.3242e+01],\n",
      "        [-1.9585e+02, -4.6808e+02, -5.4303e+01],\n",
      "        [-3.6817e+02, -8.8418e+02, -9.9142e+01],\n",
      "        [-4.4675e+02, -1.0741e+03, -1.1949e+02],\n",
      "        [-6.5970e+02, -1.5890e+03, -1.7447e+02],\n",
      "        [-8.0000e+02, -1.9284e+03, -2.1060e+02],\n",
      "        [-5.3506e+03, -1.2951e+04, -1.3734e+03],\n",
      "        [-7.4225e+03, -1.7973e+04, -1.9011e+03],\n",
      "        [-7.5349e+03, -1.8245e+04, -1.9297e+03],\n",
      "        [-8.1100e+03, -1.9639e+04, -2.0761e+03],\n",
      "        [-8.2276e+03, -1.9924e+04, -2.1060e+03],\n",
      "        [-8.3460e+03, -2.0211e+04, -2.1361e+03],\n",
      "        [-1.1721e+04, -2.8393e+04, -2.9948e+03],\n",
      "        [-1.2147e+04, -2.9426e+04, -3.1032e+03],\n",
      "        [-1.2875e+04, -3.1190e+04, -3.2881e+03],\n",
      "        [-1.4549e+04, -3.5249e+04, -3.7139e+03],\n",
      "        [-1.5832e+04, -3.8358e+04, -4.0398e+03],\n",
      "        [-1.6493e+04, -3.9961e+04, -4.2078e+03],\n",
      "        [-1.7856e+04, -4.3267e+04, -4.5543e+03],\n",
      "        [-2.2466e+04, -5.4443e+04, -5.7254e+03],\n",
      "        [-2.5278e+04, -6.1262e+04, -6.4397e+03],\n",
      "        [-2.7388e+04, -6.6379e+04, -6.9756e+03],\n",
      "        [-2.9137e+04, -7.0621e+04, -7.4197e+03],\n",
      "        [-2.9360e+04, -7.1160e+04, -7.4762e+03],\n",
      "        [-3.5932e+04, -8.7096e+04, -9.1447e+03],\n",
      "        [-3.8439e+04, -9.3178e+04, -9.7813e+03],\n",
      "        [-4.3437e+04, -1.0530e+05, -1.1050e+04],\n",
      "        [-9.2032e+04, -2.2315e+05, -2.3378e+04],\n",
      "        [-9.6828e+04, -2.3478e+05, -2.4594e+04]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "-27:the loss_1 is : tensor([[7.7732e-09, 6.5088e-19, 7.5765e-04],\n",
      "        [1.3746e-39, 0.0000e+00, 3.7224e-12],\n",
      "        [4.2039e-45, 0.0000e+00, 1.2989e-13],\n",
      "        [0.0000e+00, 0.0000e+00, 3.6584e-15],\n",
      "        [0.0000e+00, 0.0000e+00, 2.6081e-24],\n",
      "        [0.0000e+00, 0.0000e+00, 8.8282e-44],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>)\n",
      "--27: the result of GMM by hand: tensor([3.9812e-04, 1.9560e-12, 6.8252e-14, 1.9223e-15, 1.3705e-24, 4.6243e-44,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-27:the loss_2 is : tensor([3.9812e-04, 1.9560e-12, 6.8252e-14, 1.9223e-15, 1.3705e-24, 4.6243e-44,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-27:the loss is : tensor([nan], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-28:target_unpadded shape: torch.Size([35, 3])\n",
      "-28:the m[i].log_prob(target_unpadded) is : tensor([[-4.2005e+01, -9.7561e+01, -1.5055e+01],\n",
      "        [-1.9067e+02, -4.5357e+02, -5.9013e+01],\n",
      "        [-4.4799e+02, -1.0712e+03, -1.3363e+02],\n",
      "        [-6.1741e+02, -1.4781e+03, -1.8244e+02],\n",
      "        [-8.8555e+02, -2.1223e+03, -2.5944e+02],\n",
      "        [-1.1183e+03, -2.6818e+03, -3.2614e+02],\n",
      "        [-1.9255e+03, -4.6222e+03, -5.5674e+02],\n",
      "        [-2.7539e+03, -6.6144e+03, -7.9285e+02],\n",
      "        [-2.8843e+03, -6.9280e+03, -8.2998e+02],\n",
      "        [-3.0178e+03, -7.2490e+03, -8.6797e+02],\n",
      "        [-3.5086e+03, -8.4295e+03, -1.0076e+03],\n",
      "        [-4.0364e+03, -9.6989e+03, -1.1577e+03],\n",
      "        [-4.8545e+03, -1.1667e+04, -1.3903e+03],\n",
      "        [-5.2029e+03, -1.2505e+04, -1.4892e+03],\n",
      "        [-6.6168e+03, -1.5907e+04, -1.8907e+03],\n",
      "        [-6.9200e+03, -1.6636e+04, -1.9768e+03],\n",
      "        [-7.0225e+03, -1.6883e+04, -2.0059e+03],\n",
      "        [-8.8816e+03, -2.1355e+04, -2.5333e+03],\n",
      "        [-1.0576e+04, -2.5433e+04, -3.0139e+03],\n",
      "        [-1.2147e+04, -2.9212e+04, -3.4590e+03],\n",
      "        [-1.3254e+04, -3.1876e+04, -3.7728e+03],\n",
      "        [-1.3682e+04, -3.2905e+04, -3.8940e+03],\n",
      "        [-1.4262e+04, -3.4303e+04, -4.0585e+03],\n",
      "        [-1.7025e+04, -4.0952e+04, -4.8412e+03],\n",
      "        [-1.7186e+04, -4.1338e+04, -4.8867e+03],\n",
      "        [-2.8001e+04, -6.7365e+04, -7.9484e+03],\n",
      "        [-3.2263e+04, -7.7623e+04, -9.1544e+03],\n",
      "        [-3.4966e+04, -8.4126e+04, -9.9190e+03],\n",
      "        [-3.8496e+04, -9.2624e+04, -1.0918e+04],\n",
      "        [-4.5803e+04, -1.1021e+05, -1.2985e+04],\n",
      "        [-5.0658e+04, -1.2190e+05, -1.4357e+04],\n",
      "        [-7.8599e+04, -1.8915e+05, -2.2257e+04],\n",
      "        [-8.0331e+04, -1.9331e+05, -2.2746e+04],\n",
      "        [-9.3730e+04, -2.2557e+05, -2.6534e+04],\n",
      "        [-2.0295e+05, -4.8847e+05, -5.7393e+04]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "-28:the loss_1 is : tensor([[5.7210e-19, 4.2599e-43, 2.8941e-07],\n",
      "        [0.0000e+00, 0.0000e+00, 2.3487e-26],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>)\n",
      "--28: the result of GMM by hand: tensor([1.4706e-07, 1.1935e-26, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "       device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-28:the loss_2 is : tensor([1.4706e-07, 1.1935e-26, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "       device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-28:the loss is : tensor([nan], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-29:target_unpadded shape: torch.Size([36, 3])\n",
      "-29:the m[i].log_prob(target_unpadded) is : tensor([[-2.3190e+03, -5.8258e+03, -6.0230e+02],\n",
      "        [-2.8434e+03, -7.1470e+03, -7.3707e+02],\n",
      "        [-1.0228e+04, -2.5765e+04, -2.6298e+03],\n",
      "        [-1.0359e+04, -2.6096e+04, -2.6633e+03],\n",
      "        [-1.3009e+04, -3.2779e+04, -3.3415e+03],\n",
      "        [-5.5781e+04, -1.4070e+05, -1.4273e+04],\n",
      "        [-6.2374e+04, -1.5734e+05, -1.5957e+04],\n",
      "        [-6.8657e+04, -1.7320e+05, -1.7562e+04],\n",
      "        [-7.0704e+04, -1.7836e+05, -1.8085e+04],\n",
      "        [-7.5242e+04, -1.8981e+05, -1.9244e+04],\n",
      "        [-7.9192e+04, -1.9978e+05, -2.0252e+04],\n",
      "        [-1.1751e+05, -2.9649e+05, -3.0036e+04],\n",
      "        [-1.3925e+05, -3.5137e+05, -3.5587e+04],\n",
      "        [-1.5157e+05, -3.8246e+05, -3.8731e+04],\n",
      "        [-1.5767e+05, -3.9785e+05, -4.0288e+04],\n",
      "        [-1.8215e+05, -4.5966e+05, -4.6539e+04],\n",
      "        [-1.9335e+05, -4.8792e+05, -4.9397e+04],\n",
      "        [-3.0060e+05, -7.5865e+05, -7.6770e+04],\n",
      "        [-3.0917e+05, -7.8026e+05, -7.8955e+04],\n",
      "        [-3.6229e+05, -9.1436e+05, -9.2512e+04],\n",
      "        [-3.6932e+05, -9.3211e+05, -9.4307e+04],\n",
      "        [-3.9245e+05, -9.9049e+05, -1.0021e+05],\n",
      "        [-4.3482e+05, -1.0975e+06, -1.1102e+05],\n",
      "        [-4.4943e+05, -1.1343e+06, -1.1475e+05],\n",
      "        [-4.6164e+05, -1.1652e+06, -1.1786e+05],\n",
      "        [-4.9834e+05, -1.2578e+06, -1.2723e+05],\n",
      "        [-5.0751e+05, -1.2809e+06, -1.2957e+05],\n",
      "        [-5.6814e+05, -1.4340e+06, -1.4504e+05],\n",
      "        [-6.0274e+05, -1.5214e+06, -1.5387e+05],\n",
      "        [-7.7283e+05, -1.9507e+06, -1.9726e+05],\n",
      "        [-1.1291e+06, -2.8503e+06, -2.8817e+05],\n",
      "        [-1.1735e+06, -2.9623e+06, -2.9949e+05],\n",
      "        [-1.2216e+06, -3.0837e+06, -3.1176e+05],\n",
      "        [-1.2431e+06, -3.1380e+06, -3.1725e+05],\n",
      "        [-1.3177e+06, -3.3262e+06, -3.3627e+05],\n",
      "        [-1.3641e+06, -3.4433e+06, -3.4810e+05]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "-29:the loss_1 is : tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "--29: the result of GMM by hand: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
      "       grad_fn=<SumBackward1>)\n",
      "-29:the loss_2 is : tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
      "       grad_fn=<SumBackward1>)\n",
      "-29:the loss is : tensor([nan], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-30:target_unpadded shape: torch.Size([38, 3])\n",
      "-30:the m[i].log_prob(target_unpadded) is : tensor([[-2.3932e+03, -7.5142e+03, -4.5847e+02],\n",
      "        [-3.8089e+03, -1.1969e+04, -7.2532e+02],\n",
      "        [-5.3631e+03, -1.6862e+04, -1.0177e+03],\n",
      "        [-7.1827e+03, -2.2591e+04, -1.3597e+03],\n",
      "        [-1.1073e+04, -3.4840e+04, -2.0899e+03],\n",
      "        [-1.3779e+04, -4.3364e+04, -2.5975e+03],\n",
      "        [-1.4540e+04, -4.5761e+04, -2.7402e+03],\n",
      "        [-1.5322e+04, -4.8224e+04, -2.8868e+03],\n",
      "        [-2.5274e+04, -7.9570e+04, -4.7512e+03],\n",
      "        [-2.5478e+04, -8.0212e+04, -4.7893e+03],\n",
      "        [-4.0744e+04, -1.2830e+05, -7.6470e+03],\n",
      "        [-4.1262e+04, -1.2994e+05, -7.7440e+03],\n",
      "        [-5.3790e+04, -1.6941e+05, -1.0088e+04],\n",
      "        [-1.2542e+05, -3.9510e+05, -2.3481e+04],\n",
      "        [-1.2587e+05, -3.9653e+05, -2.3565e+04],\n",
      "        [-1.4518e+05, -4.5736e+05, -2.7173e+04],\n",
      "        [-1.9804e+05, -6.2393e+05, -3.7051e+04],\n",
      "        [-2.2571e+05, -7.1113e+05, -4.2221e+04],\n",
      "        [-2.4054e+05, -7.5786e+05, -4.4992e+04],\n",
      "        [-2.4877e+05, -7.8379e+05, -4.6529e+04],\n",
      "        [-3.0035e+05, -9.4633e+05, -5.6165e+04],\n",
      "        [-4.2723e+05, -1.3462e+06, -7.9864e+04],\n",
      "        [-4.5528e+05, -1.4346e+06, -8.5103e+04],\n",
      "        [-4.6221e+05, -1.4564e+06, -8.6398e+04],\n",
      "        [-4.7624e+05, -1.5006e+06, -8.9018e+04],\n",
      "        [-4.8511e+05, -1.5286e+06, -9.0675e+04],\n",
      "        [-5.2512e+05, -1.6547e+06, -9.8148e+04],\n",
      "        [-5.3257e+05, -1.6781e+06, -9.9539e+04],\n",
      "        [-6.0095e+05, -1.8936e+06, -1.1231e+05],\n",
      "        [-6.3311e+05, -1.9950e+06, -1.1832e+05],\n",
      "        [-1.7082e+06, -5.3830e+06, -3.1904e+05],\n",
      "        [-2.7013e+06, -8.5129e+06, -5.0445e+05],\n",
      "        [-3.0797e+06, -9.7055e+06, -5.7508e+05],\n",
      "        [-6.3968e+06, -2.0160e+07, -1.1943e+06],\n",
      "        [-6.6683e+06, -2.1016e+07, -1.2449e+06],\n",
      "        [-7.2799e+06, -2.2943e+07, -1.3591e+06],\n",
      "        [-1.3166e+07, -4.1495e+07, -2.4578e+06],\n",
      "        [-1.3782e+07, -4.3435e+07, -2.5727e+06]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "-30:the loss_1 is : tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "--30: the result of GMM by hand: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-30:the loss_2 is : tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-30:the loss is : tensor([nan], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-31:target_unpadded shape: torch.Size([38, 3])\n",
      "-31:the m[i].log_prob(target_unpadded) is : tensor([[-9.6830e+04, -2.0796e+05, -2.4669e+04],\n",
      "        [-1.0433e+05, -2.2407e+05, -2.6578e+04],\n",
      "        [-1.5316e+05, -3.2897e+05, -3.8998e+04],\n",
      "        [-2.1557e+05, -4.6308e+05, -5.4873e+04],\n",
      "        [-2.3554e+05, -5.0599e+05, -5.9952e+04],\n",
      "        [-3.2953e+05, -7.0793e+05, -8.3853e+04],\n",
      "        [-4.4275e+05, -9.5121e+05, -1.1264e+05],\n",
      "        [-1.8497e+06, -3.9745e+06, -4.7030e+05],\n",
      "        [-1.9055e+06, -4.0945e+06, -4.8449e+05],\n",
      "        [-2.1352e+06, -4.5881e+06, -5.4287e+05],\n",
      "        [-2.8337e+06, -6.0892e+06, -7.2042e+05],\n",
      "        [-2.9500e+06, -6.3389e+06, -7.4996e+05],\n",
      "        [-3.0364e+06, -6.5246e+06, -7.7192e+05],\n",
      "        [-3.1171e+06, -6.6980e+06, -7.9243e+05],\n",
      "        [-4.1867e+06, -8.9966e+06, -1.0643e+06],\n",
      "        [-4.3770e+06, -9.4057e+06, -1.1127e+06],\n",
      "        [-5.2318e+06, -1.1243e+07, -1.3299e+06],\n",
      "        [-6.0330e+06, -1.2964e+07, -1.5335e+06],\n",
      "        [-6.9604e+06, -1.4957e+07, -1.7692e+06],\n",
      "        [-7.7405e+06, -1.6634e+07, -1.9675e+06],\n",
      "        [-8.6237e+06, -1.8532e+07, -2.1920e+06],\n",
      "        [-9.0061e+06, -1.9353e+07, -2.2891e+06],\n",
      "        [-9.1288e+06, -1.9617e+07, -2.3203e+06],\n",
      "        [-9.5140e+06, -2.0445e+07, -2.4182e+06],\n",
      "        [-9.6687e+06, -2.0777e+07, -2.4575e+06],\n",
      "        [-1.1051e+07, -2.3749e+07, -2.8089e+06],\n",
      "        [-1.1843e+07, -2.5449e+07, -3.0100e+06],\n",
      "        [-1.2387e+07, -2.6619e+07, -3.1484e+06],\n",
      "        [-1.2615e+07, -2.7109e+07, -3.2063e+06],\n",
      "        [-1.4672e+07, -3.1529e+07, -3.7290e+06],\n",
      "        [-1.4737e+07, -3.1670e+07, -3.7457e+06],\n",
      "        [-1.4955e+07, -3.2138e+07, -3.8010e+06],\n",
      "        [-1.8121e+07, -3.8942e+07, -4.6056e+06],\n",
      "        [-1.8623e+07, -4.0019e+07, -4.7330e+06],\n",
      "        [-2.0500e+07, -4.4053e+07, -5.2101e+06],\n",
      "        [-2.0834e+07, -4.4772e+07, -5.2951e+06],\n",
      "        [-2.6896e+07, -5.7799e+07, -6.8356e+06],\n",
      "        [-2.8291e+07, -6.0796e+07, -7.1900e+06]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "-31:the loss_1 is : tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "--31: the result of GMM by hand: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-31:the loss_2 is : tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-31:the loss is : tensor([nan], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-32:target_unpadded shape: torch.Size([45, 3])\n",
      "-32:the m[i].log_prob(target_unpadded) is : tensor([[-2.6168e+01, -4.7964e+01, -7.2250e+00],\n",
      "        [-3.3420e+01, -6.2055e+01, -8.6434e+00],\n",
      "        [-4.1588e+01, -7.7979e+01, -1.0227e+01],\n",
      "        [-5.0672e+01, -9.5736e+01, -1.1975e+01],\n",
      "        [-6.0672e+01, -1.1533e+02, -1.3889e+01],\n",
      "        [-3.4522e+02, -6.7804e+02, -6.6957e+01],\n",
      "        [-4.2467e+02, -8.3579e+02, -8.1612e+01],\n",
      "        [-4.5298e+02, -8.9204e+02, -8.6827e+01],\n",
      "        [-4.8221e+02, -9.5012e+02, -9.2207e+01],\n",
      "        [-6.0830e+02, -1.2008e+03, -1.1538e+02],\n",
      "        [-6.4211e+02, -1.2680e+03, -1.2158e+02],\n",
      "        [-6.7684e+02, -1.3371e+03, -1.2795e+02],\n",
      "        [-7.8651e+02, -1.5553e+03, -1.4806e+02],\n",
      "        [-8.6420e+02, -1.7100e+03, -1.6228e+02],\n",
      "        [-9.4556e+02, -1.8720e+03, -1.7717e+02],\n",
      "        [-1.0745e+03, -2.1287e+03, -2.0074e+02],\n",
      "        [-1.3570e+03, -2.6916e+03, -2.5233e+02],\n",
      "        [-2.1445e+03, -4.2618e+03, -3.9583e+02],\n",
      "        [-2.3366e+03, -4.6450e+03, -4.3079e+02],\n",
      "        [-2.9623e+03, -5.8936e+03, -5.4458e+02],\n",
      "        [-3.5808e+03, -7.1281e+03, -6.5695e+02],\n",
      "        [-4.5269e+03, -9.0170e+03, -8.2871e+02],\n",
      "        [-4.8042e+03, -9.5707e+03, -8.7902e+02],\n",
      "        [-4.9936e+03, -9.9489e+03, -9.1339e+02],\n",
      "        [-5.8913e+03, -1.1742e+04, -1.0762e+03],\n",
      "        [-6.6408e+03, -1.3239e+04, -1.2121e+03],\n",
      "        [-7.3190e+03, -1.4594e+04, -1.3350e+03],\n",
      "        [-8.0301e+03, -1.6015e+04, -1.4638e+03],\n",
      "        [-8.3980e+03, -1.6750e+04, -1.5305e+03],\n",
      "        [-8.7742e+03, -1.7501e+04, -1.5986e+03],\n",
      "        [-1.0500e+04, -2.0949e+04, -1.9111e+03],\n",
      "        [-1.1204e+04, -2.2357e+04, -2.0387e+03],\n",
      "        [-1.1638e+04, -2.3225e+04, -2.1172e+03],\n",
      "        [-1.2229e+04, -2.4406e+04, -2.2242e+03],\n",
      "        [-1.5914e+04, -3.1771e+04, -2.8909e+03],\n",
      "        [-1.6257e+04, -3.2457e+04, -2.9530e+03],\n",
      "        [-2.1053e+04, -4.2045e+04, -3.8203e+03],\n",
      "        [-2.3475e+04, -4.6888e+04, -4.2583e+03],\n",
      "        [-2.6689e+04, -5.3313e+04, -4.8392e+03],\n",
      "        [-2.8487e+04, -5.6908e+04, -5.1641e+03],\n",
      "        [-2.9408e+04, -5.8750e+04, -5.3306e+03],\n",
      "        [-3.6523e+04, -7.2979e+04, -6.6164e+03],\n",
      "        [-4.1052e+04, -8.2037e+04, -7.4346e+03],\n",
      "        [-5.1517e+04, -1.0297e+05, -9.3249e+03],\n",
      "        [-6.9440e+04, -1.3882e+05, -1.2562e+04]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "-32:the loss_1 is : tensor([[4.3208e-12, 1.4781e-21, 7.2816e-04],\n",
      "        [3.0614e-15, 1.1221e-27, 1.7629e-04],\n",
      "        [8.6803e-19, 1.3625e-34, 3.6185e-05],\n",
      "        [9.8499e-23, 2.6457e-42, 6.2971e-06],\n",
      "        [4.4730e-27, 0.0000e+00, 9.2910e-07],\n",
      "        [0.0000e+00, 0.0000e+00, 8.3375e-30],\n",
      "        [0.0000e+00, 0.0000e+00, 3.6021e-36],\n",
      "        [0.0000e+00, 0.0000e+00, 1.9574e-38],\n",
      "        [0.0000e+00, 0.0000e+00, 9.0183e-41],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>)\n",
      "--32: the result of GMM by hand: tensor([3.9201e-04, 9.4905e-05, 1.9480e-05, 3.3901e-06, 5.0019e-07, 4.4885e-30,\n",
      "        1.9392e-36, 1.0538e-38, 4.8551e-41, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00], device='cuda:0',\n",
      "       grad_fn=<SumBackward1>)\n",
      "-32:the loss_2 is : tensor([3.9201e-04, 9.4905e-05, 1.9480e-05, 3.3901e-06, 5.0019e-07, 4.4885e-30,\n",
      "        1.9392e-36, 1.0538e-38, 4.8551e-41, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00], device='cuda:0',\n",
      "       grad_fn=<SumBackward1>)\n",
      "-32:the loss is : tensor([nan], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-33:target_unpadded shape: torch.Size([46, 3])\n",
      "-33:the m[i].log_prob(target_unpadded) is : tensor([[-9.9063e+03, -2.2225e+04, -1.6392e+03],\n",
      "        [-3.0492e+04, -6.8438e+04, -5.0177e+03],\n",
      "        [-7.7838e+04, -1.7474e+05, -1.2775e+04],\n",
      "        [-8.5123e+04, -1.9110e+05, -1.3969e+04],\n",
      "        [-1.2431e+05, -2.7910e+05, -2.0386e+04],\n",
      "        [-2.4602e+05, -5.5238e+05, -4.0305e+04],\n",
      "        [-3.3914e+05, -7.6148e+05, -5.5541e+04],\n",
      "        [-5.1808e+05, -1.1633e+06, -8.4812e+04],\n",
      "        [-6.1051e+05, -1.3708e+06, -9.9931e+04],\n",
      "        [-9.1309e+05, -2.0503e+06, -1.4942e+05],\n",
      "        [-9.8924e+05, -2.2213e+06, -1.6187e+05],\n",
      "        [-9.9972e+05, -2.2448e+06, -1.6359e+05],\n",
      "        [-1.0793e+06, -2.4236e+06, -1.7661e+05],\n",
      "        [-1.3644e+06, -3.0637e+06, -2.2322e+05],\n",
      "        [-2.0798e+06, -4.6702e+06, -3.4020e+05],\n",
      "        [-2.4501e+06, -5.5019e+06, -4.0076e+05],\n",
      "        [-2.4713e+06, -5.5495e+06, -4.0423e+05],\n",
      "        [-2.4784e+06, -5.5654e+06, -4.0539e+05],\n",
      "        [-3.0678e+06, -6.8889e+06, -5.0175e+05],\n",
      "        [-3.3971e+06, -7.6284e+06, -5.5559e+05],\n",
      "        [-3.5059e+06, -7.8727e+06, -5.7338e+05],\n",
      "        [-3.9434e+06, -8.8551e+06, -6.4491e+05],\n",
      "        [-4.0787e+06, -9.1590e+06, -6.6703e+05],\n",
      "        [-4.9388e+06, -1.1090e+07, -8.0764e+05],\n",
      "        [-4.9555e+06, -1.1128e+07, -8.1037e+05],\n",
      "        [-5.4101e+06, -1.2149e+07, -8.8470e+05],\n",
      "        [-5.8338e+06, -1.3100e+07, -9.5396e+05],\n",
      "        [-6.3111e+06, -1.4172e+07, -1.0320e+06],\n",
      "        [-6.5126e+06, -1.4625e+07, -1.0649e+06],\n",
      "        [-6.5587e+06, -1.4728e+07, -1.0725e+06],\n",
      "        [-6.9648e+06, -1.5640e+07, -1.1389e+06],\n",
      "        [-8.9881e+06, -2.0184e+07, -1.4696e+06],\n",
      "        [-9.2010e+06, -2.0662e+07, -1.5044e+06],\n",
      "        [-1.0025e+07, -2.2512e+07, -1.6391e+06],\n",
      "        [-1.0805e+07, -2.4264e+07, -1.7667e+06],\n",
      "        [-1.2709e+07, -2.8539e+07, -2.0779e+06],\n",
      "        [-1.3836e+07, -3.1069e+07, -2.2621e+06],\n",
      "        [-1.8679e+07, -4.1945e+07, -3.0538e+06],\n",
      "        [-2.2483e+07, -5.0488e+07, -3.6757e+06],\n",
      "        [-2.3157e+07, -5.2002e+07, -3.7859e+06],\n",
      "        [-4.2861e+07, -9.6249e+07, -7.0067e+06],\n",
      "        [-4.3215e+07, -9.7045e+07, -7.0646e+06],\n",
      "        [-6.2575e+07, -1.4052e+08, -1.0229e+07],\n",
      "        [-1.1717e+08, -2.6313e+08, -1.9154e+07],\n",
      "        [-2.4962e+08, -5.6056e+08, -4.0803e+07],\n",
      "        [-4.8577e+08, -1.0909e+09, -7.9402e+07]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "-33:the loss_1 is : tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "--33: the result of GMM by hand: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-33:the loss_2 is : tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-33:the loss is : tensor([nan], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-34:target_unpadded shape: torch.Size([47, 3])\n",
      "-34:the m[i].log_prob(target_unpadded) is : tensor([[-3.7568e+01, -9.7710e+01, -1.5924e+01],\n",
      "        [-1.5558e+02, -4.1377e+02, -5.7850e+01],\n",
      "        [-2.3623e+02, -6.2995e+02, -8.6052e+01],\n",
      "        [-4.0037e+02, -1.0701e+03, -1.4306e+02],\n",
      "        [-6.0772e+02, -1.6263e+03, -2.1471e+02],\n",
      "        [-6.9661e+02, -1.8648e+03, -2.4534e+02],\n",
      "        [-8.5827e+02, -2.2985e+03, -3.0098e+02],\n",
      "        [-8.9263e+02, -2.3907e+03, -3.1279e+02],\n",
      "        [-9.2766e+02, -2.4847e+03, -3.2483e+02],\n",
      "        [-1.1129e+03, -2.9819e+03, -3.8847e+02],\n",
      "        [-1.1918e+03, -3.1934e+03, -4.1553e+02],\n",
      "        [-1.3576e+03, -3.6383e+03, -4.7238e+02],\n",
      "        [-1.4890e+03, -3.9910e+03, -5.1742e+02],\n",
      "        [-1.8692e+03, -5.0113e+03, -6.4759e+02],\n",
      "        [-2.2925e+03, -6.1476e+03, -7.9239e+02],\n",
      "        [-2.8205e+03, -7.5646e+03, -9.7278e+02],\n",
      "        [-3.3357e+03, -8.9474e+03, -1.1487e+03],\n",
      "        [-4.0404e+03, -1.0839e+04, -1.3891e+03],\n",
      "        [-4.2650e+03, -1.1442e+04, -1.4657e+03],\n",
      "        [-5.0575e+03, -1.3569e+04, -1.7359e+03],\n",
      "        [-5.1405e+03, -1.3792e+04, -1.7641e+03],\n",
      "        [-6.6542e+03, -1.7856e+04, -2.2798e+03],\n",
      "        [-7.4340e+03, -1.9949e+04, -2.5453e+03],\n",
      "        [-9.9167e+03, -2.6614e+04, -3.3901e+03],\n",
      "        [-1.0985e+04, -2.9483e+04, -3.7536e+03],\n",
      "        [-1.1728e+04, -3.1478e+04, -4.0062e+03],\n",
      "        [-1.2757e+04, -3.4238e+04, -4.3559e+03],\n",
      "        [-1.5516e+04, -4.1648e+04, -5.2940e+03],\n",
      "        [-1.5807e+04, -4.2428e+04, -5.3928e+03],\n",
      "        [-1.7149e+04, -4.6032e+04, -5.8489e+03],\n",
      "        [-1.8231e+04, -4.8936e+04, -6.2165e+03],\n",
      "        [-1.8705e+04, -5.0208e+04, -6.3774e+03],\n",
      "        [-1.9024e+04, -5.1065e+04, -6.4859e+03],\n",
      "        [-1.9508e+04, -5.2364e+04, -6.6503e+03],\n",
      "        [-2.1504e+04, -5.7723e+04, -7.3283e+03],\n",
      "        [-2.2018e+04, -5.9103e+04, -7.5030e+03],\n",
      "        [-2.3776e+04, -6.3823e+04, -8.1001e+03],\n",
      "        [-2.6729e+04, -7.1752e+04, -9.1030e+03],\n",
      "        [-2.6919e+04, -7.2263e+04, -9.1676e+03],\n",
      "        [-2.7110e+04, -7.2776e+04, -9.2324e+03],\n",
      "        [-3.0056e+04, -8.0685e+04, -1.0233e+04],\n",
      "        [-3.2942e+04, -8.8435e+04, -1.1213e+04],\n",
      "        [-3.5522e+04, -9.5360e+04, -1.2088e+04],\n",
      "        [-3.8654e+04, -1.0377e+05, -1.3151e+04],\n",
      "        [-4.2875e+04, -1.1510e+05, -1.4584e+04],\n",
      "        [-4.5068e+04, -1.2099e+05, -1.5328e+04],\n",
      "        [-6.4283e+04, -1.7259e+05, -2.1848e+04]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "-34:the loss_1 is : tensor([[4.8372e-17, 3.6714e-43, 1.2145e-07],\n",
      "        [0.0000e+00, 0.0000e+00, 7.5181e-26],\n",
      "        [0.0000e+00, 0.0000e+00, 4.2477e-38],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>)\n",
      "--34: the result of GMM by hand: tensor([6.2414e-08, 3.8636e-26, 2.1829e-38, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "       device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-34:the loss_2 is : tensor([6.2414e-08, 3.8637e-26, 2.1829e-38, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "       device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-34:the loss is : tensor([nan], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-35:target_unpadded shape: torch.Size([47, 3])\n",
      "-35:the m[i].log_prob(target_unpadded) is : tensor([[-4.0789e+01, -9.0447e+01, -1.4336e+01],\n",
      "        [-4.8742e+01, -1.0875e+02, -1.6690e+01],\n",
      "        [-8.7808e+01, -1.9894e+02, -2.8116e+01],\n",
      "        [-1.8410e+02, -4.2208e+02, -5.5858e+01],\n",
      "        [-2.0076e+02, -4.6075e+02, -6.0626e+01],\n",
      "        [-2.3626e+02, -5.4317e+02, -7.0765e+01],\n",
      "        [-2.5509e+02, -5.8693e+02, -7.6136e+01],\n",
      "        [-2.7465e+02, -6.3238e+02, -8.1709e+01],\n",
      "        [-2.9494e+02, -6.7953e+02, -8.7483e+01],\n",
      "        [-4.8334e+02, -1.1178e+03, -1.4092e+02],\n",
      "        [-5.1015e+02, -1.1802e+03, -1.4850e+02],\n",
      "        [-6.2466e+02, -1.4469e+03, -1.8085e+02],\n",
      "        [-9.9942e+02, -2.3201e+03, -2.8641e+02],\n",
      "        [-1.0770e+03, -2.5010e+03, -3.0822e+02],\n",
      "        [-1.2408e+03, -2.8830e+03, -3.5425e+02],\n",
      "        [-1.2836e+03, -2.9827e+03, -3.6626e+02],\n",
      "        [-1.3271e+03, -3.0842e+03, -3.7847e+02],\n",
      "        [-1.7012e+03, -3.9568e+03, -4.8341e+02],\n",
      "        [-1.7512e+03, -4.0735e+03, -4.9743e+02],\n",
      "        [-2.0666e+03, -4.8095e+03, -5.8579e+02],\n",
      "        [-2.5278e+03, -5.8857e+03, -7.1487e+02],\n",
      "        [-3.2377e+03, -7.5429e+03, -9.1337e+02],\n",
      "        [-3.9593e+03, -9.2275e+03, -1.1150e+03],\n",
      "        [-4.2682e+03, -9.9489e+03, -1.2012e+03],\n",
      "        [-4.4270e+03, -1.0320e+04, -1.2456e+03],\n",
      "        [-4.5075e+03, -1.0508e+04, -1.2680e+03],\n",
      "        [-5.2646e+03, -1.2276e+04, -1.4793e+03],\n",
      "        [-6.0805e+03, -1.4181e+04, -1.7069e+03],\n",
      "        [-6.1748e+03, -1.4402e+04, -1.7332e+03],\n",
      "        [-6.5592e+03, -1.5300e+04, -1.8404e+03],\n",
      "        [-6.9551e+03, -1.6225e+04, -1.9508e+03],\n",
      "        [-7.3627e+03, -1.7177e+04, -2.0645e+03],\n",
      "        [-7.9959e+03, -1.8656e+04, -2.2409e+03],\n",
      "        [-9.6930e+03, -2.2621e+04, -2.7138e+03],\n",
      "        [-1.0541e+04, -2.4602e+04, -2.9500e+03],\n",
      "        [-1.0665e+04, -2.4891e+04, -2.9845e+03],\n",
      "        [-1.1553e+04, -2.6967e+04, -3.2320e+03],\n",
      "        [-1.3437e+04, -3.1369e+04, -3.7564e+03],\n",
      "        [-1.6684e+04, -3.8957e+04, -4.6602e+03],\n",
      "        [-1.9941e+04, -4.6568e+04, -5.5664e+03],\n",
      "        [-2.5178e+04, -5.8810e+04, -7.0232e+03],\n",
      "        [-2.5562e+04, -5.9707e+04, -7.1299e+03],\n",
      "        [-2.7724e+04, -6.4761e+04, -7.7312e+03],\n",
      "        [-3.0183e+04, -7.0509e+04, -8.4149e+03],\n",
      "        [-3.9134e+04, -9.1432e+04, -1.0903e+04],\n",
      "        [-4.2293e+04, -9.8817e+04, -1.1781e+04],\n",
      "        [-4.6349e+04, -1.0830e+05, -1.2908e+04]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "-35:the loss_1 is : tensor([[1.9305e-18, 5.2398e-40, 5.9413e-07],\n",
      "        [6.7875e-22, 0.0000e+00, 5.6457e-08],\n",
      "        [7.3333e-39, 0.0000e+00, 6.1564e-13],\n",
      "        [0.0000e+00, 0.0000e+00, 5.5113e-25],\n",
      "        [0.0000e+00, 0.0000e+00, 4.6838e-27],\n",
      "        [0.0000e+00, 0.0000e+00, 1.8500e-31],\n",
      "        [0.0000e+00, 0.0000e+00, 8.5982e-34],\n",
      "        [0.0000e+00, 0.0000e+00, 3.2678e-36],\n",
      "        [0.0000e+00, 0.0000e+00, 1.0156e-38],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>)\n",
      "--35: the result of GMM by hand: tensor([3.0965e-07, 2.9425e-08, 3.2087e-13, 2.8724e-25, 2.4412e-27, 9.6421e-32,\n",
      "        4.4812e-34, 1.7032e-36, 5.2934e-39, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "       device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-35:the loss_2 is : tensor([3.0965e-07, 2.9425e-08, 3.2087e-13, 2.8724e-25, 2.4412e-27, 9.6421e-32,\n",
      "        4.4813e-34, 1.7032e-36, 5.2934e-39, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "       device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-35:the loss is : tensor([nan], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-36:target_unpadded shape: torch.Size([49, 3])\n",
      "-36:the m[i].log_prob(target_unpadded) is : tensor([[-3.6126e+00, -4.4830e+00, -2.7256e+00],\n",
      "        [-1.3998e+01, -2.1054e+01, -5.9751e+00],\n",
      "        [-2.5306e+01, -3.9443e+01, -9.3398e+00],\n",
      "        [-3.2275e+01, -5.0839e+01, -1.1382e+01],\n",
      "        [-4.0121e+01, -6.3705e+01, -1.3663e+01],\n",
      "        [-5.8443e+01, -9.3840e+01, -1.8945e+01],\n",
      "        [-8.0273e+01, -1.2985e+02, -2.5186e+01],\n",
      "        [-9.2503e+01, -1.5005e+02, -2.8666e+01],\n",
      "        [-1.0561e+02, -1.7173e+02, -3.2386e+01],\n",
      "        [-1.1959e+02, -1.9487e+02, -3.6345e+01],\n",
      "        [-1.3445e+02, -2.1948e+02, -4.0544e+01],\n",
      "        [-1.6680e+02, -2.7311e+02, -4.9661e+01],\n",
      "        [-2.0266e+02, -3.3261e+02, -5.9737e+01],\n",
      "        [-2.2191e+02, -3.6457e+02, -6.5135e+01],\n",
      "        [-2.4203e+02, -3.9799e+02, -7.0772e+01],\n",
      "        [-2.6303e+02, -4.3288e+02, -7.6648e+01],\n",
      "        [-2.8490e+02, -4.6924e+02, -8.2765e+01],\n",
      "        [-3.0765e+02, -5.0706e+02, -8.9121e+01],\n",
      "        [-3.3128e+02, -5.4636e+02, -9.5717e+01],\n",
      "        [-4.0743e+02, -6.7305e+02, -1.1694e+02],\n",
      "        [-4.3456e+02, -7.1822e+02, -1.2450e+02],\n",
      "        [-5.2123e+02, -8.6253e+02, -1.4860e+02],\n",
      "        [-5.5187e+02, -9.1357e+02, -1.5711e+02],\n",
      "        [-5.8339e+02, -9.6608e+02, -1.6586e+02],\n",
      "        [-7.1824e+02, -1.1908e+03, -2.0327e+02],\n",
      "        [-7.5414e+02, -1.2507e+03, -2.1322e+02],\n",
      "        [-9.8798e+02, -1.6406e+03, -2.7797e+02],\n",
      "        [-1.0300e+03, -1.7107e+03, -2.8960e+02],\n",
      "        [-1.2534e+03, -2.0834e+03, -3.5134e+02],\n",
      "        [-1.3979e+03, -2.3246e+03, -3.9126e+02],\n",
      "        [-1.5503e+03, -2.5790e+03, -4.3333e+02],\n",
      "        [-1.6029e+03, -2.6668e+03, -4.4784e+02],\n",
      "        [-1.7107e+03, -2.8467e+03, -4.7757e+02],\n",
      "        [-1.9954e+03, -3.3221e+03, -5.5609e+02],\n",
      "        [-2.1154e+03, -3.5226e+03, -5.8917e+02],\n",
      "        [-2.1768e+03, -3.6250e+03, -6.0607e+02],\n",
      "        [-2.4308e+03, -4.0494e+03, -6.7608e+02],\n",
      "        [-2.5632e+03, -4.2705e+03, -7.1252e+02],\n",
      "        [-2.7682e+03, -4.6130e+03, -7.6898e+02],\n",
      "        [-2.8383e+03, -4.7301e+03, -7.8828e+02],\n",
      "        [-2.9093e+03, -4.8487e+03, -8.0782e+02],\n",
      "        [-2.9811e+03, -4.9687e+03, -8.2759e+02],\n",
      "        [-3.6672e+03, -6.1153e+03, -1.0164e+03],\n",
      "        [-3.7479e+03, -6.2500e+03, -1.0386e+03],\n",
      "        [-5.2526e+03, -8.7651e+03, -1.4522e+03],\n",
      "        [-5.3490e+03, -8.9263e+03, -1.4787e+03],\n",
      "        [-6.0483e+03, -1.0096e+04, -1.6708e+03],\n",
      "        [-6.5742e+03, -1.0975e+04, -1.8153e+03],\n",
      "        [-8.1632e+03, -1.3632e+04, -2.2515e+03]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "-36:the loss_1 is : tensor([[2.6981e-02, 1.1299e-02, 6.5509e-02],\n",
      "        [8.3291e-07, 7.1848e-10, 2.5413e-03],\n",
      "        [1.0225e-11, 7.4179e-18, 8.7858e-05],\n",
      "        [9.6166e-15, 8.3311e-23, 1.1403e-05],\n",
      "        [3.7634e-18, 2.1550e-28, 1.1645e-06],\n",
      "        [4.1527e-26, 1.7616e-41, 5.9171e-09],\n",
      "        [1.3738e-35, 0.0000e+00, 1.1527e-11],\n",
      "        [6.7069e-41, 0.0000e+00, 3.5514e-13],\n",
      "        [0.0000e+00, 0.0000e+00, 8.6094e-15],\n",
      "        [0.0000e+00, 0.0000e+00, 1.6423e-16],\n",
      "        [0.0000e+00, 0.0000e+00, 2.4652e-18],\n",
      "        [0.0000e+00, 0.0000e+00, 2.7062e-22],\n",
      "        [0.0000e+00, 0.0000e+00, 1.1390e-26],\n",
      "        [0.0000e+00, 0.0000e+00, 5.1575e-29],\n",
      "        [0.0000e+00, 0.0000e+00, 1.8377e-31],\n",
      "        [0.0000e+00, 0.0000e+00, 5.1527e-34],\n",
      "        [0.0000e+00, 0.0000e+00, 1.1368e-36],\n",
      "        [0.0000e+00, 0.0000e+00, 1.9736e-39],\n",
      "        [0.0000e+00, 0.0000e+00, 2.6961e-42],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>)\n",
      "--36: the result of GMM by hand: tensor([4.3326e-02, 1.3047e-03, 4.5098e-05, 5.8529e-06, 5.9773e-07, 3.0373e-09,\n",
      "        5.9170e-12, 1.8229e-13, 4.4192e-15, 8.4301e-17, 1.2654e-18, 1.3891e-22,\n",
      "        5.8463e-27, 2.6474e-29, 9.4333e-32, 2.6449e-34, 5.8354e-37, 1.0131e-39,\n",
      "        1.3845e-42, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-36:the loss_2 is : tensor([4.3326e-02, 1.3047e-03, 4.5098e-05, 5.8529e-06, 5.9773e-07, 3.0373e-09,\n",
      "        5.9170e-12, 1.8229e-13, 4.4192e-15, 8.4301e-17, 1.2654e-18, 1.3891e-22,\n",
      "        5.8463e-27, 2.6474e-29, 9.4332e-32, 2.6449e-34, 5.8354e-37, 1.0131e-39,\n",
      "        1.3845e-42, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-36:the loss is : tensor([nan], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-37:target_unpadded shape: torch.Size([50, 3])\n",
      "-37:the m[i].log_prob(target_unpadded) is : tensor([[-5.6061e+00, -9.3066e+00, -3.4688e+00],\n",
      "        [-6.0644e+01, -1.2546e+02, -1.9258e+01],\n",
      "        [-8.1346e+01, -1.6968e+02, -2.4996e+01],\n",
      "        [-9.2853e+01, -1.9430e+02, -2.8168e+01],\n",
      "        [-1.1818e+02, -2.4855e+02, -3.5122e+01],\n",
      "        [-1.4658e+02, -3.0949e+02, -4.2886e+01],\n",
      "        [-1.6194e+02, -3.4247e+02, -4.7072e+01],\n",
      "        [-1.9497e+02, -4.1345e+02, -5.6051e+01],\n",
      "        [-2.5028e+02, -5.3247e+02, -7.1040e+01],\n",
      "        [-2.7026e+02, -5.7549e+02, -7.6442e+01],\n",
      "        [-2.9101e+02, -6.2019e+02, -8.2046e+01],\n",
      "        [-3.8171e+02, -8.1568e+02, -1.0649e+02],\n",
      "        [-4.3168e+02, -9.2347e+02, -1.1993e+02],\n",
      "        [-4.8473e+02, -1.0379e+03, -1.3417e+02],\n",
      "        [-6.9467e+02, -1.4913e+03, -1.9043e+02],\n",
      "        [-7.2775e+02, -1.5628e+03, -1.9927e+02],\n",
      "        [-7.6159e+02, -1.6359e+03, -2.0832e+02],\n",
      "        [-8.3159e+02, -1.7872e+03, -2.2703e+02],\n",
      "        [-9.8082e+02, -2.1098e+03, -2.6687e+02],\n",
      "        [-1.0201e+03, -2.1947e+03, -2.7734e+02],\n",
      "        [-1.1424e+03, -2.4592e+03, -3.0995e+02],\n",
      "        [-1.2716e+03, -2.7389e+03, -3.4440e+02],\n",
      "        [-1.4078e+03, -3.0335e+03, -3.8066e+02],\n",
      "        [-1.5509e+03, -3.3433e+03, -4.1875e+02],\n",
      "        [-1.7010e+03, -3.6681e+03, -4.5866e+02],\n",
      "        [-1.7526e+03, -3.7797e+03, -4.7237e+02],\n",
      "        [-1.8580e+03, -4.0079e+03, -5.0040e+02],\n",
      "        [-2.2512e+03, -4.8594e+03, -6.0487e+02],\n",
      "        [-2.4313e+03, -5.2495e+03, -6.5269e+02],\n",
      "        [-2.4929e+03, -5.3828e+03, -6.6903e+02],\n",
      "        [-2.7469e+03, -5.9330e+03, -7.3643e+02],\n",
      "        [-2.9454e+03, -6.3632e+03, -7.8911e+02],\n",
      "        [-3.2918e+03, -7.1136e+03, -8.8096e+02],\n",
      "        [-3.5828e+03, -7.7440e+03, -9.5808e+02],\n",
      "        [-4.1216e+03, -8.9118e+03, -1.1009e+03],\n",
      "        [-4.2825e+03, -9.2604e+03, -1.1435e+03],\n",
      "        [-4.6981e+03, -1.0161e+04, -1.2536e+03],\n",
      "        [-5.7743e+03, -1.2494e+04, -1.5384e+03],\n",
      "        [-6.0607e+03, -1.3115e+04, -1.6142e+03],\n",
      "        [-6.1577e+03, -1.3326e+04, -1.6399e+03],\n",
      "        [-6.3540e+03, -1.3751e+04, -1.6918e+03],\n",
      "        [-6.8583e+03, -1.4845e+04, -1.8252e+03],\n",
      "        [-7.1701e+03, -1.5521e+04, -1.9077e+03],\n",
      "        [-7.4888e+03, -1.6212e+04, -1.9919e+03],\n",
      "        [-7.8145e+03, -1.6918e+04, -2.0781e+03],\n",
      "        [-8.1471e+03, -1.7639e+04, -2.1660e+03],\n",
      "        [-1.0288e+04, -2.2283e+04, -2.7319e+03],\n",
      "        [-1.0798e+04, -2.3389e+04, -2.8666e+03],\n",
      "        [-1.4711e+04, -3.1877e+04, -3.9001e+03],\n",
      "        [-2.0629e+04, -4.4718e+04, -5.4622e+03]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "-37:the loss_1 is : tensor([[3.6755e-03, 9.0824e-05, 3.1154e-02],\n",
      "        [4.6005e-27, 0.0000e+00, 4.3286e-09],\n",
      "        [4.6954e-36, 0.0000e+00, 1.3949e-11],\n",
      "        [4.7245e-41, 0.0000e+00, 5.8429e-13],\n",
      "        [0.0000e+00, 0.0000e+00, 5.5824e-16],\n",
      "        [0.0000e+00, 0.0000e+00, 2.3714e-19],\n",
      "        [0.0000e+00, 0.0000e+00, 3.6067e-21],\n",
      "        [0.0000e+00, 0.0000e+00, 4.5425e-25],\n",
      "        [0.0000e+00, 0.0000e+00, 1.4047e-31],\n",
      "        [0.0000e+00, 0.0000e+00, 6.3341e-34],\n",
      "        [0.0000e+00, 0.0000e+00, 2.3323e-36],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>)\n",
      "--37: the result of GMM by hand: tensor([1.7613e-02, 2.3118e-09, 7.4497e-12, 3.1206e-13, 2.9814e-16, 1.2665e-19,\n",
      "        1.9262e-21, 2.4261e-25, 7.5023e-32, 3.3829e-34, 1.2456e-36, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-37:the loss_2 is : tensor([1.7613e-02, 2.3118e-09, 7.4497e-12, 3.1206e-13, 2.9814e-16, 1.2665e-19,\n",
      "        1.9262e-21, 2.4261e-25, 7.5023e-32, 3.3829e-34, 1.2456e-36, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-37:the loss is : tensor([nan], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-38:target_unpadded shape: torch.Size([62, 3])\n",
      "-38:the m[i].log_prob(target_unpadded) is : tensor([[-6.1833e+00, -1.0058e+01, -3.1003e+00],\n",
      "        [-6.3920e+01, -1.1704e+02, -1.3405e+01],\n",
      "        [-8.8306e+01, -1.6240e+02, -1.7599e+01],\n",
      "        [-2.4731e+02, -4.5860e+02, -4.4478e+01],\n",
      "        [-9.7534e+02, -1.8172e+03, -1.6534e+02],\n",
      "        [-1.5755e+03, -2.9378e+03, -2.6426e+02],\n",
      "        [-1.8678e+03, -3.4838e+03, -3.1235e+02],\n",
      "        [-1.9917e+03, -3.7153e+03, -3.3272e+02],\n",
      "        [-2.3189e+03, -4.3264e+03, -3.8648e+02],\n",
      "        [-4.3280e+03, -8.0799e+03, -7.1590e+02],\n",
      "        [-5.7248e+03, -1.0690e+04, -9.4454e+02],\n",
      "        [-6.8420e+03, -1.2777e+04, -1.1273e+03],\n",
      "        [-7.8073e+03, -1.4581e+04, -1.2851e+03],\n",
      "        [-8.4430e+03, -1.5769e+04, -1.3890e+03],\n",
      "        [-1.0499e+04, -1.9612e+04, -1.7249e+03],\n",
      "        [-1.1385e+04, -2.1267e+04, -1.8695e+03],\n",
      "        [-1.5459e+04, -2.8882e+04, -2.5346e+03],\n",
      "        [-2.0356e+04, -3.8034e+04, -3.3335e+03],\n",
      "        [-3.0176e+04, -5.6390e+04, -4.9346e+03],\n",
      "        [-3.1664e+04, -5.9172e+04, -5.1772e+03],\n",
      "        [-3.4748e+04, -6.4937e+04, -5.6798e+03],\n",
      "        [-3.7428e+04, -6.9946e+04, -6.1165e+03],\n",
      "        [-3.7976e+04, -7.0970e+04, -6.2058e+03],\n",
      "        [-3.9083e+04, -7.3040e+04, -6.3863e+03],\n",
      "        [-3.9643e+04, -7.4087e+04, -6.4775e+03],\n",
      "        [-4.1346e+04, -7.7271e+04, -6.7550e+03],\n",
      "        [-4.1634e+04, -7.7808e+04, -6.8019e+03],\n",
      "        [-4.5460e+04, -8.4961e+04, -7.4253e+03],\n",
      "        [-4.8518e+04, -9.0677e+04, -7.9234e+03],\n",
      "        [-6.0004e+04, -1.1215e+05, -9.7943e+03],\n",
      "        [-6.5300e+04, -1.2205e+05, -1.0657e+04],\n",
      "        [-6.7481e+04, -1.2613e+05, -1.1012e+04],\n",
      "        [-7.7738e+04, -1.4530e+05, -1.2682e+04],\n",
      "        [-7.8132e+04, -1.4604e+05, -1.2746e+04],\n",
      "        [-8.2936e+04, -1.5502e+05, -1.3529e+04],\n",
      "        [-8.9987e+04, -1.6820e+05, -1.4677e+04],\n",
      "        [-9.2974e+04, -1.7378e+05, -1.5163e+04],\n",
      "        [-1.0088e+05, -1.8856e+05, -1.6450e+04],\n",
      "        [-1.0957e+05, -2.0481e+05, -1.7865e+04],\n",
      "        [-1.1192e+05, -2.0920e+05, -1.8247e+04],\n",
      "        [-1.1669e+05, -2.1812e+05, -1.9023e+04],\n",
      "        [-1.2205e+05, -2.2814e+05, -1.9896e+04],\n",
      "        [-1.2603e+05, -2.3557e+05, -2.0543e+04],\n",
      "        [-1.3057e+05, -2.4407e+05, -2.1283e+04],\n",
      "        [-1.3108e+05, -2.4503e+05, -2.1366e+04],\n",
      "        [-1.4309e+05, -2.6748e+05, -2.3321e+04],\n",
      "        [-1.5066e+05, -2.8163e+05, -2.4553e+04],\n",
      "        [-1.6754e+05, -3.1318e+05, -2.7299e+04],\n",
      "        [-1.6812e+05, -3.1427e+05, -2.7393e+04],\n",
      "        [-1.7989e+05, -3.3627e+05, -2.9308e+04],\n",
      "        [-1.8349e+05, -3.4301e+05, -2.9896e+04],\n",
      "        [-1.8410e+05, -3.4414e+05, -2.9994e+04],\n",
      "        [-2.4961e+05, -4.6662e+05, -4.0653e+04],\n",
      "        [-2.6390e+05, -4.9334e+05, -4.2979e+04],\n",
      "        [-2.8685e+05, -5.3624e+05, -4.6712e+04],\n",
      "        [-2.8836e+05, -5.3907e+05, -4.6958e+04],\n",
      "        [-2.9676e+05, -5.5477e+05, -4.8324e+04],\n",
      "        [-3.1549e+05, -5.8979e+05, -5.1371e+04],\n",
      "        [-3.4715e+05, -6.4898e+05, -5.6521e+04],\n",
      "        [-3.8644e+05, -7.2244e+05, -6.2913e+04],\n",
      "        [-4.9686e+05, -9.2888e+05, -8.0873e+04],\n",
      "        [-5.8498e+05, -1.0936e+06, -9.5206e+04]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "-38:the loss_1 is : tensor([[2.0636e-03, 4.2846e-05, 4.5036e-02],\n",
      "        [1.7373e-28, 0.0000e+00, 1.5072e-06],\n",
      "        [4.4571e-39, 0.0000e+00, 2.2742e-08],\n",
      "        [0.0000e+00, 0.0000e+00, 4.8252e-20],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>)\n",
      "--38: the result of GMM by hand: tensor([2.4659e-02, 8.0671e-07, 1.2173e-08, 2.5826e-20, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-38:the loss_2 is : tensor([2.4659e-02, 8.0672e-07, 1.2173e-08, 2.5826e-20, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-38:the loss is : tensor([nan], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-39:target_unpadded shape: torch.Size([65, 3])\n",
      "-39:the m[i].log_prob(target_unpadded) is : tensor([[-1.1092e+00, -6.6555e-01, -1.8362e+00],\n",
      "        [-1.9243e+00, -2.0094e+00, -2.1482e+00],\n",
      "        [-3.5687e+00, -5.1867e+00, -2.6601e+00],\n",
      "        [-6.0425e+00, -1.0198e+01, -3.3720e+00],\n",
      "        [-9.3455e+00, -1.7042e+01, -4.2839e+00],\n",
      "        [-1.3478e+01, -2.5720e+01, -5.3957e+00],\n",
      "        [-1.8440e+01, -3.6231e+01, -6.7074e+00],\n",
      "        [-3.0851e+01, -6.2755e+01, -9.9307e+00],\n",
      "        [-4.6579e+01, -9.6612e+01, -1.3954e+01],\n",
      "        [-5.5688e+01, -1.1629e+02, -1.6265e+01],\n",
      "        [-6.5625e+01, -1.3780e+02, -1.8777e+01],\n",
      "        [-7.6392e+01, -1.6115e+02, -2.1488e+01],\n",
      "        [-8.7988e+01, -1.8633e+02, -2.4399e+01],\n",
      "        [-1.1367e+02, -2.4219e+02, -3.0822e+01],\n",
      "        [-1.2775e+02, -2.7287e+02, -3.4333e+01],\n",
      "        [-1.4267e+02, -3.0538e+02, -3.8044e+01],\n",
      "        [-1.5841e+02, -3.3973e+02, -4.1955e+01],\n",
      "        [-1.7498e+02, -3.7591e+02, -4.6066e+01],\n",
      "        [-2.1061e+02, -4.5377e+02, -5.4888e+01],\n",
      "        [-2.2967e+02, -4.9546e+02, -5.9599e+01],\n",
      "        [-2.4956e+02, -5.3897e+02, -6.4510e+01],\n",
      "        [-2.7028e+02, -5.8432e+02, -6.9620e+01],\n",
      "        [-2.9183e+02, -6.3150e+02, -7.4931e+01],\n",
      "        [-3.6145e+02, -7.8405e+02, -9.2063e+01],\n",
      "        [-5.5292e+02, -1.2042e+03, -1.3903e+02],\n",
      "        [-5.8359e+02, -1.2715e+03, -1.4654e+02],\n",
      "        [-6.1509e+02, -1.3407e+03, -1.5425e+02],\n",
      "        [-6.8058e+02, -1.4846e+03, -1.7027e+02],\n",
      "        [-7.1457e+02, -1.5593e+03, -1.7858e+02],\n",
      "        [-8.2151e+02, -1.7943e+03, -2.0471e+02],\n",
      "        [-9.7570e+02, -2.1334e+03, -2.4235e+02],\n",
      "        [-1.0578e+03, -2.3139e+03, -2.6237e+02],\n",
      "        [-1.1001e+03, -2.4069e+03, -2.7268e+02],\n",
      "        [-1.1871e+03, -2.5985e+03, -2.9390e+02],\n",
      "        [-1.5179e+03, -3.3266e+03, -3.7446e+02],\n",
      "        [-1.5685e+03, -3.4380e+03, -3.8677e+02],\n",
      "        [-1.6721e+03, -3.6662e+03, -4.1199e+02],\n",
      "        [-1.7252e+03, -3.7831e+03, -4.2490e+02],\n",
      "        [-1.8338e+03, -4.0223e+03, -4.5131e+02],\n",
      "        [-1.8893e+03, -4.1446e+03, -4.6482e+02],\n",
      "        [-1.9457e+03, -4.2688e+03, -4.7853e+02],\n",
      "        [-2.0029e+03, -4.3948e+03, -4.9244e+02],\n",
      "        [-2.0610e+03, -4.5227e+03, -5.0655e+02],\n",
      "        [-2.1198e+03, -4.6524e+03, -5.2086e+02],\n",
      "        [-2.1795e+03, -4.7839e+03, -5.3537e+02],\n",
      "        [-2.2401e+03, -4.9173e+03, -5.5007e+02],\n",
      "        [-2.3636e+03, -5.1895e+03, -5.8009e+02],\n",
      "        [-3.7027e+03, -8.1413e+03, -9.0513e+02],\n",
      "        [-3.7814e+03, -8.3150e+03, -9.2424e+02],\n",
      "        [-4.0227e+03, -8.8471e+03, -9.8276e+02],\n",
      "        [-4.8809e+03, -1.0740e+04, -1.1908e+03],\n",
      "        [-5.2474e+03, -1.1548e+04, -1.2797e+03],\n",
      "        [-5.4356e+03, -1.1964e+04, -1.3253e+03],\n",
      "        [-6.4265e+03, -1.4150e+04, -1.5653e+03],\n",
      "        [-7.3892e+03, -1.6274e+04, -1.7985e+03],\n",
      "        [-7.9531e+03, -1.7518e+04, -1.9350e+03],\n",
      "        [-9.0203e+03, -1.9874e+04, -2.1933e+03],\n",
      "        [-9.3910e+03, -2.0692e+04, -2.2830e+03],\n",
      "        [-1.0814e+04, -2.3833e+04, -2.6274e+03],\n",
      "        [-1.0948e+04, -2.4129e+04, -2.6599e+03],\n",
      "        [-1.1632e+04, -2.5640e+04, -2.8254e+03],\n",
      "        [-1.1912e+04, -2.6256e+04, -2.8930e+03],\n",
      "        [-1.8372e+04, -4.0520e+04, -4.4552e+03],\n",
      "        [-2.1838e+04, -4.8174e+04, -5.2931e+03],\n",
      "        [-2.6017e+04, -5.7405e+04, -6.3032e+03]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "-39:the loss_1 is : tensor([[3.2982e-01, 5.1399e-01, 1.5942e-01],\n",
      "        [1.4598e-01, 1.3408e-01, 1.1669e-01],\n",
      "        [2.8192e-02, 5.5905e-03, 6.9938e-02],\n",
      "        [2.3757e-03, 3.7262e-05, 3.4320e-02],\n",
      "        [8.7356e-05, 3.9700e-08, 1.3789e-02],\n",
      "        [1.4016e-06, 6.7612e-12, 4.5362e-03],\n",
      "        [9.8130e-09, 1.8406e-16, 1.2218e-03],\n",
      "        [3.9961e-14, 5.5716e-28, 4.8658e-05],\n",
      "        [5.8994e-21, 1.1014e-42, 8.7085e-07],\n",
      "        [6.5335e-25, 0.0000e+00, 8.6315e-08],\n",
      "        [3.1573e-29, 0.0000e+00, 7.0047e-09],\n",
      "        [6.6576e-34, 0.0000e+00, 4.6544e-10],\n",
      "        [6.1257e-39, 0.0000e+00, 2.5322e-11],\n",
      "        [0.0000e+00, 0.0000e+00, 4.1139e-14],\n",
      "        [0.0000e+00, 0.0000e+00, 1.2285e-15],\n",
      "        [0.0000e+00, 0.0000e+00, 3.0038e-17],\n",
      "        [0.0000e+00, 0.0000e+00, 6.0134e-19],\n",
      "        [0.0000e+00, 0.0000e+00, 9.8569e-21],\n",
      "        [0.0000e+00, 0.0000e+00, 1.4537e-24],\n",
      "        [0.0000e+00, 0.0000e+00, 1.3079e-26],\n",
      "        [0.0000e+00, 0.0000e+00, 9.6350e-29],\n",
      "        [0.0000e+00, 0.0000e+00, 5.8115e-31],\n",
      "        [0.0000e+00, 0.0000e+00, 2.8701e-33],\n",
      "        [0.0000e+00, 0.0000e+00, 1.0416e-40],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>)\n",
      "--39: the result of GMM by hand: tensor([2.7574e-01, 1.2766e-01, 4.6106e-02, 1.9182e-02, 7.4856e-03, 2.4557e-03,\n",
      "        6.6135e-04, 2.6337e-05, 4.7136e-07, 4.6719e-08, 3.7914e-09, 2.5192e-10,\n",
      "        1.3706e-11, 2.2267e-14, 6.6495e-16, 1.6258e-17, 3.2549e-19, 5.3352e-21,\n",
      "        7.8682e-25, 7.0792e-27, 5.2151e-29, 3.1456e-31, 1.5535e-33, 5.6376e-41,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "       device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-39:the loss_2 is : tensor([2.7574e-01, 1.2766e-01, 4.6106e-02, 1.9182e-02, 7.4856e-03, 2.4557e-03,\n",
      "        6.6135e-04, 2.6337e-05, 4.7136e-07, 4.6719e-08, 3.7914e-09, 2.5192e-10,\n",
      "        1.3706e-11, 2.2267e-14, 6.6495e-16, 1.6258e-17, 3.2549e-19, 5.3352e-21,\n",
      "        7.8683e-25, 7.0793e-27, 5.2151e-29, 3.1456e-31, 1.5535e-33, 5.6376e-41,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "       device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-39:the loss is : tensor([nan], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-40:target_unpadded shape: torch.Size([70, 3])\n",
      "-40:the m[i].log_prob(target_unpadded) is : tensor([[-4.9598e+00, -9.7840e+00, -3.3395e+00],\n",
      "        [-1.0888e+01, -2.4739e+01, -5.1597e+00],\n",
      "        [-1.9531e+01, -4.6799e+01, -7.6785e+00],\n",
      "        [-3.0889e+01, -7.5962e+01, -1.0896e+01],\n",
      "        [-3.7587e+01, -9.3208e+01, -1.2767e+01],\n",
      "        [-4.4963e+01, -1.1223e+02, -1.4812e+01],\n",
      "        [-5.3017e+01, -1.3303e+02, -1.7032e+01],\n",
      "        [-6.1751e+01, -1.5560e+02, -1.9427e+01],\n",
      "        [-7.1163e+01, -1.7995e+02, -2.1996e+01],\n",
      "        [-8.1254e+01, -2.0608e+02, -2.4741e+01],\n",
      "        [-9.2024e+01, -2.3398e+02, -2.7659e+01],\n",
      "        [-1.2841e+02, -3.2834e+02, -3.7464e+01],\n",
      "        [-1.4189e+02, -3.6335e+02, -4.1081e+01],\n",
      "        [-1.7090e+02, -4.3869e+02, -4.8840e+01],\n",
      "        [-1.8642e+02, -4.7902e+02, -5.2981e+01],\n",
      "        [-2.0262e+02, -5.2113e+02, -5.7297e+01],\n",
      "        [-2.1950e+02, -5.6502e+02, -6.1788e+01],\n",
      "        [-2.5529e+02, -6.5812e+02, -7.1294e+01],\n",
      "        [-2.7421e+02, -7.0733e+02, -7.6309e+01],\n",
      "        [-2.9380e+02, -7.5832e+02, -8.1498e+01],\n",
      "        [-3.1407e+02, -8.1109e+02, -8.6862e+01],\n",
      "        [-3.5665e+02, -9.2195e+02, -9.8114e+01],\n",
      "        [-3.7896e+02, -9.8004e+02, -1.0400e+02],\n",
      "        [-4.2562e+02, -1.1016e+03, -1.1630e+02],\n",
      "        [-4.7499e+02, -1.2302e+03, -1.2930e+02],\n",
      "        [-5.0069e+02, -1.2972e+03, -1.3606e+02],\n",
      "        [-5.5413e+02, -1.4364e+03, -1.5011e+02],\n",
      "        [-6.1029e+02, -1.5828e+03, -1.6486e+02],\n",
      "        [-6.3938e+02, -1.6587e+03, -1.7249e+02],\n",
      "        [-6.6916e+02, -1.7363e+03, -1.8030e+02],\n",
      "        [-7.3075e+02, -1.8969e+03, -1.9644e+02],\n",
      "        [-7.6256e+02, -1.9798e+03, -2.0478e+02],\n",
      "        [-7.9505e+02, -2.0646e+03, -2.1328e+02],\n",
      "        [-8.6206e+02, -2.2394e+03, -2.3082e+02],\n",
      "        [-8.9659e+02, -2.3294e+03, -2.3986e+02],\n",
      "        [-9.3180e+02, -2.4213e+03, -2.4906e+02],\n",
      "        [-1.0042e+03, -2.6103e+03, -2.6800e+02],\n",
      "        [-1.0794e+03, -2.8064e+03, -2.8764e+02],\n",
      "        [-1.1180e+03, -2.9071e+03, -2.9772e+02],\n",
      "        [-1.2379e+03, -3.2199e+03, -3.2901e+02],\n",
      "        [-1.2792e+03, -3.3277e+03, -3.3978e+02],\n",
      "        [-1.5413e+03, -4.0120e+03, -4.0813e+02],\n",
      "        [-1.5874e+03, -4.1322e+03, -4.2013e+02],\n",
      "        [-1.8780e+03, -4.8911e+03, -4.9580e+02],\n",
      "        [-1.9804e+03, -5.1582e+03, -5.2243e+02],\n",
      "        [-2.2480e+03, -5.8572e+03, -5.9204e+02],\n",
      "        [-2.3598e+03, -6.1492e+03, -6.2111e+02],\n",
      "        [-2.5326e+03, -6.6005e+03, -6.6602e+02],\n",
      "        [-2.6512e+03, -6.9103e+03, -6.9684e+02],\n",
      "        [-2.7726e+03, -7.2272e+03, -7.2835e+02],\n",
      "        [-2.8342e+03, -7.3883e+03, -7.4437e+02],\n",
      "        [-3.2186e+03, -8.3922e+03, -8.4415e+02],\n",
      "        [-3.9134e+03, -1.0207e+04, -1.0244e+03],\n",
      "        [-3.9866e+03, -1.0399e+04, -1.0434e+03],\n",
      "        [-4.1351e+03, -1.0787e+04, -1.0819e+03],\n",
      "        [-4.2863e+03, -1.1182e+04, -1.1211e+03],\n",
      "        [-4.5968e+03, -1.1993e+04, -1.2016e+03],\n",
      "        [-4.6761e+03, -1.2200e+04, -1.2222e+03],\n",
      "        [-5.1663e+03, -1.3481e+04, -1.3492e+03],\n",
      "        [-5.2504e+03, -1.3701e+04, -1.3710e+03],\n",
      "        [-5.4206e+03, -1.4146e+04, -1.4151e+03],\n",
      "        [-5.5067e+03, -1.4371e+04, -1.4374e+03],\n",
      "        [-5.6809e+03, -1.4826e+04, -1.4825e+03],\n",
      "        [-5.9474e+03, -1.5523e+04, -1.5515e+03],\n",
      "        [-6.4051e+03, -1.6719e+04, -1.6701e+03],\n",
      "        [-8.4057e+03, -2.1948e+04, -2.1878e+03],\n",
      "        [-1.1042e+04, -2.8839e+04, -2.8696e+03],\n",
      "        [-1.1789e+04, -3.0792e+04, -3.0626e+03],\n",
      "        [-1.4454e+04, -3.7761e+04, -3.7516e+03],\n",
      "        [-1.4878e+04, -3.8868e+04, -3.8609e+03]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "-40:the loss_1 is : tensor([[7.0146e-03, 5.6346e-05, 3.5453e-02],\n",
      "        [1.8684e-05, 1.8023e-11, 5.7434e-03],\n",
      "        [3.2945e-09, 4.7371e-21, 4.6265e-04],\n",
      "        [3.8457e-14, 1.0231e-33, 1.8531e-05],\n",
      "        [4.7466e-17, 3.3127e-41, 2.8540e-06],\n",
      "        [2.9718e-20, 0.0000e+00, 3.6909e-07],\n",
      "        [9.4377e-24, 0.0000e+00, 4.0083e-08],\n",
      "        [1.5203e-27, 0.0000e+00, 3.6554e-09],\n",
      "        [1.2423e-31, 0.0000e+00, 2.7993e-10],\n",
      "        [5.1488e-36, 0.0000e+00, 1.8001e-11],\n",
      "        [1.0825e-40, 0.0000e+00, 9.7208e-13],\n",
      "        [0.0000e+00, 0.0000e+00, 5.3673e-17],\n",
      "        [0.0000e+00, 0.0000e+00, 1.4412e-18],\n",
      "        [0.0000e+00, 0.0000e+00, 6.1531e-22],\n",
      "        [0.0000e+00, 0.0000e+00, 9.7833e-24],\n",
      "        [0.0000e+00, 0.0000e+00, 1.3063e-25],\n",
      "        [0.0000e+00, 0.0000e+00, 1.4646e-27],\n",
      "        [0.0000e+00, 0.0000e+00, 1.0902e-31],\n",
      "        [0.0000e+00, 0.0000e+00, 7.2379e-34],\n",
      "        [0.0000e+00, 0.0000e+00, 4.0353e-36],\n",
      "        [0.0000e+00, 0.0000e+00, 1.8892e-38],\n",
      "        [0.0000e+00, 0.0000e+00, 2.4523e-43],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>)\n",
      "--40: the result of GMM by hand: tensor([2.0944e-02, 3.0888e-03, 2.4841e-04, 9.9499e-06, 1.5324e-06, 1.9817e-07,\n",
      "        2.1521e-08, 1.9627e-09, 1.5030e-10, 9.6652e-12, 5.2193e-13, 2.8818e-17,\n",
      "        7.7380e-19, 3.3037e-22, 5.2529e-24, 7.0135e-26, 7.8636e-28, 5.8535e-32,\n",
      "        3.8862e-34, 2.1666e-36, 1.0143e-38, 1.3172e-43, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00], device='cuda:0',\n",
      "       grad_fn=<SumBackward1>)\n",
      "-40:the loss_2 is : tensor([2.0944e-02, 3.0888e-03, 2.4841e-04, 9.9499e-06, 1.5324e-06, 1.9817e-07,\n",
      "        2.1522e-08, 1.9627e-09, 1.5030e-10, 9.6652e-12, 5.2193e-13, 2.8818e-17,\n",
      "        7.7381e-19, 3.3037e-22, 5.2529e-24, 7.0135e-26, 7.8636e-28, 5.8535e-32,\n",
      "        3.8862e-34, 2.1666e-36, 1.0143e-38, 1.3172e-43, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00], device='cuda:0',\n",
      "       grad_fn=<SumBackward1>)\n",
      "-40:the loss is : tensor([nan], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-41:target_unpadded shape: torch.Size([80, 3])\n",
      "-41:the m[i].log_prob(target_unpadded) is : tensor([[-1.2061e+02, -2.8672e+02, -3.8091e+01],\n",
      "        [-5.5119e+02, -1.3226e+03, -1.6156e+02],\n",
      "        [-1.9471e+03, -4.6850e+03, -5.5633e+02],\n",
      "        [-1.1523e+04, -2.7768e+04, -3.2429e+03],\n",
      "        [-1.2205e+04, -2.9412e+04, -3.4338e+03],\n",
      "        [-1.2624e+04, -3.0421e+04, -3.5510e+03],\n",
      "        [-1.2765e+04, -3.0761e+04, -3.5905e+03],\n",
      "        [-2.3808e+04, -5.7386e+04, -6.6799e+03],\n",
      "        [-2.7412e+04, -6.6077e+04, -7.6876e+03],\n",
      "        [-2.8247e+04, -6.8091e+04, -7.9211e+03],\n",
      "        [-4.6234e+04, -1.1146e+05, -1.2947e+04],\n",
      "        [-4.6774e+04, -1.1276e+05, -1.3098e+04],\n",
      "        [-5.2633e+04, -1.2689e+05, -1.4735e+04],\n",
      "        [-5.8534e+04, -1.4112e+05, -1.6383e+04],\n",
      "        [-6.9616e+04, -1.6785e+05, -1.9478e+04],\n",
      "        [-7.5690e+04, -1.8249e+05, -2.1174e+04],\n",
      "        [-7.8120e+04, -1.8835e+05, -2.1853e+04],\n",
      "        [-8.2735e+04, -1.9948e+05, -2.3142e+04],\n",
      "        [-9.0848e+04, -2.1905e+05, -2.5407e+04],\n",
      "        [-1.0986e+05, -2.6491e+05, -3.0715e+04],\n",
      "        [-1.2443e+05, -3.0003e+05, -3.4780e+04],\n",
      "        [-1.2978e+05, -3.1294e+05, -3.6275e+04],\n",
      "        [-1.5976e+05, -3.8522e+05, -4.4640e+04],\n",
      "        [-1.8147e+05, -4.3758e+05, -5.0699e+04],\n",
      "        [-2.0854e+05, -5.0287e+05, -5.8254e+04],\n",
      "        [-2.1662e+05, -5.2236e+05, -6.0509e+04],\n",
      "        [-2.2131e+05, -5.3367e+05, -6.1816e+04],\n",
      "        [-2.2426e+05, -5.4079e+05, -6.2641e+04],\n",
      "        [-2.4798e+05, -5.9800e+05, -6.9259e+04],\n",
      "        [-2.5363e+05, -6.1160e+05, -7.0833e+04],\n",
      "        [-2.6899e+05, -6.4864e+05, -7.5119e+04],\n",
      "        [-2.9559e+05, -7.1280e+05, -8.2540e+04],\n",
      "        [-3.1285e+05, -7.5443e+05, -8.7356e+04],\n",
      "        [-3.4149e+05, -8.2350e+05, -9.5345e+04],\n",
      "        [-3.6682e+05, -8.8458e+05, -1.0241e+05],\n",
      "        [-3.7062e+05, -8.9375e+05, -1.0347e+05],\n",
      "        [-3.9070e+05, -9.4218e+05, -1.0907e+05],\n",
      "        [-4.0094e+05, -9.6688e+05, -1.1193e+05],\n",
      "        [-4.0811e+05, -9.8417e+05, -1.1393e+05],\n",
      "        [-4.1373e+05, -9.9771e+05, -1.1550e+05],\n",
      "        [-4.1857e+05, -1.0094e+06, -1.1685e+05],\n",
      "        [-4.3328e+05, -1.0449e+06, -1.2095e+05],\n",
      "        [-4.3907e+05, -1.0588e+06, -1.2257e+05],\n",
      "        [-4.5244e+05, -1.0911e+06, -1.2630e+05],\n",
      "        [-4.5329e+05, -1.0931e+06, -1.2653e+05],\n",
      "        [-4.7720e+05, -1.1508e+06, -1.3320e+05],\n",
      "        [-4.8240e+05, -1.1633e+06, -1.3465e+05],\n",
      "        [-5.2868e+05, -1.2749e+06, -1.4756e+05],\n",
      "        [-5.8089e+05, -1.4009e+06, -1.6212e+05],\n",
      "        [-6.8333e+05, -1.6479e+06, -1.9069e+05],\n",
      "        [-7.3177e+05, -1.7647e+06, -2.0420e+05],\n",
      "        [-7.3821e+05, -1.7803e+06, -2.0600e+05],\n",
      "        [-7.8409e+05, -1.8909e+06, -2.1879e+05],\n",
      "        [-8.2223e+05, -1.9829e+06, -2.2943e+05],\n",
      "        [-9.2397e+05, -2.2283e+06, -2.5780e+05],\n",
      "        [-9.3362e+05, -2.2516e+06, -2.6050e+05],\n",
      "        [-1.0064e+06, -2.4270e+06, -2.8078e+05],\n",
      "        [-1.0831e+06, -2.6122e+06, -3.0219e+05],\n",
      "        [-1.2118e+06, -2.9226e+06, -3.3808e+05],\n",
      "        [-1.2718e+06, -3.0672e+06, -3.5481e+05],\n",
      "        [-1.3550e+06, -3.2679e+06, -3.7801e+05],\n",
      "        [-1.3697e+06, -3.3032e+06, -3.8209e+05],\n",
      "        [-1.4051e+06, -3.3885e+06, -3.9196e+05],\n",
      "        [-1.6413e+06, -3.9583e+06, -4.5783e+05],\n",
      "        [-1.8023e+06, -4.3465e+06, -5.0271e+05],\n",
      "        [-1.8174e+06, -4.3831e+06, -5.0694e+05],\n",
      "        [-1.9270e+06, -4.6475e+06, -5.3751e+05],\n",
      "        [-1.9392e+06, -4.6768e+06, -5.4090e+05],\n",
      "        [-2.1376e+06, -5.1553e+06, -5.9621e+05],\n",
      "        [-2.3017e+06, -5.5511e+06, -6.4197e+05],\n",
      "        [-2.4171e+06, -5.8294e+06, -6.7414e+05],\n",
      "        [-2.5154e+06, -6.0665e+06, -7.0155e+05],\n",
      "        [-2.5633e+06, -6.1819e+06, -7.1490e+05],\n",
      "        [-3.2856e+06, -7.9240e+06, -9.1629e+05],\n",
      "        [-3.5873e+06, -8.6515e+06, -1.0004e+06],\n",
      "        [-3.6348e+06, -8.7663e+06, -1.0137e+06],\n",
      "        [-3.9543e+06, -9.5367e+06, -1.1027e+06],\n",
      "        [-4.1687e+06, -1.0054e+07, -1.1625e+06],\n",
      "        [-4.5717e+06, -1.1026e+07, -1.2749e+06],\n",
      "        [-5.6515e+06, -1.3630e+07, -1.5759e+06]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "-41:the loss_1 is : tensor([[0.0000e+00, 0.0000e+00, 2.8647e-17],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>)\n",
      "--41: the result of GMM by hand: tensor([1.4413e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-41:the loss_2 is : tensor([1.4413e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-41:the loss is : tensor([nan], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-42:target_unpadded shape: torch.Size([114, 3])\n",
      "-42:the m[i].log_prob(target_unpadded) is : tensor([[-5.8732e+03, -1.4419e+04, -1.3665e+03],\n",
      "        [-1.0009e+04, -2.4578e+04, -2.3202e+03],\n",
      "        [-1.1279e+04, -2.7699e+04, -2.6129e+03],\n",
      "        [-1.7606e+04, -4.3243e+04, -4.0699e+03],\n",
      "        [-2.5337e+04, -6.2235e+04, -5.8485e+03],\n",
      "        [-3.0476e+04, -7.4862e+04, -7.0305e+03],\n",
      "        [-3.2221e+04, -7.9149e+04, -7.4317e+03],\n",
      "        [-3.2888e+04, -8.0787e+04, -7.5850e+03],\n",
      "        [-3.3337e+04, -8.1889e+04, -7.6881e+03],\n",
      "        [-3.4471e+04, -8.4675e+04, -7.9488e+03],\n",
      "        [-3.7987e+04, -9.3314e+04, -8.7572e+03],\n",
      "        [-4.0674e+04, -9.9916e+04, -9.3748e+03],\n",
      "        [-4.4747e+04, -1.0992e+05, -1.0311e+04],\n",
      "        [-5.5197e+04, -1.3560e+05, -1.2712e+04],\n",
      "        [-6.2055e+04, -1.5245e+05, -1.4288e+04],\n",
      "        [-6.2979e+04, -1.5472e+05, -1.4500e+04],\n",
      "        [-9.1627e+04, -2.2511e+05, -2.1080e+04],\n",
      "        [-9.8849e+04, -2.4285e+05, -2.2739e+04],\n",
      "        [-1.0918e+05, -2.6822e+05, -2.5110e+04],\n",
      "        [-1.1789e+05, -2.8964e+05, -2.7111e+04],\n",
      "        [-1.3316e+05, -3.2716e+05, -3.0617e+04],\n",
      "        [-1.4138e+05, -3.4734e+05, -3.2503e+04],\n",
      "        [-1.9366e+05, -4.7580e+05, -4.4504e+04],\n",
      "        [-2.2287e+05, -5.4759e+05, -5.1209e+04],\n",
      "        [-2.4369e+05, -5.9875e+05, -5.5988e+04],\n",
      "        [-2.4613e+05, -6.0474e+05, -5.6548e+04],\n",
      "        [-2.6608e+05, -6.5375e+05, -6.1125e+04],\n",
      "        [-2.9211e+05, -7.1770e+05, -6.7098e+04],\n",
      "        [-3.6249e+05, -8.9063e+05, -8.3247e+04],\n",
      "        [-4.0757e+05, -1.0014e+06, -9.3591e+04],\n",
      "        [-4.1072e+05, -1.0091e+06, -9.4314e+04],\n",
      "        [-4.1230e+05, -1.0130e+06, -9.4677e+04],\n",
      "        [-4.1786e+05, -1.0267e+06, -9.5952e+04],\n",
      "        [-4.3394e+05, -1.0662e+06, -9.9641e+04],\n",
      "        [-4.5779e+05, -1.1248e+06, -1.0511e+05],\n",
      "        [-5.1889e+05, -1.2749e+06, -1.1913e+05],\n",
      "        [-5.2333e+05, -1.2859e+06, -1.2015e+05],\n",
      "        [-5.5407e+05, -1.3614e+06, -1.2720e+05],\n",
      "        [-5.8758e+05, -1.4437e+06, -1.3489e+05],\n",
      "        [-6.5654e+05, -1.6132e+06, -1.5071e+05],\n",
      "        [-6.6757e+05, -1.6403e+06, -1.5324e+05],\n",
      "        [-7.0533e+05, -1.7330e+06, -1.6190e+05],\n",
      "        [-7.1571e+05, -1.7586e+06, -1.6428e+05],\n",
      "        [-8.4625e+05, -2.0793e+06, -1.9423e+05],\n",
      "        [-9.0621e+05, -2.2266e+06, -2.0798e+05],\n",
      "        [-9.0738e+05, -2.2295e+06, -2.0825e+05],\n",
      "        [-1.0385e+06, -2.5518e+06, -2.3834e+05],\n",
      "        [-1.0613e+06, -2.6076e+06, -2.4355e+05],\n",
      "        [-1.0638e+06, -2.6139e+06, -2.4413e+05],\n",
      "        [-1.1113e+06, -2.7307e+06, -2.5503e+05],\n",
      "        [-1.1322e+06, -2.7820e+06, -2.5982e+05],\n",
      "        [-1.1612e+06, -2.8533e+06, -2.6648e+05],\n",
      "        [-1.1893e+06, -2.9222e+06, -2.7291e+05],\n",
      "        [-1.1947e+06, -2.9354e+06, -2.7414e+05],\n",
      "        [-1.3460e+06, -3.3072e+06, -3.0884e+05],\n",
      "        [-1.4213e+06, -3.4923e+06, -3.2612e+05],\n",
      "        [-1.4897e+06, -3.6603e+06, -3.4180e+05],\n",
      "        [-1.7351e+06, -4.2633e+06, -3.9809e+05],\n",
      "        [-1.7973e+06, -4.4162e+06, -4.1236e+05],\n",
      "        [-2.0132e+06, -4.9467e+06, -4.6187e+05],\n",
      "        [-2.2988e+06, -5.6486e+06, -5.2738e+05],\n",
      "        [-2.3477e+06, -5.7685e+06, -5.3857e+05],\n",
      "        [-2.6514e+06, -6.5148e+06, -6.0822e+05],\n",
      "        [-2.7119e+06, -6.6635e+06, -6.2210e+05],\n",
      "        [-2.7404e+06, -6.7335e+06, -6.2863e+05],\n",
      "        [-2.8308e+06, -6.9558e+06, -6.4938e+05],\n",
      "        [-2.8955e+06, -7.1146e+06, -6.6420e+05],\n",
      "        [-2.9017e+06, -7.1300e+06, -6.6564e+05],\n",
      "        [-3.3119e+06, -8.1380e+06, -7.5971e+05],\n",
      "        [-3.5076e+06, -8.6186e+06, -8.0456e+05],\n",
      "        [-3.5725e+06, -8.7781e+06, -8.1945e+05],\n",
      "        [-3.5888e+06, -8.8182e+06, -8.2319e+05],\n",
      "        [-3.9278e+06, -9.6514e+06, -9.0094e+05],\n",
      "        [-3.9695e+06, -9.7536e+06, -9.1048e+05],\n",
      "        [-4.0956e+06, -1.0064e+07, -9.3942e+05],\n",
      "        [-4.5252e+06, -1.1119e+07, -1.0379e+06],\n",
      "        [-4.6359e+06, -1.1391e+07, -1.0633e+06],\n",
      "        [-4.9460e+06, -1.2153e+07, -1.1344e+06],\n",
      "        [-5.8288e+06, -1.4323e+07, -1.3369e+06],\n",
      "        [-6.7842e+06, -1.6670e+07, -1.5559e+06],\n",
      "        [-6.9618e+06, -1.7106e+07, -1.5966e+06],\n",
      "        [-7.4579e+06, -1.8325e+07, -1.7104e+06],\n",
      "        [-7.9955e+06, -1.9646e+07, -1.8337e+06],\n",
      "        [-8.0933e+06, -1.9887e+07, -1.8561e+06],\n",
      "        [-8.5950e+06, -2.1120e+07, -1.9711e+06],\n",
      "        [-8.8534e+06, -2.1754e+07, -2.0304e+06],\n",
      "        [-8.8754e+06, -2.1809e+07, -2.0354e+06],\n",
      "        [-9.4004e+06, -2.3099e+07, -2.1558e+06],\n",
      "        [-9.4231e+06, -2.3154e+07, -2.1610e+06],\n",
      "        [-9.7435e+06, -2.3942e+07, -2.2345e+06],\n",
      "        [-1.0444e+07, -2.5663e+07, -2.3951e+06],\n",
      "        [-1.1384e+07, -2.7973e+07, -2.6106e+06],\n",
      "        [-1.1459e+07, -2.8157e+07, -2.6278e+06],\n",
      "        [-1.2020e+07, -2.9536e+07, -2.7565e+06],\n",
      "        [-1.4227e+07, -3.4960e+07, -3.2626e+06],\n",
      "        [-1.5935e+07, -3.9155e+07, -3.6540e+06],\n",
      "        [-1.6376e+07, -4.0238e+07, -3.7551e+06],\n",
      "        [-1.6626e+07, -4.0853e+07, -3.8124e+06],\n",
      "        [-1.8167e+07, -4.4640e+07, -4.1658e+06],\n",
      "        [-1.8240e+07, -4.4821e+07, -4.1827e+06],\n",
      "        [-2.0764e+07, -5.1020e+07, -4.7612e+06],\n",
      "        [-2.1901e+07, -5.3816e+07, -5.0221e+06],\n",
      "        [-2.3194e+07, -5.6993e+07, -5.3184e+06],\n",
      "        [-2.5317e+07, -6.2210e+07, -5.8052e+06],\n",
      "        [-2.8007e+07, -6.8820e+07, -6.4220e+06],\n",
      "        [-2.9040e+07, -7.1358e+07, -6.6588e+06],\n",
      "        [-3.0874e+07, -7.5864e+07, -7.0793e+06],\n",
      "        [-3.1217e+07, -7.6708e+07, -7.1580e+06],\n",
      "        [-4.4631e+07, -1.0967e+08, -1.0233e+07],\n",
      "        [-4.8626e+07, -1.1948e+08, -1.1149e+07],\n",
      "        [-6.0292e+07, -1.4815e+08, -1.3824e+07],\n",
      "        [-7.3147e+07, -1.7974e+08, -1.6771e+07],\n",
      "        [-9.2452e+07, -2.2717e+08, -2.1197e+07],\n",
      "        [-1.2737e+08, -3.1297e+08, -2.9202e+07]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "-42:the loss_1 is : tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "--42: the result of GMM by hand: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-42:the loss_2 is : tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-42:the loss is : tensor([nan], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-43:target_unpadded shape: torch.Size([148, 3])\n",
      "-43:the m[i].log_prob(target_unpadded) is : tensor([[-1.1785e+00, -7.0306e-01, -1.8082e+00],\n",
      "        [-1.7861e+00, -2.0964e+00, -2.2107e+00],\n",
      "        [-3.0599e+00, -5.2669e+00, -2.8504e+00],\n",
      "        [-4.9999e+00, -1.0215e+01, -3.7272e+00],\n",
      "        [-7.6061e+00, -1.6940e+01, -4.8413e+00],\n",
      "        [-1.0878e+01, -2.5442e+01, -6.1926e+00],\n",
      "        [-1.4817e+01, -3.5722e+01, -7.7811e+00],\n",
      "        [-1.9422e+01, -4.7779e+01, -9.6067e+00],\n",
      "        [-2.4693e+01, -6.1613e+01, -1.1670e+01],\n",
      "        [-3.0630e+01, -7.7224e+01, -1.3970e+01],\n",
      "        [-3.7234e+01, -9.4612e+01, -1.6507e+01],\n",
      "        [-4.4503e+01, -1.1378e+02, -1.9281e+01],\n",
      "        [-5.2439e+01, -1.3472e+02, -2.2293e+01],\n",
      "        [-6.1041e+01, -1.5744e+02, -2.5542e+01],\n",
      "        [-7.0310e+01, -1.8194e+02, -2.9028e+01],\n",
      "        [-8.0244e+01, -2.0821e+02, -3.2751e+01],\n",
      "        [-9.0845e+01, -2.3627e+02, -3.6712e+01],\n",
      "        [-1.0211e+02, -2.6610e+02, -4.0910e+01],\n",
      "        [-1.1405e+02, -2.9770e+02, -4.5344e+01],\n",
      "        [-1.2664e+02, -3.3109e+02, -5.0017e+01],\n",
      "        [-1.3991e+02, -3.6625e+02, -5.4926e+01],\n",
      "        [-1.5384e+02, -4.0319e+02, -6.0072e+01],\n",
      "        [-1.6844e+02, -4.4190e+02, -6.5456e+01],\n",
      "        [-1.8370e+02, -4.8239e+02, -7.1077e+01],\n",
      "        [-1.9964e+02, -5.2466e+02, -7.6935e+01],\n",
      "        [-2.1623e+02, -5.6871e+02, -8.3030e+01],\n",
      "        [-2.3349e+02, -6.1454e+02, -8.9363e+01],\n",
      "        [-2.5142e+02, -6.6214e+02, -9.5933e+01],\n",
      "        [-2.7002e+02, -7.1152e+02, -1.0274e+02],\n",
      "        [-2.8928e+02, -7.6267e+02, -1.0978e+02],\n",
      "        [-3.0921e+02, -8.1561e+02, -1.1706e+02],\n",
      "        [-3.2980e+02, -8.7032e+02, -1.2458e+02],\n",
      "        [-3.5106e+02, -9.2681e+02, -1.3234e+02],\n",
      "        [-3.7299e+02, -9.8507e+02, -1.4033e+02],\n",
      "        [-3.9558e+02, -1.0451e+03, -1.4856e+02],\n",
      "        [-4.1884e+02, -1.1069e+03, -1.5703e+02],\n",
      "        [-4.4277e+02, -1.1705e+03, -1.6573e+02],\n",
      "        [-4.6736e+02, -1.2359e+03, -1.7468e+02],\n",
      "        [-4.9261e+02, -1.3031e+03, -1.8385e+02],\n",
      "        [-5.1854e+02, -1.3720e+03, -1.9327e+02],\n",
      "        [-5.4513e+02, -1.4427e+03, -2.0292e+02],\n",
      "        [-5.7238e+02, -1.5152e+03, -2.1281e+02],\n",
      "        [-6.0031e+02, -1.5894e+03, -2.2294e+02],\n",
      "        [-6.2889e+02, -1.6655e+03, -2.3331e+02],\n",
      "        [-6.5815e+02, -1.7433e+03, -2.4391e+02],\n",
      "        [-6.8807e+02, -1.8229e+03, -2.5475e+02],\n",
      "        [-7.1866e+02, -1.9043e+03, -2.6582e+02],\n",
      "        [-7.4991e+02, -1.9874e+03, -2.7714e+02],\n",
      "        [-7.8183e+02, -2.0723e+03, -2.8869e+02],\n",
      "        [-8.1442e+02, -2.1590e+03, -3.0048e+02],\n",
      "        [-8.4767e+02, -2.2475e+03, -3.1250e+02],\n",
      "        [-8.8159e+02, -2.3378e+03, -3.2477e+02],\n",
      "        [-9.1617e+02, -2.4298e+03, -3.3727e+02],\n",
      "        [-9.5142e+02, -2.5236e+03, -3.5000e+02],\n",
      "        [-9.8734e+02, -2.6192e+03, -3.6298e+02],\n",
      "        [-1.0239e+03, -2.7166e+03, -3.7619e+02],\n",
      "        [-1.0612e+03, -2.8157e+03, -3.8964e+02],\n",
      "        [-1.0991e+03, -2.9166e+03, -4.0332e+02],\n",
      "        [-1.1377e+03, -3.0193e+03, -4.1724e+02],\n",
      "        [-1.1769e+03, -3.1238e+03, -4.3140e+02],\n",
      "        [-1.2168e+03, -3.2300e+03, -4.4580e+02],\n",
      "        [-1.2574e+03, -3.3381e+03, -4.6044e+02],\n",
      "        [-1.2987e+03, -3.4479e+03, -4.7531e+02],\n",
      "        [-1.3406e+03, -3.5595e+03, -4.9042e+02],\n",
      "        [-1.3831e+03, -3.6728e+03, -5.0576e+02],\n",
      "        [-1.4264e+03, -3.7880e+03, -5.2135e+02],\n",
      "        [-1.4703e+03, -3.9049e+03, -5.3717e+02],\n",
      "        [-1.5149e+03, -4.0236e+03, -5.5323e+02],\n",
      "        [-1.5601e+03, -4.1440e+03, -5.6952e+02],\n",
      "        [-1.6060e+03, -4.2663e+03, -5.8605e+02],\n",
      "        [-1.6526e+03, -4.3903e+03, -6.0282e+02],\n",
      "        [-1.6999e+03, -4.5161e+03, -6.1983e+02],\n",
      "        [-1.7963e+03, -4.7730e+03, -6.5455e+02],\n",
      "        [-1.8456e+03, -4.9042e+03, -6.7227e+02],\n",
      "        [-1.8955e+03, -5.0371e+03, -6.9023e+02],\n",
      "        [-1.9461e+03, -5.1718e+03, -7.0842e+02],\n",
      "        [-1.9973e+03, -5.3082e+03, -7.2685e+02],\n",
      "        [-2.0492e+03, -5.4465e+03, -7.4552e+02],\n",
      "        [-2.1018e+03, -5.5865e+03, -7.6442e+02],\n",
      "        [-2.1550e+03, -5.7283e+03, -7.8356e+02],\n",
      "        [-2.2089e+03, -5.8719e+03, -8.0294e+02],\n",
      "        [-2.2635e+03, -6.0172e+03, -8.2256e+02],\n",
      "        [-2.3187e+03, -6.1643e+03, -8.4241e+02],\n",
      "        [-2.3746e+03, -6.3132e+03, -8.6250e+02],\n",
      "        [-2.4312e+03, -6.4639e+03, -8.8283e+02],\n",
      "        [-2.4884e+03, -6.6164e+03, -9.0339e+02],\n",
      "        [-2.5463e+03, -6.7706e+03, -9.2419e+02],\n",
      "        [-2.6049e+03, -6.9266e+03, -9.4523e+02],\n",
      "        [-2.6641e+03, -7.0844e+03, -9.6651e+02],\n",
      "        [-2.7846e+03, -7.4053e+03, -1.0098e+03],\n",
      "        [-2.8458e+03, -7.5685e+03, -1.0318e+03],\n",
      "        [-2.9077e+03, -7.7334e+03, -1.0540e+03],\n",
      "        [-2.9703e+03, -7.9000e+03, -1.0764e+03],\n",
      "        [-3.0335e+03, -8.0685e+03, -1.0991e+03],\n",
      "        [-3.2272e+03, -8.5845e+03, -1.1687e+03],\n",
      "        [-3.2931e+03, -8.7601e+03, -1.1923e+03],\n",
      "        [-3.3597e+03, -8.9374e+03, -1.2162e+03],\n",
      "        [-3.4269e+03, -9.1166e+03, -1.2403e+03],\n",
      "        [-3.5634e+03, -9.4801e+03, -1.2893e+03],\n",
      "        [-3.6326e+03, -9.6646e+03, -1.3141e+03],\n",
      "        [-3.7731e+03, -1.0039e+04, -1.3645e+03],\n",
      "        [-3.8443e+03, -1.0229e+04, -1.3900e+03],\n",
      "        [-3.9162e+03, -1.0420e+04, -1.4158e+03],\n",
      "        [-4.0620e+03, -1.0809e+04, -1.4681e+03],\n",
      "        [-4.1359e+03, -1.1005e+04, -1.4946e+03],\n",
      "        [-4.2104e+03, -1.1204e+04, -1.5213e+03],\n",
      "        [-4.3615e+03, -1.1607e+04, -1.5755e+03],\n",
      "        [-4.5153e+03, -1.2017e+04, -1.6306e+03],\n",
      "        [-4.6717e+03, -1.2433e+04, -1.6867e+03],\n",
      "        [-4.7510e+03, -1.2645e+04, -1.7151e+03],\n",
      "        [-4.9926e+03, -1.3289e+04, -1.8017e+03],\n",
      "        [-5.1571e+03, -1.3727e+04, -1.8606e+03],\n",
      "        [-5.2403e+03, -1.3949e+04, -1.8904e+03],\n",
      "        [-5.3242e+03, -1.4172e+04, -1.9205e+03],\n",
      "        [-5.4939e+03, -1.4625e+04, -1.9813e+03],\n",
      "        [-5.5798e+03, -1.4853e+04, -2.0121e+03],\n",
      "        [-5.6664e+03, -1.5084e+04, -2.0431e+03],\n",
      "        [-5.8415e+03, -1.5551e+04, -2.1058e+03],\n",
      "        [-5.9300e+03, -1.5787e+04, -2.1375e+03],\n",
      "        [-6.0192e+03, -1.6025e+04, -2.1694e+03],\n",
      "        [-6.1997e+03, -1.6505e+04, -2.2340e+03],\n",
      "        [-6.3827e+03, -1.6993e+04, -2.2996e+03],\n",
      "        [-6.5685e+03, -1.7488e+04, -2.3661e+03],\n",
      "        [-6.6624e+03, -1.7739e+04, -2.3997e+03],\n",
      "        [-6.7569e+03, -1.7991e+04, -2.4336e+03],\n",
      "        [-6.8521e+03, -1.8244e+04, -2.4677e+03],\n",
      "        [-7.4374e+03, -1.9804e+04, -2.6772e+03],\n",
      "        [-7.5373e+03, -2.0070e+04, -2.7129e+03],\n",
      "        [-8.1505e+03, -2.1705e+04, -2.9324e+03],\n",
      "        [-8.2550e+03, -2.1984e+04, -2.9698e+03],\n",
      "        [-8.3602e+03, -2.2264e+04, -3.0074e+03],\n",
      "        [-9.2258e+03, -2.4571e+04, -3.3171e+03],\n",
      "        [-9.3370e+03, -2.4868e+04, -3.3569e+03],\n",
      "        [-9.4489e+03, -2.5166e+04, -3.3969e+03],\n",
      "        [-1.0723e+04, -2.8564e+04, -3.8527e+03],\n",
      "        [-1.1207e+04, -2.9852e+04, -4.0256e+03],\n",
      "        [-1.1329e+04, -3.0179e+04, -4.0694e+03],\n",
      "        [-1.2334e+04, -3.2856e+04, -4.4284e+03],\n",
      "        [-1.2721e+04, -3.3889e+04, -4.5669e+03],\n",
      "        [-1.3380e+04, -3.5647e+04, -4.8026e+03],\n",
      "        [-1.3784e+04, -3.6723e+04, -4.9468e+03],\n",
      "        [-1.3920e+04, -3.7085e+04, -4.9954e+03],\n",
      "        [-1.4056e+04, -3.7449e+04, -5.0442e+03],\n",
      "        [-1.4193e+04, -3.7814e+04, -5.0932e+03],\n",
      "        [-1.5458e+04, -4.1186e+04, -5.5451e+03],\n",
      "        [-1.7532e+04, -4.6717e+04, -6.2863e+03],\n",
      "        [-1.8619e+04, -4.9613e+04, -6.6744e+03],\n",
      "        [-1.9738e+04, -5.2596e+04, -7.0740e+03]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "-43:the loss_1 is : tensor([[3.0773e-01, 4.9507e-01, 1.6395e-01],\n",
      "        [1.6761e-01, 1.2290e-01, 1.0962e-01],\n",
      "        [4.6894e-02, 5.1594e-03, 5.7823e-02],\n",
      "        [6.7389e-03, 3.6626e-05, 2.4059e-02],\n",
      "        [4.9743e-04, 4.3968e-08, 7.8966e-03],\n",
      "        [1.8860e-05, 8.9254e-12, 2.0445e-03],\n",
      "        [3.6729e-07, 3.0638e-16, 4.1757e-04],\n",
      "        [3.6741e-09, 1.7785e-21, 6.7273e-05],\n",
      "        [1.8878e-11, 1.7458e-27, 8.5496e-06],\n",
      "        [4.9824e-14, 2.8979e-34, 8.5710e-07],\n",
      "        [6.7544e-17, 8.1345e-42, 6.7781e-08],\n",
      "        [4.7032e-20, 0.0000e+00, 4.2283e-09],\n",
      "        [1.6822e-23, 0.0000e+00, 2.0807e-10],\n",
      "        [3.0904e-27, 0.0000e+00, 8.0767e-12],\n",
      "        [2.9163e-31, 0.0000e+00, 2.4731e-13],\n",
      "        [1.4135e-35, 0.0000e+00, 5.9737e-15],\n",
      "        [3.5192e-40, 0.0000e+00, 1.1382e-16],\n",
      "        [4.2039e-45, 0.0000e+00, 1.7108e-18],\n",
      "        [0.0000e+00, 0.0000e+00, 2.0284e-20],\n",
      "        [0.0000e+00, 0.0000e+00, 1.8971e-22],\n",
      "        [0.0000e+00, 0.0000e+00, 1.3996e-24],\n",
      "        [0.0000e+00, 0.0000e+00, 8.1454e-27],\n",
      "        [0.0000e+00, 0.0000e+00, 3.7394e-29],\n",
      "        [0.0000e+00, 0.0000e+00, 1.3542e-31],\n",
      "        [0.0000e+00, 0.0000e+00, 3.8685e-34],\n",
      "        [0.0000e+00, 0.0000e+00, 8.7175e-37],\n",
      "        [0.0000e+00, 0.0000e+00, 1.5496e-39],\n",
      "        [0.0000e+00, 0.0000e+00, 2.1734e-42],\n",
      "        [0.0000e+00, 0.0000e+00, 2.8026e-45],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>)\n",
      "--43: the result of GMM by hand: tensor([2.6687e-01, 1.2747e-01, 4.4589e-02, 1.4783e-02, 4.3996e-03, 1.1102e-03,\n",
      "        2.2583e-04, 3.6369e-05, 4.6219e-06, 4.6335e-07, 3.6642e-08, 2.2858e-09,\n",
      "        1.1248e-10, 4.3663e-12, 1.3370e-13, 3.2294e-15, 6.1532e-17, 9.2485e-19,\n",
      "        1.0965e-20, 1.0256e-22, 7.5663e-25, 4.4034e-27, 2.0215e-29, 7.3208e-32,\n",
      "        2.0913e-34, 4.7127e-37, 8.3772e-40, 1.1743e-42, 1.4013e-45, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00], device='cuda:0',\n",
      "       grad_fn=<SumBackward1>)\n",
      "-43:the loss_2 is : tensor([2.6687e-01, 1.2747e-01, 4.4589e-02, 1.4783e-02, 4.3996e-03, 1.1102e-03,\n",
      "        2.2583e-04, 3.6369e-05, 4.6219e-06, 4.6335e-07, 3.6642e-08, 2.2858e-09,\n",
      "        1.1248e-10, 4.3663e-12, 1.3370e-13, 3.2294e-15, 6.1532e-17, 9.2485e-19,\n",
      "        1.0965e-20, 1.0256e-22, 7.5663e-25, 4.4034e-27, 2.0215e-29, 7.3209e-32,\n",
      "        2.0913e-34, 4.7127e-37, 8.3773e-40, 1.1743e-42, 1.4013e-45, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00], device='cuda:0',\n",
      "       grad_fn=<SumBackward1>)\n",
      "-43:the loss is : tensor([nan], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-44:target_unpadded shape: torch.Size([153, 3])\n",
      "-44:the m[i].log_prob(target_unpadded) is : tensor([[-5.2758e+01, -1.0656e+02, -1.0437e+01],\n",
      "        [-2.6567e+02, -5.5369e+02, -4.2665e+01],\n",
      "        [-4.3381e+02, -9.0836e+02, -6.7733e+01],\n",
      "        [-7.2195e+02, -1.5172e+03, -1.1044e+02],\n",
      "        [-1.1849e+03, -2.4967e+03, -1.7875e+02],\n",
      "        [-1.2375e+03, -2.6080e+03, -1.8650e+02],\n",
      "        [-1.2912e+03, -2.7218e+03, -1.9441e+02],\n",
      "        [-1.6993e+03, -3.5859e+03, -2.5441e+02],\n",
      "        [-1.8262e+03, -3.8546e+03, -2.7305e+02],\n",
      "        [-2.9233e+03, -6.1797e+03, -4.3396e+02],\n",
      "        [-3.4341e+03, -7.2627e+03, -5.0878e+02],\n",
      "        [-4.0820e+03, -8.6366e+03, -6.0360e+02],\n",
      "        [-4.3768e+03, -9.2619e+03, -6.4673e+02],\n",
      "        [-4.6819e+03, -9.9090e+03, -6.9135e+02],\n",
      "        [-6.3616e+03, -1.3472e+04, -9.3683e+02],\n",
      "        [-6.6049e+03, -1.3989e+04, -9.7238e+02],\n",
      "        [-1.0338e+04, -2.1910e+04, -1.5172e+03],\n",
      "        [-1.1280e+04, -2.3911e+04, -1.6547e+03],\n",
      "        [-1.1767e+04, -2.4944e+04, -1.7257e+03],\n",
      "        [-1.2264e+04, -2.5999e+04, -1.7982e+03],\n",
      "        [-1.2601e+04, -2.6714e+04, -1.8473e+03],\n",
      "        [-1.4174e+04, -3.0054e+04, -2.0767e+03],\n",
      "        [-1.5274e+04, -3.2389e+04, -2.2371e+03],\n",
      "        [-1.7799e+04, -3.7750e+04, -2.6050e+03],\n",
      "        [-2.0952e+04, -4.4445e+04, -3.0644e+03],\n",
      "        [-2.1172e+04, -4.4911e+04, -3.0964e+03],\n",
      "        [-2.1837e+04, -4.6322e+04, -3.1932e+03],\n",
      "        [-2.2968e+04, -4.8724e+04, -3.3579e+03],\n",
      "        [-2.3197e+04, -4.9212e+04, -3.3914e+03],\n",
      "        [-2.3428e+04, -4.9702e+04, -3.4250e+03],\n",
      "        [-2.5798e+04, -5.4735e+04, -3.7702e+03],\n",
      "        [-2.9051e+04, -6.1642e+04, -4.2438e+03],\n",
      "        [-3.1954e+04, -6.7807e+04, -4.6664e+03],\n",
      "        [-3.3595e+04, -7.1294e+04, -4.9054e+03],\n",
      "        [-3.4995e+04, -7.4266e+04, -5.1091e+03],\n",
      "        [-3.5848e+04, -7.6078e+04, -5.2333e+03],\n",
      "        [-3.9065e+04, -8.2910e+04, -5.7015e+03],\n",
      "        [-4.0269e+04, -8.5468e+04, -5.8767e+03],\n",
      "        [-4.0573e+04, -8.6113e+04, -5.9210e+03],\n",
      "        [-4.2732e+04, -9.0699e+04, -6.2352e+03],\n",
      "        [-4.3359e+04, -9.2031e+04, -6.3264e+03],\n",
      "        [-4.3675e+04, -9.2701e+04, -6.3723e+03],\n",
      "        [-4.4947e+04, -9.5404e+04, -6.5575e+03],\n",
      "        [-4.5914e+04, -9.7456e+04, -6.6981e+03],\n",
      "        [-5.2619e+04, -1.1170e+05, -7.6738e+03],\n",
      "        [-5.4367e+04, -1.1541e+05, -7.9281e+03],\n",
      "        [-5.7585e+04, -1.2225e+05, -8.3962e+03],\n",
      "        [-5.9782e+04, -1.2691e+05, -8.7158e+03],\n",
      "        [-6.1269e+04, -1.3007e+05, -8.9321e+03],\n",
      "        [-6.5841e+04, -1.3978e+05, -9.5971e+03],\n",
      "        [-6.7794e+04, -1.4393e+05, -9.8812e+03],\n",
      "        [-7.1382e+04, -1.5156e+05, -1.0403e+04],\n",
      "        [-7.2599e+04, -1.5414e+05, -1.0580e+04],\n",
      "        [-7.6311e+04, -1.6203e+05, -1.1120e+04],\n",
      "        [-7.6729e+04, -1.6291e+05, -1.1181e+04],\n",
      "        [-7.8412e+04, -1.6649e+05, -1.1425e+04],\n",
      "        [-7.9261e+04, -1.6829e+05, -1.1549e+04],\n",
      "        [-7.9687e+04, -1.6920e+05, -1.1611e+04],\n",
      "        [-8.0543e+04, -1.7102e+05, -1.1735e+04],\n",
      "        [-8.7552e+04, -1.8591e+05, -1.2755e+04],\n",
      "        [-8.9350e+04, -1.8973e+05, -1.3016e+04],\n",
      "        [-8.9803e+04, -1.9069e+05, -1.3082e+04],\n",
      "        [-9.1624e+04, -1.9456e+05, -1.3347e+04],\n",
      "        [-9.2082e+04, -1.9553e+05, -1.3413e+04],\n",
      "        [-9.3463e+04, -1.9846e+05, -1.3614e+04],\n",
      "        [-9.7196e+04, -2.0639e+05, -1.4157e+04],\n",
      "        [-1.0100e+05, -2.1448e+05, -1.4710e+04],\n",
      "        [-1.1033e+05, -2.3431e+05, -1.6067e+04],\n",
      "        [-1.1134e+05, -2.3645e+05, -1.6214e+04],\n",
      "        [-1.1286e+05, -2.3967e+05, -1.6434e+04],\n",
      "        [-1.1337e+05, -2.4075e+05, -1.6508e+04],\n",
      "        [-1.1541e+05, -2.4509e+05, -1.6805e+04],\n",
      "        [-1.1644e+05, -2.4728e+05, -1.6955e+04],\n",
      "        [-1.2166e+05, -2.5836e+05, -1.7713e+04],\n",
      "        [-1.2377e+05, -2.6286e+05, -1.8021e+04],\n",
      "        [-1.2752e+05, -2.7083e+05, -1.8566e+04],\n",
      "        [-1.3024e+05, -2.7659e+05, -1.8961e+04],\n",
      "        [-1.5061e+05, -3.1988e+05, -2.1923e+04],\n",
      "        [-1.5120e+05, -3.2113e+05, -2.2008e+04],\n",
      "        [-1.5415e+05, -3.2740e+05, -2.2437e+04],\n",
      "        [-1.5594e+05, -3.3120e+05, -2.2697e+04],\n",
      "        [-1.5834e+05, -3.3629e+05, -2.3045e+04],\n",
      "        [-1.5894e+05, -3.3757e+05, -2.3133e+04],\n",
      "        [-1.6136e+05, -3.4271e+05, -2.3484e+04],\n",
      "        [-1.6380e+05, -3.4789e+05, -2.3838e+04],\n",
      "        [-1.6873e+05, -3.5836e+05, -2.4555e+04],\n",
      "        [-1.7122e+05, -3.6366e+05, -2.4917e+04],\n",
      "        [-1.7689e+05, -3.7572e+05, -2.5742e+04],\n",
      "        [-1.7753e+05, -3.7707e+05, -2.5835e+04],\n",
      "        [-1.8331e+05, -3.8935e+05, -2.6674e+04],\n",
      "        [-1.8395e+05, -3.9072e+05, -2.6769e+04],\n",
      "        [-1.9447e+05, -4.1307e+05, -2.8297e+04],\n",
      "        [-1.9782e+05, -4.2018e+05, -2.8784e+04],\n",
      "        [-2.0872e+05, -4.4335e+05, -3.0368e+04],\n",
      "        [-2.1149e+05, -4.4923e+05, -3.0771e+04],\n",
      "        [-2.2134e+05, -4.7015e+05, -3.2201e+04],\n",
      "        [-2.2850e+05, -4.8538e+05, -3.3243e+04],\n",
      "        [-2.3652e+05, -5.0241e+05, -3.4408e+04],\n",
      "        [-2.4994e+05, -5.3092e+05, -3.6357e+04],\n",
      "        [-2.5373e+05, -5.3898e+05, -3.6909e+04],\n",
      "        [-2.5678e+05, -5.4547e+05, -3.7352e+04],\n",
      "        [-2.6997e+05, -5.7348e+05, -3.9268e+04],\n",
      "        [-2.8915e+05, -6.1423e+05, -4.2055e+04],\n",
      "        [-2.9733e+05, -6.3162e+05, -4.3244e+04],\n",
      "        [-3.0563e+05, -6.4926e+05, -4.4450e+04],\n",
      "        [-3.2601e+05, -6.9257e+05, -4.7412e+04],\n",
      "        [-3.3557e+05, -7.1289e+05, -4.8801e+04],\n",
      "        [-3.3645e+05, -7.1475e+05, -4.8928e+04],\n",
      "        [-3.3997e+05, -7.2222e+05, -4.9439e+04],\n",
      "        [-3.4794e+05, -7.3917e+05, -5.0598e+04],\n",
      "        [-3.5601e+05, -7.5632e+05, -5.1771e+04],\n",
      "        [-3.6054e+05, -7.6593e+05, -5.2428e+04],\n",
      "        [-3.6327e+05, -7.7173e+05, -5.2824e+04],\n",
      "        [-3.7985e+05, -8.0696e+05, -5.5233e+04],\n",
      "        [-4.0445e+05, -8.5925e+05, -5.8808e+04],\n",
      "        [-4.3082e+05, -9.1528e+05, -6.2639e+04],\n",
      "        [-4.3480e+05, -9.2373e+05, -6.3217e+04],\n",
      "        [-4.4281e+05, -9.4075e+05, -6.4381e+04],\n",
      "        [-4.5089e+05, -9.5793e+05, -6.5555e+04],\n",
      "        [-4.6728e+05, -9.9275e+05, -6.7935e+04],\n",
      "        [-4.7038e+05, -9.9934e+05, -6.8386e+04],\n",
      "        [-4.7558e+05, -1.0104e+06, -6.9141e+04],\n",
      "        [-4.8396e+05, -1.0282e+06, -7.0358e+04],\n",
      "        [-4.9559e+05, -1.0529e+06, -7.2048e+04],\n",
      "        [-5.5923e+05, -1.1881e+06, -8.1292e+04],\n",
      "        [-5.6717e+05, -1.2050e+06, -8.2446e+04],\n",
      "        [-5.9248e+05, -1.2588e+06, -8.6124e+04],\n",
      "        [-6.0888e+05, -1.2937e+06, -8.8506e+04],\n",
      "        [-6.2074e+05, -1.3188e+06, -9.0227e+04],\n",
      "        [-6.3150e+05, -1.3417e+06, -9.1791e+04],\n",
      "        [-6.3390e+05, -1.3468e+06, -9.2140e+04],\n",
      "        [-6.6188e+05, -1.4063e+06, -9.6205e+04],\n",
      "        [-6.7052e+05, -1.4246e+06, -9.7459e+04],\n",
      "        [-6.7672e+05, -1.4378e+06, -9.8360e+04],\n",
      "        [-6.8670e+05, -1.4590e+06, -9.9810e+04],\n",
      "        [-7.0816e+05, -1.5046e+06, -1.0293e+05],\n",
      "        [-7.1966e+05, -1.5291e+06, -1.0460e+05],\n",
      "        [-7.2351e+05, -1.5372e+06, -1.0516e+05],\n",
      "        [-7.5338e+05, -1.6007e+06, -1.0949e+05],\n",
      "        [-8.0813e+05, -1.7171e+06, -1.1745e+05],\n",
      "        [-8.1767e+05, -1.7373e+06, -1.1883e+05],\n",
      "        [-8.2726e+05, -1.7577e+06, -1.2023e+05],\n",
      "        [-8.4245e+05, -1.7900e+06, -1.2243e+05],\n",
      "        [-8.9028e+05, -1.8916e+06, -1.2938e+05],\n",
      "        [-9.0173e+05, -1.9160e+06, -1.3104e+05],\n",
      "        [-1.0572e+06, -2.2463e+06, -1.5362e+05],\n",
      "        [-1.0838e+06, -2.3028e+06, -1.5748e+05],\n",
      "        [-1.1043e+06, -2.3465e+06, -1.6046e+05],\n",
      "        [-1.1283e+06, -2.3974e+06, -1.6394e+05],\n",
      "        [-1.1363e+06, -2.4145e+06, -1.6511e+05],\n",
      "        [-1.4740e+06, -3.1322e+06, -2.1416e+05],\n",
      "        [-2.0521e+06, -4.3606e+06, -2.9810e+05],\n",
      "        [-2.2674e+06, -4.8183e+06, -3.2938e+05]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "-44:the loss_1 is : tensor([[1.2234e-23, 0.0000e+00, 2.9318e-05],\n",
      "        [0.0000e+00, 0.0000e+00, 2.9563e-19],\n",
      "        [0.0000e+00, 0.0000e+00, 3.8358e-30],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>)\n",
      "--44: the result of GMM by hand: tensor([1.5280e-05, 1.5408e-19, 1.9991e-30, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00], device='cuda:0',\n",
      "       grad_fn=<SumBackward1>)\n",
      "-44:the loss_2 is : tensor([1.5280e-05, 1.5408e-19, 1.9991e-30, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00], device='cuda:0',\n",
      "       grad_fn=<SumBackward1>)\n",
      "-44:the loss is : tensor([nan], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-45:target_unpadded shape: torch.Size([178, 3])\n",
      "-45:the m[i].log_prob(target_unpadded) is : tensor([[-1.0312e+02, -2.5664e+02, -3.0813e+01],\n",
      "        [-6.1705e+02, -1.5714e+03, -1.6887e+02],\n",
      "        [-2.4362e+03, -6.2448e+03, -6.5134e+02],\n",
      "        [-1.1448e+04, -2.9440e+04, -3.0269e+03],\n",
      "        [-1.6817e+04, -4.3270e+04, -4.4398e+03],\n",
      "        [-1.9630e+04, -5.0514e+04, -5.1794e+03],\n",
      "        [-2.4543e+04, -6.3171e+04, -6.4713e+03],\n",
      "        [-3.0004e+04, -7.7242e+04, -7.9069e+03],\n",
      "        [-4.9678e+04, -1.2794e+05, -1.3076e+04],\n",
      "        [-5.1610e+04, -1.3291e+05, -1.3584e+04],\n",
      "        [-7.5967e+04, -1.9569e+05, -1.9980e+04],\n",
      "        [-7.7667e+04, -2.0007e+05, -2.0427e+04],\n",
      "        [-8.1822e+04, -2.1078e+05, -2.1518e+04],\n",
      "        [-1.1897e+05, -3.0651e+05, -3.1269e+04],\n",
      "        [-1.3649e+05, -3.5167e+05, -3.5868e+04],\n",
      "        [-1.3968e+05, -3.5989e+05, -3.6705e+04],\n",
      "        [-1.4290e+05, -3.6821e+05, -3.7552e+04],\n",
      "        [-1.6008e+05, -4.1249e+05, -4.2061e+04],\n",
      "        [-1.7412e+05, -4.4866e+05, -4.5744e+04],\n",
      "        [-1.7979e+05, -4.6329e+05, -4.7233e+04],\n",
      "        [-2.7454e+05, -7.0754e+05, -7.2098e+04],\n",
      "        [-2.8166e+05, -7.2588e+05, -7.3964e+04],\n",
      "        [-2.9084e+05, -7.4956e+05, -7.6374e+04],\n",
      "        [-3.1583e+05, -8.1397e+05, -8.2930e+04],\n",
      "        [-3.4400e+05, -8.8659e+05, -9.0321e+04],\n",
      "        [-3.9465e+05, -1.0172e+06, -1.0361e+05],\n",
      "        [-4.2367e+05, -1.0920e+06, -1.1122e+05],\n",
      "        [-4.6453e+05, -1.1973e+06, -1.2194e+05],\n",
      "        [-4.6788e+05, -1.2059e+06, -1.2282e+05],\n",
      "        [-4.7292e+05, -1.2189e+06, -1.2414e+05],\n",
      "        [-5.2844e+05, -1.3621e+06, -1.3871e+05],\n",
      "        [-5.9363e+05, -1.5301e+06, -1.5581e+05],\n",
      "        [-6.0503e+05, -1.5595e+06, -1.5880e+05],\n",
      "        [-6.6462e+05, -1.7131e+06, -1.7443e+05],\n",
      "        [-7.2701e+05, -1.8740e+06, -1.9080e+05],\n",
      "        [-7.5019e+05, -1.9338e+06, -1.9688e+05],\n",
      "        [-8.6702e+05, -2.2349e+06, -2.2752e+05],\n",
      "        [-8.7617e+05, -2.2586e+06, -2.2992e+05],\n",
      "        [-1.0009e+06, -2.5800e+06, -2.6262e+05],\n",
      "        [-1.0181e+06, -2.6245e+06, -2.6715e+05],\n",
      "        [-1.0231e+06, -2.6373e+06, -2.6845e+05],\n",
      "        [-1.0518e+06, -2.7113e+06, -2.7598e+05],\n",
      "        [-1.2834e+06, -3.3085e+06, -3.3673e+05],\n",
      "        [-1.3029e+06, -3.3588e+06, -3.4186e+05],\n",
      "        [-1.4101e+06, -3.6350e+06, -3.6995e+05],\n",
      "        [-1.4734e+06, -3.7982e+06, -3.8655e+05],\n",
      "        [-1.4868e+06, -3.8328e+06, -3.9007e+05],\n",
      "        [-1.7051e+06, -4.3958e+06, -4.4733e+05],\n",
      "        [-1.7180e+06, -4.4288e+06, -4.5070e+05],\n",
      "        [-1.7438e+06, -4.4954e+06, -4.5747e+05],\n",
      "        [-1.8556e+06, -4.7838e+06, -4.8681e+05],\n",
      "        [-1.8842e+06, -4.8573e+06, -4.9428e+05],\n",
      "        [-1.8909e+06, -4.8747e+06, -4.9605e+05],\n",
      "        [-1.9146e+06, -4.9358e+06, -5.0226e+05],\n",
      "        [-1.9367e+06, -4.9928e+06, -5.0807e+05],\n",
      "        [-2.0317e+06, -5.2378e+06, -5.3298e+05],\n",
      "        [-2.2377e+06, -5.7689e+06, -5.8701e+05],\n",
      "        [-2.2543e+06, -5.8115e+06, -5.9134e+05],\n",
      "        [-2.2690e+06, -5.8496e+06, -5.9521e+05],\n",
      "        [-2.3360e+06, -6.0223e+06, -6.1278e+05],\n",
      "        [-2.5821e+06, -6.6568e+06, -6.7732e+05],\n",
      "        [-2.6435e+06, -6.8152e+06, -6.9343e+05],\n",
      "        [-2.6455e+06, -6.8204e+06, -6.9396e+05],\n",
      "        [-2.6615e+06, -6.8616e+06, -6.9815e+05],\n",
      "        [-2.6816e+06, -6.9133e+06, -7.0340e+05],\n",
      "        [-2.7118e+06, -6.9912e+06, -7.1133e+05],\n",
      "        [-2.8219e+06, -7.2752e+06, -7.4021e+05],\n",
      "        [-2.9154e+06, -7.5162e+06, -7.6473e+05],\n",
      "        [-2.9385e+06, -7.5757e+06, -7.7078e+05],\n",
      "        [-3.2071e+06, -8.2684e+06, -8.4123e+05],\n",
      "        [-3.2601e+06, -8.4048e+06, -8.5511e+05],\n",
      "        [-3.3268e+06, -8.5770e+06, -8.7262e+05],\n",
      "        [-3.4192e+06, -8.8151e+06, -8.9684e+05],\n",
      "        [-3.4898e+06, -8.9973e+06, -9.1537e+05],\n",
      "        [-3.4990e+06, -9.0209e+06, -9.1777e+05],\n",
      "        [-3.7014e+06, -9.5428e+06, -9.7086e+05],\n",
      "        [-3.8012e+06, -9.8001e+06, -9.9702e+05],\n",
      "        [-3.8300e+06, -9.8742e+06, -1.0046e+06],\n",
      "        [-3.8324e+06, -9.8804e+06, -1.0052e+06],\n",
      "        [-3.9266e+06, -1.0123e+07, -1.0299e+06],\n",
      "        [-4.0121e+06, -1.0344e+07, -1.0523e+06],\n",
      "        [-4.0367e+06, -1.0407e+07, -1.0588e+06],\n",
      "        [-4.0688e+06, -1.0490e+07, -1.0672e+06],\n",
      "        [-4.1184e+06, -1.0618e+07, -1.0802e+06],\n",
      "        [-4.1558e+06, -1.0714e+07, -1.0900e+06],\n",
      "        [-4.3072e+06, -1.1105e+07, -1.1297e+06],\n",
      "        [-4.3506e+06, -1.1216e+07, -1.1411e+06],\n",
      "        [-4.3916e+06, -1.1322e+07, -1.1518e+06],\n",
      "        [-4.4380e+06, -1.1442e+07, -1.1640e+06],\n",
      "        [-4.5393e+06, -1.1703e+07, -1.1906e+06],\n",
      "        [-4.6444e+06, -1.1974e+07, -1.2181e+06],\n",
      "        [-4.6497e+06, -1.1988e+07, -1.2195e+06],\n",
      "        [-4.7534e+06, -1.2255e+07, -1.2467e+06],\n",
      "        [-4.7561e+06, -1.2262e+07, -1.2474e+06],\n",
      "        [-5.0163e+06, -1.2933e+07, -1.3157e+06],\n",
      "        [-5.4082e+06, -1.3944e+07, -1.4184e+06],\n",
      "        [-5.6563e+06, -1.4583e+07, -1.4835e+06],\n",
      "        [-5.7795e+06, -1.4901e+07, -1.5158e+06],\n",
      "        [-6.1448e+06, -1.5843e+07, -1.6116e+06],\n",
      "        [-6.2608e+06, -1.6142e+07, -1.6420e+06],\n",
      "        [-6.4152e+06, -1.6540e+07, -1.6825e+06],\n",
      "        [-6.7646e+06, -1.7441e+07, -1.7741e+06],\n",
      "        [-6.7902e+06, -1.7507e+07, -1.7808e+06],\n",
      "        [-6.8414e+06, -1.7639e+07, -1.7942e+06],\n",
      "        [-7.0092e+06, -1.8071e+07, -1.8382e+06],\n",
      "        [-7.2582e+06, -1.8713e+07, -1.9035e+06],\n",
      "        [-7.3909e+06, -1.9056e+07, -1.9383e+06],\n",
      "        [-7.8617e+06, -2.0269e+07, -2.0617e+06],\n",
      "        [-8.1497e+06, -2.1012e+07, -2.1373e+06],\n",
      "        [-8.1882e+06, -2.1111e+07, -2.1474e+06],\n",
      "        [-8.3080e+06, -2.1420e+07, -2.1788e+06],\n",
      "        [-8.4857e+06, -2.1878e+07, -2.2254e+06],\n",
      "        [-8.5752e+06, -2.2109e+07, -2.2488e+06],\n",
      "        [-8.7993e+06, -2.2687e+07, -2.3076e+06],\n",
      "        [-8.9381e+06, -2.3045e+07, -2.3440e+06],\n",
      "        [-9.2376e+06, -2.3817e+07, -2.4225e+06],\n",
      "        [-9.5799e+06, -2.4700e+07, -2.5123e+06],\n",
      "        [-9.5875e+06, -2.4719e+07, -2.5143e+06],\n",
      "        [-1.0002e+07, -2.5788e+07, -2.6230e+06],\n",
      "        [-1.0049e+07, -2.5908e+07, -2.6352e+06],\n",
      "        [-1.0437e+07, -2.6910e+07, -2.7371e+06],\n",
      "        [-1.1064e+07, -2.8527e+07, -2.9015e+06],\n",
      "        [-1.1101e+07, -2.8622e+07, -2.9112e+06],\n",
      "        [-1.1735e+07, -3.0257e+07, -3.0774e+06],\n",
      "        [-1.2469e+07, -3.2148e+07, -3.2698e+06],\n",
      "        [-1.3203e+07, -3.4040e+07, -3.4622e+06],\n",
      "        [-1.3921e+07, -3.5892e+07, -3.6504e+06],\n",
      "        [-1.4090e+07, -3.6330e+07, -3.6950e+06],\n",
      "        [-1.5342e+07, -3.9556e+07, -4.0230e+06],\n",
      "        [-1.5660e+07, -4.0377e+07, -4.1066e+06],\n",
      "        [-1.6223e+07, -4.1829e+07, -4.2542e+06],\n",
      "        [-1.7191e+07, -4.4323e+07, -4.5079e+06],\n",
      "        [-1.7863e+07, -4.6058e+07, -4.6842e+06],\n",
      "        [-1.9070e+07, -4.9169e+07, -5.0006e+06],\n",
      "        [-1.9724e+07, -5.0854e+07, -5.1720e+06],\n",
      "        [-2.0549e+07, -5.2983e+07, -5.3884e+06],\n",
      "        [-2.1516e+07, -5.5477e+07, -5.6421e+06],\n",
      "        [-2.1876e+07, -5.6405e+07, -5.7364e+06],\n",
      "        [-2.3792e+07, -6.1345e+07, -6.2388e+06],\n",
      "        [-2.4540e+07, -6.3272e+07, -6.4348e+06],\n",
      "        [-2.6763e+07, -6.9005e+07, -7.0177e+06],\n",
      "        [-2.6934e+07, -6.9447e+07, -7.0627e+06],\n",
      "        [-2.9036e+07, -7.4866e+07, -7.6137e+06],\n",
      "        [-2.9601e+07, -7.6322e+07, -7.7617e+06],\n",
      "        [-2.9928e+07, -7.7167e+07, -7.8477e+06],\n",
      "        [-3.0016e+07, -7.7392e+07, -7.8706e+06],\n",
      "        [-3.9942e+07, -1.0299e+08, -1.0473e+07],\n",
      "        [-4.0097e+07, -1.0339e+08, -1.0514e+07],\n",
      "        [-4.0487e+07, -1.0439e+08, -1.0616e+07],\n",
      "        [-4.2023e+07, -1.0835e+08, -1.1019e+07],\n",
      "        [-4.5428e+07, -1.1713e+08, -1.1912e+07],\n",
      "        [-4.6192e+07, -1.1910e+08, -1.2112e+07],\n",
      "        [-4.9258e+07, -1.2701e+08, -1.2916e+07],\n",
      "        [-5.0305e+07, -1.2971e+08, -1.3190e+07],\n",
      "        [-5.0933e+07, -1.3133e+08, -1.3355e+07],\n",
      "        [-5.2219e+07, -1.3464e+08, -1.3692e+07],\n",
      "        [-5.2574e+07, -1.3556e+08, -1.3785e+07],\n",
      "        [-5.2993e+07, -1.3664e+08, -1.3895e+07],\n",
      "        [-5.3503e+07, -1.3795e+08, -1.4029e+07],\n",
      "        [-5.4649e+07, -1.4091e+08, -1.4329e+07],\n",
      "        [-5.5541e+07, -1.4321e+08, -1.4563e+07],\n",
      "        [-5.7087e+07, -1.4719e+08, -1.4968e+07],\n",
      "        [-6.0787e+07, -1.5673e+08, -1.5938e+07],\n",
      "        [-6.2831e+07, -1.6200e+08, -1.6474e+07],\n",
      "        [-6.9441e+07, -1.7905e+08, -1.8207e+07],\n",
      "        [-7.1438e+07, -1.8420e+08, -1.8731e+07],\n",
      "        [-7.7296e+07, -1.9930e+08, -2.0267e+07],\n",
      "        [-7.7685e+07, -2.0030e+08, -2.0369e+07],\n",
      "        [-9.1397e+07, -2.3566e+08, -2.3964e+07],\n",
      "        [-9.1490e+07, -2.3590e+08, -2.3988e+07],\n",
      "        [-9.2526e+07, -2.3857e+08, -2.4260e+07],\n",
      "        [-9.4757e+07, -2.4432e+08, -2.4845e+07],\n",
      "        [-1.0606e+08, -2.7346e+08, -2.7808e+07],\n",
      "        [-1.2131e+08, -3.1279e+08, -3.1807e+07],\n",
      "        [-1.6311e+08, -4.2057e+08, -4.2766e+07],\n",
      "        [-2.0332e+08, -5.2426e+08, -5.3309e+07],\n",
      "        [-2.0617e+08, -5.3159e+08, -5.4054e+07],\n",
      "        [-2.4503e+08, -6.3181e+08, -6.4245e+07]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "-45:the loss_1 is : tensor([[1.4013e-45, 0.0000e+00, 4.1486e-14],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>)\n",
      "--45: the result of GMM by hand: tensor([2.2271e-14, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00], device='cuda:0',\n",
      "       grad_fn=<SumBackward1>)\n",
      "-45:the loss_2 is : tensor([2.2271e-14, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00], device='cuda:0',\n",
      "       grad_fn=<SumBackward1>)\n",
      "-45:the loss is : tensor([nan], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-46:target_unpadded shape: torch.Size([207, 3])\n",
      "-46:the m[i].log_prob(target_unpadded) is : tensor([[-1.2863e+02, -4.2532e+02, -3.3806e+01],\n",
      "        [-7.0948e+02, -2.3681e+03, -1.6942e+02],\n",
      "        [-7.4248e+02, -2.4785e+03, -1.7705e+02],\n",
      "        [-1.6585e+03, -5.5448e+03, -3.8804e+02],\n",
      "        [-1.7598e+03, -5.8839e+03, -4.1130e+02],\n",
      "        [-1.9174e+03, -6.4116e+03, -4.4747e+02],\n",
      "        [-1.9715e+03, -6.5925e+03, -4.5987e+02],\n",
      "        [-2.3114e+03, -7.7308e+03, -5.3782e+02],\n",
      "        [-2.4308e+03, -8.1303e+03, -5.6516e+02],\n",
      "        [-2.7422e+03, -9.1733e+03, -6.3649e+02],\n",
      "        [-3.5664e+03, -1.1933e+04, -8.2504e+02],\n",
      "        [-3.9417e+03, -1.3190e+04, -9.1082e+02],\n",
      "        [-4.7488e+03, -1.5893e+04, -1.0952e+03],\n",
      "        [-4.9192e+03, -1.6463e+04, -1.1341e+03],\n",
      "        [-5.0926e+03, -1.7044e+04, -1.1736e+03],\n",
      "        [-5.7232e+03, -1.9156e+04, -1.3176e+03],\n",
      "        [-5.8163e+03, -1.9468e+04, -1.3388e+03],\n",
      "        [-6.1962e+03, -2.0740e+04, -1.4254e+03],\n",
      "        [-6.2931e+03, -2.1065e+04, -1.4475e+03],\n",
      "        [-6.7886e+03, -2.2724e+04, -1.5605e+03],\n",
      "        [-8.0545e+03, -2.6964e+04, -1.8491e+03],\n",
      "        [-8.8428e+03, -2.9605e+04, -2.0287e+03],\n",
      "        [-1.0405e+04, -3.4836e+04, -2.3843e+03],\n",
      "        [-1.1298e+04, -3.7829e+04, -2.5878e+03],\n",
      "        [-1.1429e+04, -3.8267e+04, -2.6175e+03],\n",
      "        [-1.2364e+04, -4.1401e+04, -2.8305e+03],\n",
      "        [-1.3909e+04, -4.6575e+04, -3.1819e+03],\n",
      "        [-1.4493e+04, -4.8532e+04, -3.3148e+03],\n",
      "        [-1.4939e+04, -5.0026e+04, -3.4163e+03],\n",
      "        [-1.5698e+04, -5.2567e+04, -3.5888e+03],\n",
      "        [-1.6162e+04, -5.4121e+04, -3.6943e+03],\n",
      "        [-1.6318e+04, -5.4644e+04, -3.7299e+03],\n",
      "        [-1.7758e+04, -5.9467e+04, -4.0572e+03],\n",
      "        [-1.9429e+04, -6.5064e+04, -4.4371e+03],\n",
      "        [-2.0643e+04, -6.9132e+04, -4.7131e+03],\n",
      "        [-2.2258e+04, -7.4543e+04, -5.0803e+03],\n",
      "        [-2.2810e+04, -7.6392e+04, -5.2057e+03],\n",
      "        [-2.3934e+04, -8.0158e+04, -5.4612e+03],\n",
      "        [-2.4315e+04, -8.1434e+04, -5.5477e+03],\n",
      "        [-2.4699e+04, -8.2719e+04, -5.6349e+03],\n",
      "        [-2.6663e+04, -8.9298e+04, -6.0811e+03],\n",
      "        [-2.7064e+04, -9.0644e+04, -6.1724e+03],\n",
      "        [-2.7266e+04, -9.1321e+04, -6.2182e+03],\n",
      "        [-2.9538e+04, -9.8931e+04, -6.7343e+03],\n",
      "        [-2.9749e+04, -9.9638e+04, -6.7822e+03],\n",
      "        [-3.1682e+04, -1.0611e+05, -7.2213e+03],\n",
      "        [-3.2561e+04, -1.0906e+05, -7.4209e+03],\n",
      "        [-3.3452e+04, -1.1204e+05, -7.6232e+03],\n",
      "        [-3.7371e+04, -1.2517e+05, -8.5132e+03],\n",
      "        [-3.8325e+04, -1.2837e+05, -8.7298e+03],\n",
      "        [-3.9048e+04, -1.3079e+05, -8.8940e+03],\n",
      "        [-4.0269e+04, -1.3488e+05, -9.1711e+03],\n",
      "        [-4.1259e+04, -1.3820e+05, -9.3958e+03],\n",
      "        [-4.1758e+04, -1.3987e+05, -9.5092e+03],\n",
      "        [-4.2261e+04, -1.4155e+05, -9.6232e+03],\n",
      "        [-4.3530e+04, -1.4580e+05, -9.9114e+03],\n",
      "        [-4.4300e+04, -1.4839e+05, -1.0086e+04],\n",
      "        [-4.4559e+04, -1.4925e+05, -1.0145e+04],\n",
      "        [-4.7986e+04, -1.6073e+05, -1.0923e+04],\n",
      "        [-4.8795e+04, -1.6344e+05, -1.1106e+04],\n",
      "        [-4.9338e+04, -1.6526e+05, -1.1230e+04],\n",
      "        [-5.0985e+04, -1.7078e+05, -1.1604e+04],\n",
      "        [-5.1540e+04, -1.7264e+05, -1.1729e+04],\n",
      "        [-5.1818e+04, -1.7357e+05, -1.1793e+04],\n",
      "        [-5.2659e+04, -1.7639e+05, -1.1983e+04],\n",
      "        [-5.3790e+04, -1.8018e+05, -1.2240e+04],\n",
      "        [-5.4646e+04, -1.8305e+05, -1.2434e+04],\n",
      "        [-5.5509e+04, -1.8594e+05, -1.2630e+04],\n",
      "        [-5.6088e+04, -1.8788e+05, -1.2762e+04],\n",
      "        [-5.6379e+04, -1.8885e+05, -1.2828e+04],\n",
      "        [-5.6670e+04, -1.8983e+05, -1.2894e+04],\n",
      "        [-5.8731e+04, -1.9673e+05, -1.3361e+04],\n",
      "        [-6.0829e+04, -2.0376e+05, -1.3837e+04],\n",
      "        [-6.2963e+04, -2.1091e+05, -1.4322e+04],\n",
      "        [-6.3580e+04, -2.1298e+05, -1.4462e+04],\n",
      "        [-6.7980e+04, -2.2772e+05, -1.5460e+04],\n",
      "        [-7.0236e+04, -2.3528e+05, -1.5972e+04],\n",
      "        [-7.4522e+04, -2.4964e+05, -1.6944e+04],\n",
      "        [-7.6883e+04, -2.5754e+05, -1.7480e+04],\n",
      "        [-8.4898e+04, -2.8440e+05, -1.9298e+04],\n",
      "        [-8.5614e+04, -2.8680e+05, -1.9460e+04],\n",
      "        [-1.0017e+05, -3.3557e+05, -2.2762e+04],\n",
      "        [-1.0608e+05, -3.5535e+05, -2.4101e+04],\n",
      "        [-1.1215e+05, -3.7570e+05, -2.5478e+04],\n",
      "        [-1.1256e+05, -3.7707e+05, -2.5571e+04],\n",
      "        [-1.1338e+05, -3.7983e+05, -2.5758e+04],\n",
      "        [-1.1504e+05, -3.8538e+05, -2.6134e+04],\n",
      "        [-1.1713e+05, -3.9238e+05, -2.6607e+04],\n",
      "        [-1.2308e+05, -4.1230e+05, -2.7956e+04],\n",
      "        [-1.2917e+05, -4.3272e+05, -2.9337e+04],\n",
      "        [-1.3767e+05, -4.6122e+05, -3.1266e+04],\n",
      "        [-1.4226e+05, -4.7658e+05, -3.2306e+04],\n",
      "        [-1.4551e+05, -4.8748e+05, -3.3043e+04],\n",
      "        [-1.5405e+05, -5.1609e+05, -3.4979e+04],\n",
      "        [-1.6135e+05, -5.4055e+05, -3.6634e+04],\n",
      "        [-1.6185e+05, -5.4220e+05, -3.6746e+04],\n",
      "        [-1.6882e+05, -5.6558e+05, -3.8328e+04],\n",
      "        [-1.8638e+05, -6.2440e+05, -4.2307e+04],\n",
      "        [-1.9820e+05, -6.6401e+05, -4.4987e+04],\n",
      "        [-1.9984e+05, -6.6951e+05, -4.5359e+04],\n",
      "        [-2.0094e+05, -6.7319e+05, -4.5608e+04],\n",
      "        [-2.0149e+05, -6.7503e+05, -4.5733e+04],\n",
      "        [-2.0871e+05, -6.9921e+05, -4.7368e+04],\n",
      "        [-2.1378e+05, -7.1619e+05, -4.8517e+04],\n",
      "        [-2.1891e+05, -7.3338e+05, -4.9680e+04],\n",
      "        [-2.2410e+05, -7.5078e+05, -5.0857e+04],\n",
      "        [-2.2526e+05, -7.5467e+05, -5.1120e+04],\n",
      "        [-2.2701e+05, -7.6053e+05, -5.1517e+04],\n",
      "        [-2.2994e+05, -7.7035e+05, -5.2181e+04],\n",
      "        [-2.3407e+05, -7.8419e+05, -5.3117e+04],\n",
      "        [-2.3586e+05, -7.9016e+05, -5.3521e+04],\n",
      "        [-2.4852e+05, -8.3260e+05, -5.6392e+04],\n",
      "        [-2.5282e+05, -8.4699e+05, -5.7365e+04],\n",
      "        [-2.5902e+05, -8.6777e+05, -5.8771e+04],\n",
      "        [-2.6089e+05, -8.7405e+05, -5.9196e+04],\n",
      "        [-2.7421e+05, -9.1866e+05, -6.2213e+04],\n",
      "        [-2.7549e+05, -9.2296e+05, -6.2504e+04],\n",
      "        [-2.7872e+05, -9.3377e+05, -6.3235e+04],\n",
      "        [-2.7936e+05, -9.3594e+05, -6.3382e+04],\n",
      "        [-2.8131e+05, -9.4246e+05, -6.3823e+04],\n",
      "        [-3.0520e+05, -1.0225e+06, -6.9237e+04],\n",
      "        [-3.1959e+05, -1.0707e+06, -7.2497e+04],\n",
      "        [-3.2028e+05, -1.0730e+06, -7.2654e+04],\n",
      "        [-3.2585e+05, -1.0917e+06, -7.3917e+04],\n",
      "        [-3.3501e+05, -1.1224e+06, -7.5992e+04],\n",
      "        [-3.3643e+05, -1.1272e+06, -7.6314e+04],\n",
      "        [-3.4071e+05, -1.1415e+06, -7.7284e+04],\n",
      "        [-3.4574e+05, -1.1583e+06, -7.8423e+04],\n",
      "        [-3.5517e+05, -1.1899e+06, -8.0560e+04],\n",
      "        [-3.6473e+05, -1.2220e+06, -8.2726e+04],\n",
      "        [-3.6621e+05, -1.2269e+06, -8.3062e+04],\n",
      "        [-3.7217e+05, -1.2469e+06, -8.4412e+04],\n",
      "        [-3.8120e+05, -1.2771e+06, -8.6457e+04],\n",
      "        [-3.9034e+05, -1.3077e+06, -8.8527e+04],\n",
      "        [-4.2077e+05, -1.4097e+06, -9.5423e+04],\n",
      "        [-4.2636e+05, -1.4284e+06, -9.6689e+04],\n",
      "        [-4.3763e+05, -1.4662e+06, -9.9244e+04],\n",
      "        [-4.4333e+05, -1.4853e+06, -1.0053e+05],\n",
      "        [-4.5483e+05, -1.5238e+06, -1.0314e+05],\n",
      "        [-4.7404e+05, -1.5882e+06, -1.0749e+05],\n",
      "        [-4.8678e+05, -1.6309e+06, -1.1038e+05],\n",
      "        [-4.9021e+05, -1.6424e+06, -1.1116e+05],\n",
      "        [-4.9624e+05, -1.6626e+06, -1.1252e+05],\n",
      "        [-4.9970e+05, -1.6742e+06, -1.1330e+05],\n",
      "        [-5.0404e+05, -1.6887e+06, -1.1429e+05],\n",
      "        [-5.0491e+05, -1.6916e+06, -1.1449e+05],\n",
      "        [-5.0752e+05, -1.7004e+06, -1.1508e+05],\n",
      "        [-5.1365e+05, -1.7209e+06, -1.1647e+05],\n",
      "        [-5.3495e+05, -1.7923e+06, -1.2129e+05],\n",
      "        [-5.4849e+05, -1.8376e+06, -1.2436e+05],\n",
      "        [-5.5121e+05, -1.8468e+06, -1.2498e+05],\n",
      "        [-5.5852e+05, -1.8712e+06, -1.2663e+05],\n",
      "        [-6.1675e+05, -2.0664e+06, -1.3982e+05],\n",
      "        [-6.4499e+05, -2.1610e+06, -1.4622e+05],\n",
      "        [-6.7889e+05, -2.2746e+06, -1.5390e+05],\n",
      "        [-7.1159e+05, -2.3841e+06, -1.6131e+05],\n",
      "        [-7.3242e+05, -2.4539e+06, -1.6602e+05],\n",
      "        [-7.4612e+05, -2.4998e+06, -1.6913e+05],\n",
      "        [-7.5995e+05, -2.5462e+06, -1.7226e+05],\n",
      "        [-7.9562e+05, -2.6657e+06, -1.8034e+05],\n",
      "        [-8.1874e+05, -2.7432e+06, -1.8558e+05],\n",
      "        [-8.5802e+05, -2.8748e+06, -1.9448e+05],\n",
      "        [-8.9358e+05, -2.9939e+06, -2.0253e+05],\n",
      "        [-8.9822e+05, -3.0094e+06, -2.0358e+05],\n",
      "        [-1.2189e+06, -4.0838e+06, -2.7621e+05],\n",
      "        [-1.2488e+06, -4.1842e+06, -2.8299e+05],\n",
      "        [-1.3014e+06, -4.3604e+06, -2.9490e+05],\n",
      "        [-1.3608e+06, -4.5594e+06, -3.0835e+05],\n",
      "        [-1.4776e+06, -4.9507e+06, -3.3480e+05],\n",
      "        [-1.5637e+06, -5.2393e+06, -3.5431e+05],\n",
      "        [-1.6476e+06, -5.5203e+06, -3.7330e+05],\n",
      "        [-1.6650e+06, -5.5785e+06, -3.7723e+05],\n",
      "        [-1.8971e+06, -6.3563e+06, -4.2981e+05],\n",
      "        [-1.9090e+06, -6.3960e+06, -4.3249e+05],\n",
      "        [-1.9550e+06, -6.5501e+06, -4.4291e+05],\n",
      "        [-1.9928e+06, -6.6771e+06, -4.5149e+05],\n",
      "        [-2.0189e+06, -6.7643e+06, -4.5738e+05],\n",
      "        [-2.2664e+06, -7.5936e+06, -5.1343e+05],\n",
      "        [-2.2701e+06, -7.6059e+06, -5.1426e+05],\n",
      "        [-2.4259e+06, -8.1282e+06, -5.4956e+05],\n",
      "        [-2.5048e+06, -8.3926e+06, -5.6743e+05],\n",
      "        [-2.5791e+06, -8.6414e+06, -5.8424e+05],\n",
      "        [-2.6704e+06, -8.9474e+06, -6.0493e+05],\n",
      "        [-2.6945e+06, -9.0282e+06, -6.1038e+05],\n",
      "        [-3.3230e+06, -1.1134e+07, -7.5269e+05],\n",
      "        [-3.5989e+06, -1.2058e+07, -8.1516e+05],\n",
      "        [-3.8399e+06, -1.2866e+07, -8.6975e+05],\n",
      "        [-3.9026e+06, -1.3076e+07, -8.8395e+05],\n",
      "        [-4.3456e+06, -1.4560e+07, -9.8423e+05],\n",
      "        [-4.8042e+06, -1.6097e+07, -1.0881e+06],\n",
      "        [-4.8365e+06, -1.6205e+07, -1.0954e+06],\n",
      "        [-5.2409e+06, -1.7560e+07, -1.1870e+06],\n",
      "        [-5.2690e+06, -1.7654e+07, -1.1933e+06],\n",
      "        [-7.0402e+06, -2.3589e+07, -1.5943e+06],\n",
      "        [-7.1119e+06, -2.3829e+07, -1.6106e+06],\n",
      "        [-7.2598e+06, -2.4325e+07, -1.6441e+06],\n",
      "        [-7.6988e+06, -2.5796e+07, -1.7435e+06],\n",
      "        [-7.7773e+06, -2.6059e+07, -1.7612e+06],\n",
      "        [-1.0716e+07, -3.5906e+07, -2.4266e+06],\n",
      "        [-1.1393e+07, -3.8172e+07, -2.5798e+06],\n",
      "        [-1.2654e+07, -4.2400e+07, -2.8654e+06],\n",
      "        [-1.3357e+07, -4.4755e+07, -3.0245e+06],\n",
      "        [-1.3366e+07, -4.4785e+07, -3.0266e+06],\n",
      "        [-1.3442e+07, -4.5041e+07, -3.0438e+06],\n",
      "        [-1.6234e+07, -5.4396e+07, -3.6760e+06],\n",
      "        [-2.3042e+07, -7.7205e+07, -5.2171e+06],\n",
      "        [-2.6929e+07, -9.0231e+07, -6.0972e+06]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "-46:the loss_1 is : tensor([[0.0000e+00, 0.0000e+00, 2.0818e-15],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>)\n",
      "--46: the result of GMM by hand: tensor([1.1021e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00], device='cuda:0',\n",
      "       grad_fn=<SumBackward1>)\n",
      "-46:the loss_2 is : tensor([1.1021e-15, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00], device='cuda:0',\n",
      "       grad_fn=<SumBackward1>)\n",
      "-46:the loss is : tensor([nan], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-47:target_unpadded shape: torch.Size([277, 3])\n",
      "-47:the m[i].log_prob(target_unpadded) is : tensor([[-2.2176e+01, -5.9518e+01, -9.7545e+00],\n",
      "        [-2.8249e+01, -7.6400e+01, -1.1878e+01],\n",
      "        [-3.5088e+01, -9.5404e+01, -1.4248e+01],\n",
      "        [-4.2693e+01, -1.1653e+02, -1.6864e+01],\n",
      "        [-5.1065e+01, -1.3978e+02, -1.9726e+01],\n",
      "        [-6.0203e+01, -1.6515e+02, -2.2834e+01],\n",
      "        [-7.0107e+01, -1.9264e+02, -2.6188e+01],\n",
      "        [-8.0777e+01, -2.2226e+02, -2.9788e+01],\n",
      "        [-9.2214e+01, -2.5399e+02, -3.3634e+01],\n",
      "        [-1.1739e+02, -3.2383e+02, -4.2064e+01],\n",
      "        [-1.3112e+02, -3.6194e+02, -4.6648e+01],\n",
      "        [-1.4562e+02, -4.0216e+02, -5.1478e+01],\n",
      "        [-1.6089e+02, -4.4451e+02, -5.6555e+01],\n",
      "        [-1.7693e+02, -4.8898e+02, -6.1877e+01],\n",
      "        [-1.9373e+02, -5.3557e+02, -6.7445e+01],\n",
      "        [-2.1129e+02, -5.8428e+02, -7.3260e+01],\n",
      "        [-2.2963e+02, -6.3512e+02, -7.9320e+01],\n",
      "        [-2.4873e+02, -6.8808e+02, -8.5627e+01],\n",
      "        [-2.6859e+02, -7.4316e+02, -9.2179e+01],\n",
      "        [-2.8922e+02, -8.0036e+02, -9.8978e+01],\n",
      "        [-3.1062e+02, -8.5969e+02, -1.0602e+02],\n",
      "        [-3.3279e+02, -9.2113e+02, -1.1331e+02],\n",
      "        [-3.7941e+02, -1.0504e+03, -1.2863e+02],\n",
      "        [-4.0388e+02, -1.1182e+03, -1.3666e+02],\n",
      "        [-4.2911e+02, -1.1881e+03, -1.4494e+02],\n",
      "        [-4.5510e+02, -1.2602e+03, -1.5346e+02],\n",
      "        [-4.8186e+02, -1.3344e+03, -1.6222e+02],\n",
      "        [-5.0939e+02, -1.4107e+03, -1.7124e+02],\n",
      "        [-5.3769e+02, -1.4891e+03, -1.8050e+02],\n",
      "        [-5.6675e+02, -1.5696e+03, -1.9000e+02],\n",
      "        [-5.9657e+02, -1.6523e+03, -1.9975e+02],\n",
      "        [-6.2717e+02, -1.7371e+03, -2.0975e+02],\n",
      "        [-6.9065e+02, -1.9130e+03, -2.3048e+02],\n",
      "        [-7.5720e+02, -2.0975e+03, -2.5220e+02],\n",
      "        [-7.9163e+02, -2.1929e+03, -2.6343e+02],\n",
      "        [-8.2682e+02, -2.2904e+03, -2.7490e+02],\n",
      "        [-8.6278e+02, -2.3901e+03, -2.8662e+02],\n",
      "        [-8.9950e+02, -2.4918e+03, -2.9859e+02],\n",
      "        [-9.3699e+02, -2.5957e+03, -3.1080e+02],\n",
      "        [-9.7525e+02, -2.7017e+03, -3.2325e+02],\n",
      "        [-1.0143e+03, -2.8099e+03, -3.3596e+02],\n",
      "        [-1.0541e+03, -2.9201e+03, -3.4891e+02],\n",
      "        [-1.0946e+03, -3.0325e+03, -3.6210e+02],\n",
      "        [-1.1359e+03, -3.1470e+03, -3.7555e+02],\n",
      "        [-1.1780e+03, -3.2636e+03, -3.8923e+02],\n",
      "        [-1.2209e+03, -3.3823e+03, -4.0317e+02],\n",
      "        [-1.2645e+03, -3.5032e+03, -4.1735e+02],\n",
      "        [-1.3089e+03, -3.6262e+03, -4.3177e+02],\n",
      "        [-1.3540e+03, -3.7513e+03, -4.4645e+02],\n",
      "        [-1.4000e+03, -3.8785e+03, -4.6136e+02],\n",
      "        [-1.4466e+03, -4.0079e+03, -4.7653e+02],\n",
      "        [-1.4941e+03, -4.1394e+03, -4.9194e+02],\n",
      "        [-1.5423e+03, -4.2730e+03, -5.0759e+02],\n",
      "        [-1.5913e+03, -4.4087e+03, -5.2350e+02],\n",
      "        [-1.7428e+03, -4.8286e+03, -5.7268e+02],\n",
      "        [-1.7949e+03, -4.9728e+03, -5.8957e+02],\n",
      "        [-1.8477e+03, -5.1191e+03, -6.0670e+02],\n",
      "        [-1.9013e+03, -5.2676e+03, -6.2408e+02],\n",
      "        [-1.9556e+03, -5.4182e+03, -6.4170e+02],\n",
      "        [-2.0107e+03, -5.5709e+03, -6.5957e+02],\n",
      "        [-2.0666e+03, -5.7257e+03, -6.7769e+02],\n",
      "        [-2.1233e+03, -5.8826e+03, -6.9605e+02],\n",
      "        [-2.1807e+03, -6.0417e+03, -7.1466e+02],\n",
      "        [-2.2389e+03, -6.2029e+03, -7.3352e+02],\n",
      "        [-2.2978e+03, -6.3662e+03, -7.5262e+02],\n",
      "        [-2.3575e+03, -6.5316e+03, -7.7196e+02],\n",
      "        [-2.4180e+03, -6.6992e+03, -7.9156e+02],\n",
      "        [-2.5412e+03, -7.0406e+03, -8.3148e+02],\n",
      "        [-2.6040e+03, -7.2145e+03, -8.5181e+02],\n",
      "        [-2.7970e+03, -7.7490e+03, -9.1428e+02],\n",
      "        [-2.8628e+03, -7.9314e+03, -9.3560e+02],\n",
      "        [-2.9294e+03, -8.1160e+03, -9.5716e+02],\n",
      "        [-2.9968e+03, -8.3026e+03, -9.7897e+02],\n",
      "        [-3.0649e+03, -8.4914e+03, -1.0010e+03],\n",
      "        [-3.1338e+03, -8.6823e+03, -1.0233e+03],\n",
      "        [-3.2035e+03, -8.8753e+03, -1.0459e+03],\n",
      "        [-3.2739e+03, -9.0705e+03, -1.0687e+03],\n",
      "        [-3.3451e+03, -9.2677e+03, -1.0917e+03],\n",
      "        [-3.4171e+03, -9.4671e+03, -1.1150e+03],\n",
      "        [-3.4899e+03, -9.6686e+03, -1.1385e+03],\n",
      "        [-3.5634e+03, -9.8722e+03, -1.1623e+03],\n",
      "        [-3.6376e+03, -1.0078e+04, -1.1863e+03],\n",
      "        [-3.7885e+03, -1.0496e+04, -1.2351e+03],\n",
      "        [-3.8650e+03, -1.0708e+04, -1.2598e+03],\n",
      "        [-3.9424e+03, -1.0922e+04, -1.2849e+03],\n",
      "        [-4.0205e+03, -1.1139e+04, -1.3101e+03],\n",
      "        [-4.0993e+03, -1.1357e+04, -1.3356e+03],\n",
      "        [-4.1790e+03, -1.1578e+04, -1.3613e+03],\n",
      "        [-4.2594e+03, -1.1800e+04, -1.3873e+03],\n",
      "        [-4.3405e+03, -1.2025e+04, -1.4136e+03],\n",
      "        [-4.5052e+03, -1.2481e+04, -1.4668e+03],\n",
      "        [-4.5886e+03, -1.2713e+04, -1.4938e+03],\n",
      "        [-4.6729e+03, -1.2946e+04, -1.5210e+03],\n",
      "        [-4.7579e+03, -1.3181e+04, -1.5484e+03],\n",
      "        [-4.8436e+03, -1.3419e+04, -1.5762e+03],\n",
      "        [-4.9302e+03, -1.3659e+04, -1.6041e+03],\n",
      "        [-5.0175e+03, -1.3900e+04, -1.6323e+03],\n",
      "        [-5.1055e+03, -1.4144e+04, -1.6608e+03],\n",
      "        [-5.1944e+03, -1.4390e+04, -1.6895e+03],\n",
      "        [-5.2840e+03, -1.4639e+04, -1.7184e+03],\n",
      "        [-5.3743e+03, -1.4889e+04, -1.7476e+03],\n",
      "        [-5.4654e+03, -1.5141e+04, -1.7770e+03],\n",
      "        [-5.5573e+03, -1.5396e+04, -1.8067e+03],\n",
      "        [-5.6500e+03, -1.5653e+04, -1.8366e+03],\n",
      "        [-5.7434e+03, -1.5911e+04, -1.8668e+03],\n",
      "        [-5.8376e+03, -1.6172e+04, -1.8972e+03],\n",
      "        [-6.0283e+03, -1.6701e+04, -1.9588e+03],\n",
      "        [-6.1248e+03, -1.6968e+04, -1.9900e+03],\n",
      "        [-6.2221e+03, -1.7237e+04, -2.0214e+03],\n",
      "        [-6.3201e+03, -1.7509e+04, -2.0530e+03],\n",
      "        [-6.4189e+03, -1.7782e+04, -2.0849e+03],\n",
      "        [-6.5184e+03, -1.8058e+04, -2.1171e+03],\n",
      "        [-6.6188e+03, -1.8336e+04, -2.1494e+03],\n",
      "        [-6.7198e+03, -1.8616e+04, -2.1821e+03],\n",
      "        [-6.9243e+03, -1.9183e+04, -2.2481e+03],\n",
      "        [-7.0277e+03, -1.9469e+04, -2.2815e+03],\n",
      "        [-7.1319e+03, -1.9758e+04, -2.3151e+03],\n",
      "        [-7.2368e+03, -2.0048e+04, -2.3489e+03],\n",
      "        [-7.3425e+03, -2.0341e+04, -2.3830e+03],\n",
      "        [-7.4489e+03, -2.0636e+04, -2.4174e+03],\n",
      "        [-7.5561e+03, -2.0933e+04, -2.4520e+03],\n",
      "        [-7.6641e+03, -2.1232e+04, -2.4868e+03],\n",
      "        [-7.7729e+03, -2.1533e+04, -2.5219e+03],\n",
      "        [-7.8824e+03, -2.1837e+04, -2.5573e+03],\n",
      "        [-7.9927e+03, -2.2142e+04, -2.5929e+03],\n",
      "        [-8.2156e+03, -2.2759e+04, -2.6648e+03],\n",
      "        [-8.3281e+03, -2.3071e+04, -2.7011e+03],\n",
      "        [-8.4415e+03, -2.3385e+04, -2.7377e+03],\n",
      "        [-8.5556e+03, -2.3701e+04, -2.7745e+03],\n",
      "        [-8.7861e+03, -2.4340e+04, -2.8489e+03],\n",
      "        [-8.9026e+03, -2.4662e+04, -2.8864e+03],\n",
      "        [-9.0197e+03, -2.4987e+04, -2.9242e+03],\n",
      "        [-9.1377e+03, -2.5314e+04, -2.9623e+03],\n",
      "        [-9.2564e+03, -2.5642e+04, -3.0006e+03],\n",
      "        [-9.3759e+03, -2.5973e+04, -3.0391e+03],\n",
      "        [-9.4961e+03, -2.6306e+04, -3.0779e+03],\n",
      "        [-9.6171e+03, -2.6642e+04, -3.1169e+03],\n",
      "        [-9.7389e+03, -2.6979e+04, -3.1562e+03],\n",
      "        [-9.8615e+03, -2.7318e+04, -3.1957e+03],\n",
      "        [-9.9848e+03, -2.7660e+04, -3.2355e+03],\n",
      "        [-1.0109e+04, -2.8004e+04, -3.2755e+03],\n",
      "        [-1.0234e+04, -2.8350e+04, -3.3157e+03],\n",
      "        [-1.0359e+04, -2.8697e+04, -3.3563e+03],\n",
      "        [-1.0486e+04, -2.9048e+04, -3.3970e+03],\n",
      "        [-1.0613e+04, -2.9400e+04, -3.4380e+03],\n",
      "        [-1.0741e+04, -2.9754e+04, -3.4793e+03],\n",
      "        [-1.0869e+04, -3.0110e+04, -3.5207e+03],\n",
      "        [-1.1129e+04, -3.0830e+04, -3.6045e+03],\n",
      "        [-1.1260e+04, -3.1192e+04, -3.6467e+03],\n",
      "        [-1.1392e+04, -3.1557e+04, -3.6892e+03],\n",
      "        [-1.1524e+04, -3.1924e+04, -3.7319e+03],\n",
      "        [-1.1658e+04, -3.2293e+04, -3.7749e+03],\n",
      "        [-1.1792e+04, -3.2665e+04, -3.8181e+03],\n",
      "        [-1.1926e+04, -3.3038e+04, -3.8615e+03],\n",
      "        [-1.2062e+04, -3.3414e+04, -3.9052e+03],\n",
      "        [-1.2198e+04, -3.3791e+04, -3.9492e+03],\n",
      "        [-1.2335e+04, -3.4171e+04, -3.9934e+03],\n",
      "        [-1.2473e+04, -3.4553e+04, -4.0378e+03],\n",
      "        [-1.2612e+04, -3.4937e+04, -4.0825e+03],\n",
      "        [-1.2751e+04, -3.5323e+04, -4.1275e+03],\n",
      "        [-1.2891e+04, -3.5711e+04, -4.1726e+03],\n",
      "        [-1.3032e+04, -3.6102e+04, -4.2181e+03],\n",
      "        [-1.3174e+04, -3.6494e+04, -4.2637e+03],\n",
      "        [-1.3317e+04, -3.6889e+04, -4.3097e+03],\n",
      "        [-1.3604e+04, -3.7684e+04, -4.4022e+03],\n",
      "        [-1.3894e+04, -3.8489e+04, -4.4958e+03],\n",
      "        [-1.4040e+04, -3.8894e+04, -4.5429e+03],\n",
      "        [-1.4335e+04, -3.9711e+04, -4.6380e+03],\n",
      "        [-1.4484e+04, -4.0122e+04, -4.6859e+03],\n",
      "        [-1.4633e+04, -4.0536e+04, -4.7340e+03],\n",
      "        [-1.4934e+04, -4.1370e+04, -4.8310e+03],\n",
      "        [-1.5086e+04, -4.1790e+04, -4.8799e+03],\n",
      "        [-1.5238e+04, -4.2212e+04, -4.9290e+03],\n",
      "        [-1.5392e+04, -4.2636e+04, -4.9784e+03],\n",
      "        [-1.5546e+04, -4.3063e+04, -5.0280e+03],\n",
      "        [-1.5700e+04, -4.3491e+04, -5.0778e+03],\n",
      "        [-1.5856e+04, -4.3922e+04, -5.1279e+03],\n",
      "        [-1.6012e+04, -4.4355e+04, -5.1783e+03],\n",
      "        [-1.6169e+04, -4.4790e+04, -5.2289e+03],\n",
      "        [-1.6327e+04, -4.5227e+04, -5.2797e+03],\n",
      "        [-1.6645e+04, -4.6107e+04, -5.3821e+03],\n",
      "        [-1.6805e+04, -4.6551e+04, -5.4337e+03],\n",
      "        [-1.7290e+04, -4.7894e+04, -5.5899e+03],\n",
      "        [-1.7782e+04, -4.9256e+04, -5.7484e+03],\n",
      "        [-1.8280e+04, -5.0637e+04, -5.9090e+03],\n",
      "        [-1.8448e+04, -5.1102e+04, -5.9630e+03],\n",
      "        [-1.8616e+04, -5.1569e+04, -6.0173e+03],\n",
      "        [-1.8786e+04, -5.2037e+04, -6.0719e+03],\n",
      "        [-1.8956e+04, -5.2508e+04, -6.1266e+03],\n",
      "        [-1.9127e+04, -5.2982e+04, -6.1817e+03],\n",
      "        [-1.9298e+04, -5.3457e+04, -6.2369e+03],\n",
      "        [-1.9471e+04, -5.3934e+04, -6.2924e+03],\n",
      "        [-1.9644e+04, -5.4414e+04, -6.3482e+03],\n",
      "        [-1.9818e+04, -5.4895e+04, -6.4042e+03],\n",
      "        [-1.9992e+04, -5.5379e+04, -6.4605e+03],\n",
      "        [-2.0168e+04, -5.5865e+04, -6.5170e+03],\n",
      "        [-2.0344e+04, -5.6353e+04, -6.5737e+03],\n",
      "        [-2.0521e+04, -5.6843e+04, -6.6307e+03],\n",
      "        [-2.1056e+04, -5.8326e+04, -6.8032e+03],\n",
      "        [-2.1236e+04, -5.8825e+04, -6.8611e+03],\n",
      "        [-2.1417e+04, -5.9326e+04, -6.9194e+03],\n",
      "        [-2.1964e+04, -6.0840e+04, -7.0955e+03],\n",
      "        [-2.2148e+04, -6.1350e+04, -7.1547e+03],\n",
      "        [-2.2518e+04, -6.2374e+04, -7.2739e+03],\n",
      "        [-2.2704e+04, -6.2890e+04, -7.3338e+03],\n",
      "        [-2.2891e+04, -6.3408e+04, -7.3940e+03],\n",
      "        [-2.3079e+04, -6.3928e+04, -7.4544e+03],\n",
      "        [-2.3267e+04, -6.4449e+04, -7.5151e+03],\n",
      "        [-2.3837e+04, -6.6028e+04, -7.6986e+03],\n",
      "        [-2.4221e+04, -6.7091e+04, -7.8222e+03],\n",
      "        [-2.4608e+04, -6.8163e+04, -7.9468e+03],\n",
      "        [-2.5194e+04, -6.9786e+04, -8.1355e+03],\n",
      "        [-2.5390e+04, -7.0331e+04, -8.1989e+03],\n",
      "        [-2.5786e+04, -7.1428e+04, -8.3264e+03],\n",
      "        [-2.5986e+04, -7.1980e+04, -8.3905e+03],\n",
      "        [-2.6186e+04, -7.2533e+04, -8.4549e+03],\n",
      "        [-2.6588e+04, -7.3647e+04, -8.5844e+03],\n",
      "        [-2.6993e+04, -7.4770e+04, -8.7148e+03],\n",
      "        [-2.7197e+04, -7.5334e+04, -8.7804e+03],\n",
      "        [-2.7401e+04, -7.5901e+04, -8.8463e+03],\n",
      "        [-2.7607e+04, -7.6469e+04, -8.9124e+03],\n",
      "        [-2.7813e+04, -7.7040e+04, -8.9787e+03],\n",
      "        [-2.8019e+04, -7.7613e+04, -9.0453e+03],\n",
      "        [-2.8227e+04, -7.8188e+04, -9.1121e+03],\n",
      "        [-2.8435e+04, -7.8765e+04, -9.1792e+03],\n",
      "        [-2.8854e+04, -7.9926e+04, -9.3141e+03],\n",
      "        [-2.9065e+04, -8.0509e+04, -9.3819e+03],\n",
      "        [-2.9489e+04, -8.1682e+04, -9.5183e+03],\n",
      "        [-2.9702e+04, -8.2272e+04, -9.5869e+03],\n",
      "        [-2.9915e+04, -8.2864e+04, -9.6557e+03],\n",
      "        [-3.0130e+04, -8.3458e+04, -9.7247e+03],\n",
      "        [-3.0561e+04, -8.4653e+04, -9.8635e+03],\n",
      "        [-3.0778e+04, -8.5253e+04, -9.9333e+03],\n",
      "        [-3.1653e+04, -8.7676e+04, -1.0215e+04],\n",
      "        [-3.2095e+04, -8.8901e+04, -1.0357e+04],\n",
      "        [-3.2540e+04, -9.0133e+04, -1.0500e+04],\n",
      "        [-3.3439e+04, -9.2624e+04, -1.0790e+04],\n",
      "        [-3.3666e+04, -9.3252e+04, -1.0863e+04],\n",
      "        [-3.4351e+04, -9.5149e+04, -1.1083e+04],\n",
      "        [-3.4581e+04, -9.5786e+04, -1.1157e+04],\n",
      "        [-3.5275e+04, -9.7708e+04, -1.1381e+04],\n",
      "        [-3.5508e+04, -9.8353e+04, -1.1456e+04],\n",
      "        [-3.5976e+04, -9.9650e+04, -1.1606e+04],\n",
      "        [-3.6921e+04, -1.0227e+05, -1.1911e+04],\n",
      "        [-3.7159e+04, -1.0293e+05, -1.1987e+04],\n",
      "        [-3.8120e+04, -1.0559e+05, -1.2296e+04],\n",
      "        [-3.8605e+04, -1.0693e+05, -1.2452e+04],\n",
      "        [-3.9093e+04, -1.0828e+05, -1.2610e+04],\n",
      "        [-3.9584e+04, -1.0964e+05, -1.2768e+04],\n",
      "        [-4.1076e+04, -1.1377e+05, -1.3248e+04],\n",
      "        [-4.1579e+04, -1.1517e+05, -1.3409e+04],\n",
      "        [-4.2851e+04, -1.1869e+05, -1.3819e+04],\n",
      "        [-4.3107e+04, -1.1940e+05, -1.3901e+04],\n",
      "        [-4.3882e+04, -1.2155e+05, -1.4150e+04],\n",
      "        [-4.5981e+04, -1.2736e+05, -1.4826e+04],\n",
      "        [-4.6513e+04, -1.2884e+05, -1.4997e+04],\n",
      "        [-4.6781e+04, -1.2958e+05, -1.5083e+04],\n",
      "        [-4.7049e+04, -1.3032e+05, -1.5170e+04],\n",
      "        [-4.7858e+04, -1.3256e+05, -1.5430e+04],\n",
      "        [-4.9222e+04, -1.3634e+05, -1.5869e+04],\n",
      "        [-4.9497e+04, -1.3710e+05, -1.5957e+04],\n",
      "        [-5.1725e+04, -1.4327e+05, -1.6674e+04],\n",
      "        [-5.3142e+04, -1.4719e+05, -1.7130e+04],\n",
      "        [-5.5449e+04, -1.5358e+05, -1.7872e+04],\n",
      "        [-5.6622e+04, -1.5683e+05, -1.8249e+04],\n",
      "        [-5.7509e+04, -1.5929e+05, -1.8535e+04],\n",
      "        [-5.7806e+04, -1.6011e+05, -1.8630e+04],\n",
      "        [-5.8403e+04, -1.6176e+05, -1.8822e+04],\n",
      "        [-5.9304e+04, -1.6426e+05, -1.9112e+04],\n",
      "        [-6.1433e+04, -1.7016e+05, -1.9797e+04],\n",
      "        [-6.1740e+04, -1.7101e+05, -1.9896e+04],\n",
      "        [-6.2976e+04, -1.7443e+05, -2.0293e+04],\n",
      "        [-7.2641e+04, -2.0120e+05, -2.3402e+04],\n",
      "        [-7.6358e+04, -2.1149e+05, -2.4597e+04],\n",
      "        [-7.7732e+04, -2.1530e+05, -2.5039e+04],\n",
      "        [-8.5511e+04, -2.3684e+05, -2.7541e+04],\n",
      "        [-9.6331e+04, -2.6681e+05, -3.1020e+04]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "-47:the loss_1 is : tensor([[2.3400e-10, 1.4182e-26, 5.8033e-05],\n",
      "        [5.3928e-13, 6.6064e-34, 6.9397e-06],\n",
      "        [5.7761e-16, 3.6854e-42, 6.4887e-07],\n",
      "        [2.8752e-19, 0.0000e+00, 4.7437e-08],\n",
      "        [6.6514e-23, 0.0000e+00, 2.7115e-09],\n",
      "        [7.1511e-27, 0.0000e+00, 1.2119e-10],\n",
      "        [3.5732e-31, 0.0000e+00, 4.2349e-12],\n",
      "        [8.2975e-36, 0.0000e+00, 1.1571e-13],\n",
      "        [8.9547e-41, 0.0000e+00, 2.4721e-15],\n",
      "        [0.0000e+00, 0.0000e+00, 5.3931e-19],\n",
      "        [0.0000e+00, 0.0000e+00, 5.5074e-21],\n",
      "        [0.0000e+00, 0.0000e+00, 4.3974e-23],\n",
      "        [0.0000e+00, 0.0000e+00, 2.7453e-25],\n",
      "        [0.0000e+00, 0.0000e+00, 1.3401e-27],\n",
      "        [0.0000e+00, 0.0000e+00, 5.1147e-30],\n",
      "        [0.0000e+00, 0.0000e+00, 1.5263e-32],\n",
      "        [0.0000e+00, 0.0000e+00, 3.5614e-35],\n",
      "        [0.0000e+00, 0.0000e+00, 6.4973e-38],\n",
      "        [0.0000e+00, 0.0000e+00, 9.2680e-41],\n",
      "        [0.0000e+00, 0.0000e+00, 1.0370e-43],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>)\n",
      "--47: the result of GMM by hand: tensor([2.9451e-05, 3.5218e-06, 3.2929e-07, 2.4073e-08, 1.3760e-09, 6.1501e-11,\n",
      "        2.1492e-12, 5.8722e-14, 1.2545e-15, 2.7369e-19, 2.7949e-21, 2.2316e-23,\n",
      "        1.3932e-25, 6.8007e-28, 2.5956e-30, 7.7458e-33, 1.8073e-35, 3.2972e-38,\n",
      "        4.7033e-41, 5.3249e-44, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-47:the loss_2 is : tensor([2.9451e-05, 3.5218e-06, 3.2929e-07, 2.4073e-08, 1.3761e-09, 6.1501e-11,\n",
      "        2.1492e-12, 5.8722e-14, 1.2545e-15, 2.7369e-19, 2.7949e-21, 2.2316e-23,\n",
      "        1.3932e-25, 6.8007e-28, 2.5956e-30, 7.7458e-33, 1.8073e-35, 3.2972e-38,\n",
      "        4.7033e-41, 5.3249e-44, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-47:the loss is : tensor([nan], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-48:target_unpadded shape: torch.Size([278, 3])\n",
      "-48:the m[i].log_prob(target_unpadded) is : tensor([[-1.1965e+00, -7.4491e-01, -1.9275e+00],\n",
      "        [-2.0648e+02, -7.4484e+02, -7.0452e+01],\n",
      "        [-2.4008e+02, -8.6638e+02, -8.1254e+01],\n",
      "        [-7.1614e+02, -2.5871e+03, -2.3262e+02],\n",
      "        [-8.0950e+02, -2.9244e+03, -2.6212e+02],\n",
      "        [-1.0134e+03, -3.6611e+03, -3.2644e+02],\n",
      "        [-1.2008e+03, -4.3382e+03, -3.8546e+02],\n",
      "        [-1.2803e+03, -4.6251e+03, -4.1045e+02],\n",
      "        [-1.5338e+03, -5.5410e+03, -4.9014e+02],\n",
      "        [-1.6692e+03, -6.0299e+03, -5.3265e+02],\n",
      "        [-1.8103e+03, -6.5395e+03, -5.7692e+02],\n",
      "        [-1.9571e+03, -7.0698e+03, -6.2298e+02],\n",
      "        [-2.1618e+03, -7.8090e+03, -6.8714e+02],\n",
      "        [-2.2145e+03, -7.9996e+03, -7.0367e+02],\n",
      "        [-2.3766e+03, -8.5850e+03, -7.5445e+02],\n",
      "        [-2.7180e+03, -9.8178e+03, -8.6133e+02],\n",
      "        [-2.7771e+03, -1.0031e+04, -8.7983e+02],\n",
      "        [-2.8369e+03, -1.0247e+04, -8.9853e+02],\n",
      "        [-3.0200e+03, -1.0908e+04, -9.5582e+02],\n",
      "        [-3.6036e+03, -1.3016e+04, -1.1383e+03],\n",
      "        [-3.6717e+03, -1.3262e+04, -1.1596e+03],\n",
      "        [-4.4620e+03, -1.6115e+04, -1.4064e+03],\n",
      "        [-4.5377e+03, -1.6389e+04, -1.4301e+03],\n",
      "        [-4.6140e+03, -1.6664e+04, -1.4539e+03],\n",
      "        [-4.6909e+03, -1.6942e+04, -1.4779e+03],\n",
      "        [-5.0852e+03, -1.8366e+04, -1.6010e+03],\n",
      "        [-5.1659e+03, -1.8657e+04, -1.6262e+03],\n",
      "        [-6.5446e+03, -2.3635e+04, -2.0562e+03],\n",
      "        [-6.6362e+03, -2.3966e+04, -2.0847e+03],\n",
      "        [-6.9148e+03, -2.4972e+04, -2.1716e+03],\n",
      "        [-7.6856e+03, -2.7754e+04, -2.4118e+03],\n",
      "        [-7.8847e+03, -2.8473e+04, -2.4738e+03],\n",
      "        [-8.3935e+03, -3.0310e+04, -2.6324e+03],\n",
      "        [-8.4971e+03, -3.0684e+04, -2.6647e+03],\n",
      "        [-8.8120e+03, -3.1821e+04, -2.7627e+03],\n",
      "        [-9.4588e+03, -3.4156e+04, -2.9642e+03],\n",
      "        [-9.7908e+03, -3.5355e+04, -3.0676e+03],\n",
      "        [-1.0015e+04, -3.6166e+04, -3.1375e+03],\n",
      "        [-1.0821e+04, -3.9075e+04, -3.3884e+03],\n",
      "        [-1.2780e+04, -4.6148e+04, -3.9981e+03],\n",
      "        [-1.2908e+04, -4.6609e+04, -4.0378e+03],\n",
      "        [-1.3557e+04, -4.8951e+04, -4.2397e+03],\n",
      "        [-1.4222e+04, -5.1351e+04, -4.4465e+03],\n",
      "        [-1.5040e+04, -5.4307e+04, -4.7011e+03],\n",
      "        [-1.5318e+04, -5.5310e+04, -4.7876e+03],\n",
      "        [-1.6456e+04, -5.9416e+04, -5.1413e+03],\n",
      "        [-1.7040e+04, -6.1524e+04, -5.3229e+03],\n",
      "        [-1.8086e+04, -6.5302e+04, -5.6483e+03],\n",
      "        [-1.8391e+04, -6.6402e+04, -5.7430e+03],\n",
      "        [-1.8698e+04, -6.7511e+04, -5.8385e+03],\n",
      "        [-1.9320e+04, -6.9757e+04, -6.0319e+03],\n",
      "        [-1.9794e+04, -7.1465e+04, -6.1791e+03],\n",
      "        [-2.0757e+04, -7.4944e+04, -6.4786e+03],\n",
      "        [-2.2246e+04, -8.0318e+04, -6.9413e+03],\n",
      "        [-2.2584e+04, -8.1538e+04, -7.0463e+03],\n",
      "        [-2.3267e+04, -8.4004e+04, -7.2586e+03],\n",
      "        [-2.3786e+04, -8.5878e+04, -7.4199e+03],\n",
      "        [-2.4487e+04, -8.8409e+04, -7.6378e+03],\n",
      "        [-2.4664e+04, -8.9047e+04, -7.6927e+03],\n",
      "        [-2.4841e+04, -8.9688e+04, -7.7479e+03],\n",
      "        [-2.5378e+04, -9.1624e+04, -7.9145e+03],\n",
      "        [-2.5738e+04, -9.2926e+04, -8.0266e+03],\n",
      "        [-2.6284e+04, -9.4896e+04, -8.1961e+03],\n",
      "        [-2.7021e+04, -9.7555e+04, -8.4250e+03],\n",
      "        [-2.7580e+04, -9.9574e+04, -8.5987e+03],\n",
      "        [-2.7768e+04, -1.0025e+05, -8.6570e+03],\n",
      "        [-2.7956e+04, -1.0093e+05, -8.7155e+03],\n",
      "        [-2.8525e+04, -1.0298e+05, -8.8922e+03],\n",
      "        [-2.9486e+04, -1.0645e+05, -9.1906e+03],\n",
      "        [-3.0070e+04, -1.0856e+05, -9.3720e+03],\n",
      "        [-3.1455e+04, -1.1356e+05, -9.8022e+03],\n",
      "        [-3.1856e+04, -1.1501e+05, -9.9269e+03],\n",
      "        [-3.2871e+04, -1.1867e+05, -1.0242e+04],\n",
      "        [-3.3076e+04, -1.1941e+05, -1.0306e+04],\n",
      "        [-3.4109e+04, -1.2314e+05, -1.0627e+04],\n",
      "        [-3.4318e+04, -1.2390e+05, -1.0692e+04],\n",
      "        [-3.8404e+04, -1.3864e+05, -1.1960e+04],\n",
      "        [-4.0874e+04, -1.4756e+05, -1.2727e+04],\n",
      "        [-4.3187e+04, -1.5591e+05, -1.3445e+04],\n",
      "        [-4.3657e+04, -1.5761e+05, -1.3591e+04],\n",
      "        [-4.4844e+04, -1.6189e+05, -1.3960e+04],\n",
      "        [-4.5563e+04, -1.6449e+05, -1.4183e+04],\n",
      "        [-4.7510e+04, -1.7152e+05, -1.4787e+04],\n",
      "        [-4.8499e+04, -1.7508e+05, -1.5094e+04],\n",
      "        [-4.8997e+04, -1.7688e+05, -1.5249e+04],\n",
      "        [-4.9498e+04, -1.7869e+05, -1.5404e+04],\n",
      "        [-4.9749e+04, -1.7960e+05, -1.5482e+04],\n",
      "        [-5.1270e+04, -1.8509e+05, -1.5954e+04],\n",
      "        [-5.3074e+04, -1.9160e+05, -1.6514e+04],\n",
      "        [-5.5705e+04, -2.0109e+05, -1.7331e+04],\n",
      "        [-5.6775e+04, -2.0496e+05, -1.7663e+04],\n",
      "        [-5.8127e+04, -2.0984e+05, -1.8082e+04],\n",
      "        [-5.9495e+04, -2.1478e+05, -1.8507e+04],\n",
      "        [-6.0047e+04, -2.1677e+05, -1.8678e+04],\n",
      "        [-6.0323e+04, -2.1777e+05, -1.8764e+04],\n",
      "        [-6.1997e+04, -2.2381e+05, -1.9283e+04],\n",
      "        [-6.2279e+04, -2.2482e+05, -1.9371e+04],\n",
      "        [-6.6573e+04, -2.4033e+05, -2.0703e+04],\n",
      "        [-6.8627e+04, -2.4774e+05, -2.1340e+04],\n",
      "        [-6.8922e+04, -2.4880e+05, -2.1432e+04],\n",
      "        [-7.0411e+04, -2.5418e+05, -2.1894e+04],\n",
      "        [-7.3437e+04, -2.6510e+05, -2.2833e+04],\n",
      "        [-7.6214e+04, -2.7512e+05, -2.3694e+04],\n",
      "        [-7.6838e+04, -2.7738e+05, -2.3888e+04],\n",
      "        [-7.7465e+04, -2.7964e+05, -2.4082e+04],\n",
      "        [-7.8094e+04, -2.8191e+05, -2.4278e+04],\n",
      "        [-7.8726e+04, -2.8419e+05, -2.4474e+04],\n",
      "        [-8.3546e+04, -3.0159e+05, -2.5969e+04],\n",
      "        [-8.7505e+04, -3.1588e+05, -2.7197e+04],\n",
      "        [-8.9856e+04, -3.2437e+05, -2.7926e+04],\n",
      "        [-9.0534e+04, -3.2681e+05, -2.8137e+04],\n",
      "        [-9.3615e+04, -3.3793e+05, -2.9092e+04],\n",
      "        [-9.3960e+04, -3.3918e+05, -2.9199e+04],\n",
      "        [-9.4306e+04, -3.4043e+05, -2.9307e+04],\n",
      "        [-9.5001e+04, -3.4293e+05, -2.9522e+04],\n",
      "        [-9.6047e+04, -3.4671e+05, -2.9846e+04],\n",
      "        [-9.6397e+04, -3.4797e+05, -2.9955e+04],\n",
      "        [-9.6747e+04, -3.4924e+05, -3.0064e+04],\n",
      "        [-9.7803e+04, -3.5305e+05, -3.0391e+04],\n",
      "        [-1.0389e+05, -3.7503e+05, -3.2280e+04],\n",
      "        [-1.0719e+05, -3.8693e+05, -3.3303e+04],\n",
      "        [-1.0793e+05, -3.8961e+05, -3.3532e+04],\n",
      "        [-1.0905e+05, -3.9363e+05, -3.3878e+04],\n",
      "        [-1.1017e+05, -3.9767e+05, -3.4226e+04],\n",
      "        [-1.1242e+05, -4.0582e+05, -3.4926e+04],\n",
      "        [-1.1471e+05, -4.1406e+05, -3.5633e+04],\n",
      "        [-1.1547e+05, -4.1682e+05, -3.5871e+04],\n",
      "        [-1.1895e+05, -4.2937e+05, -3.6949e+04],\n",
      "        [-1.2090e+05, -4.3642e+05, -3.7554e+04],\n",
      "        [-1.2129e+05, -4.3784e+05, -3.7676e+04],\n",
      "        [-1.2806e+05, -4.6228e+05, -3.9776e+04],\n",
      "        [-1.3091e+05, -4.7253e+05, -4.0657e+04],\n",
      "        [-1.3296e+05, -4.7993e+05, -4.1292e+04],\n",
      "        [-1.3502e+05, -4.8738e+05, -4.1933e+04],\n",
      "        [-1.3543e+05, -4.8888e+05, -4.2061e+04],\n",
      "        [-1.3627e+05, -4.9188e+05, -4.2319e+04],\n",
      "        [-1.4046e+05, -5.0703e+05, -4.3620e+04],\n",
      "        [-1.4173e+05, -5.1162e+05, -4.4015e+04],\n",
      "        [-1.4216e+05, -5.1315e+05, -4.4146e+04],\n",
      "        [-1.4472e+05, -5.2240e+05, -4.4941e+04],\n",
      "        [-1.4644e+05, -5.2862e+05, -4.5475e+04],\n",
      "        [-1.4731e+05, -5.3174e+05, -4.5743e+04],\n",
      "        [-1.4861e+05, -5.3644e+05, -4.6147e+04],\n",
      "        [-1.5167e+05, -5.4748e+05, -4.7096e+04],\n",
      "        [-1.5255e+05, -5.5066e+05, -4.7369e+04],\n",
      "        [-1.5299e+05, -5.5225e+05, -4.7505e+04],\n",
      "        [-1.5476e+05, -5.5864e+05, -4.8054e+04],\n",
      "        [-1.5521e+05, -5.6024e+05, -4.8192e+04],\n",
      "        [-1.5610e+05, -5.6346e+05, -4.8468e+04],\n",
      "        [-1.6059e+05, -5.7966e+05, -4.9860e+04],\n",
      "        [-1.6149e+05, -5.8293e+05, -5.0140e+04],\n",
      "        [-1.6422e+05, -5.9279e+05, -5.0987e+04],\n",
      "        [-1.6468e+05, -5.9444e+05, -5.1129e+04],\n",
      "        [-1.6698e+05, -6.0273e+05, -5.1841e+04],\n",
      "        [-1.7444e+05, -6.2965e+05, -5.4153e+04],\n",
      "        [-1.7491e+05, -6.3135e+05, -5.4299e+04],\n",
      "        [-1.7633e+05, -6.3647e+05, -5.4739e+04],\n",
      "        [-1.7823e+05, -6.4333e+05, -5.5328e+04],\n",
      "        [-1.8254e+05, -6.5889e+05, -5.6665e+04],\n",
      "        [-1.8593e+05, -6.7112e+05, -5.7716e+04],\n",
      "        [-1.8739e+05, -6.7640e+05, -5.8169e+04],\n",
      "        [-1.8837e+05, -6.7993e+05, -5.8472e+04],\n",
      "        [-1.8935e+05, -6.8347e+05, -5.8776e+04],\n",
      "        [-1.9181e+05, -6.9236e+05, -5.9540e+04],\n",
      "        [-1.9379e+05, -6.9951e+05, -6.0154e+04],\n",
      "        [-1.9528e+05, -7.0490e+05, -6.0617e+04],\n",
      "        [-1.9578e+05, -7.0670e+05, -6.0771e+04],\n",
      "        [-1.9678e+05, -7.1031e+05, -6.1081e+04],\n",
      "        [-1.9980e+05, -7.2119e+05, -6.2016e+04],\n",
      "        [-2.0283e+05, -7.3215e+05, -6.2957e+04],\n",
      "        [-2.0334e+05, -7.3398e+05, -6.3115e+04],\n",
      "        [-2.0898e+05, -7.5432e+05, -6.4861e+04],\n",
      "        [-2.1053e+05, -7.5992e+05, -6.5342e+04],\n",
      "        [-2.1105e+05, -7.6179e+05, -6.5502e+04],\n",
      "        [-2.1156e+05, -7.6366e+05, -6.5663e+04],\n",
      "        [-2.1208e+05, -7.6553e+05, -6.5824e+04],\n",
      "        [-2.1312e+05, -7.6929e+05, -6.6147e+04],\n",
      "        [-2.1417e+05, -7.7305e+05, -6.6470e+04],\n",
      "        [-2.1469e+05, -7.7494e+05, -6.6632e+04],\n",
      "        [-2.1679e+05, -7.8250e+05, -6.7282e+04],\n",
      "        [-2.2101e+05, -7.9774e+05, -6.8590e+04],\n",
      "        [-2.2154e+05, -7.9966e+05, -6.8755e+04],\n",
      "        [-2.2474e+05, -8.1120e+05, -6.9746e+04],\n",
      "        [-2.2581e+05, -8.1506e+05, -7.0078e+04],\n",
      "        [-2.3283e+05, -8.4041e+05, -7.2255e+04],\n",
      "        [-2.3447e+05, -8.4632e+05, -7.2762e+04],\n",
      "        [-2.3611e+05, -8.5224e+05, -7.3271e+04],\n",
      "        [-2.3886e+05, -8.6217e+05, -7.4123e+04],\n",
      "        [-2.4329e+05, -8.7816e+05, -7.5496e+04],\n",
      "        [-2.4384e+05, -8.8017e+05, -7.5669e+04],\n",
      "        [-2.4440e+05, -8.8218e+05, -7.5842e+04],\n",
      "        [-2.4552e+05, -8.8621e+05, -7.6188e+04],\n",
      "        [-2.4776e+05, -8.9430e+05, -7.6883e+04],\n",
      "        [-2.5398e+05, -9.1674e+05, -7.8809e+04],\n",
      "        [-2.5626e+05, -9.2496e+05, -7.9516e+04],\n",
      "        [-2.5797e+05, -9.3116e+05, -8.0047e+04],\n",
      "        [-2.5854e+05, -9.3323e+05, -8.0225e+04],\n",
      "        [-2.6084e+05, -9.4153e+05, -8.0938e+04],\n",
      "        [-2.6258e+05, -9.4778e+05, -8.1475e+04],\n",
      "        [-2.6373e+05, -9.5195e+05, -8.1833e+04],\n",
      "        [-2.6664e+05, -9.6244e+05, -8.2734e+04],\n",
      "        [-2.6956e+05, -9.7298e+05, -8.3639e+04],\n",
      "        [-2.7014e+05, -9.7509e+05, -8.3820e+04],\n",
      "        [-2.7250e+05, -9.8358e+05, -8.4549e+04],\n",
      "        [-2.7545e+05, -9.9424e+05, -8.5464e+04],\n",
      "        [-2.8020e+05, -1.0114e+06, -8.6939e+04],\n",
      "        [-2.8500e+05, -1.0287e+06, -8.8426e+04],\n",
      "        [-2.8561e+05, -1.0309e+06, -8.8612e+04],\n",
      "        [-2.8621e+05, -1.0331e+06, -8.8799e+04],\n",
      "        [-2.9045e+05, -1.0484e+06, -9.0113e+04],\n",
      "        [-2.9411e+05, -1.0616e+06, -9.1248e+04],\n",
      "        [-3.0088e+05, -1.0860e+06, -9.3345e+04],\n",
      "        [-3.0212e+05, -1.0905e+06, -9.3729e+04],\n",
      "        [-3.0274e+05, -1.0927e+06, -9.3922e+04],\n",
      "        [-3.0336e+05, -1.0950e+06, -9.4114e+04],\n",
      "        [-3.0460e+05, -1.0995e+06, -9.4500e+04],\n",
      "        [-3.0960e+05, -1.1175e+06, -9.6050e+04],\n",
      "        [-3.1212e+05, -1.1266e+06, -9.6829e+04],\n",
      "        [-3.1655e+05, -1.1426e+06, -9.8202e+04],\n",
      "        [-3.2037e+05, -1.1564e+06, -9.9385e+04],\n",
      "        [-3.2357e+05, -1.1679e+06, -1.0038e+05],\n",
      "        [-3.2678e+05, -1.1795e+06, -1.0137e+05],\n",
      "        [-3.3457e+05, -1.2076e+06, -1.0379e+05],\n",
      "        [-3.3915e+05, -1.2242e+06, -1.0521e+05],\n",
      "        [-3.4775e+05, -1.2552e+06, -1.0787e+05],\n",
      "        [-3.4908e+05, -1.2600e+06, -1.0828e+05],\n",
      "        [-3.5309e+05, -1.2745e+06, -1.0953e+05],\n",
      "        [-3.5780e+05, -1.2915e+06, -1.1099e+05],\n",
      "        [-3.6868e+05, -1.3307e+06, -1.1436e+05],\n",
      "        [-3.7005e+05, -1.3357e+06, -1.1478e+05],\n",
      "        [-3.7625e+05, -1.3581e+06, -1.1670e+05],\n",
      "        [-3.7764e+05, -1.3631e+06, -1.1713e+05],\n",
      "        [-3.7833e+05, -1.3656e+06, -1.1735e+05],\n",
      "        [-3.8111e+05, -1.3756e+06, -1.1821e+05],\n",
      "        [-3.8670e+05, -1.3958e+06, -1.1994e+05],\n",
      "        [-3.8811e+05, -1.4009e+06, -1.2038e+05],\n",
      "        [-3.8881e+05, -1.4034e+06, -1.2060e+05],\n",
      "        [-3.9234e+05, -1.4161e+06, -1.2169e+05],\n",
      "        [-3.9517e+05, -1.4263e+06, -1.2257e+05],\n",
      "        [-3.9659e+05, -1.4315e+06, -1.2301e+05],\n",
      "        [-4.0372e+05, -1.4572e+06, -1.2522e+05],\n",
      "        [-4.0516e+05, -1.4624e+06, -1.2566e+05],\n",
      "        [-4.0948e+05, -1.4780e+06, -1.2700e+05],\n",
      "        [-4.1165e+05, -1.4858e+06, -1.2767e+05],\n",
      "        [-4.1965e+05, -1.5147e+06, -1.3015e+05],\n",
      "        [-4.2258e+05, -1.5253e+06, -1.3106e+05],\n",
      "        [-4.2331e+05, -1.5279e+06, -1.3129e+05],\n",
      "        [-4.2625e+05, -1.5385e+06, -1.3220e+05],\n",
      "        [-4.2920e+05, -1.5492e+06, -1.3311e+05],\n",
      "        [-4.4712e+05, -1.6139e+06, -1.3867e+05],\n",
      "        [-4.5090e+05, -1.6275e+06, -1.3984e+05],\n",
      "        [-4.5851e+05, -1.6550e+06, -1.4219e+05],\n",
      "        [-4.6004e+05, -1.6605e+06, -1.4267e+05],\n",
      "        [-4.6388e+05, -1.6743e+06, -1.4386e+05],\n",
      "        [-4.6464e+05, -1.6771e+06, -1.4409e+05],\n",
      "        [-4.6541e+05, -1.6799e+06, -1.4433e+05],\n",
      "        [-4.7237e+05, -1.7050e+06, -1.4649e+05],\n",
      "        [-4.7314e+05, -1.7078e+06, -1.4673e+05],\n",
      "        [-4.7781e+05, -1.7246e+06, -1.4817e+05],\n",
      "        [-4.9591e+05, -1.7900e+06, -1.5378e+05],\n",
      "        [-5.0710e+05, -1.8303e+06, -1.5725e+05],\n",
      "        [-5.1032e+05, -1.8419e+06, -1.5825e+05],\n",
      "        [-5.1274e+05, -1.8507e+06, -1.5900e+05],\n",
      "        [-5.1679e+05, -1.8653e+06, -1.6025e+05],\n",
      "        [-5.1760e+05, -1.8682e+06, -1.6050e+05],\n",
      "        [-5.3891e+05, -1.9452e+06, -1.6711e+05],\n",
      "        [-5.4974e+05, -1.9842e+06, -1.7046e+05],\n",
      "        [-5.5141e+05, -1.9903e+06, -1.7098e+05],\n",
      "        [-5.6066e+05, -2.0237e+06, -1.7384e+05],\n",
      "        [-5.6489e+05, -2.0389e+06, -1.7516e+05],\n",
      "        [-5.9062e+05, -2.1318e+06, -1.8313e+05],\n",
      "        [-5.9583e+05, -2.1506e+06, -1.8474e+05],\n",
      "        [-5.9758e+05, -2.1569e+06, -1.8528e+05],\n",
      "        [-6.0107e+05, -2.1695e+06, -1.8636e+05],\n",
      "        [-6.2849e+05, -2.2685e+06, -1.9486e+05],\n",
      "        [-7.0586e+05, -2.5477e+06, -2.1883e+05],\n",
      "        [-7.2495e+05, -2.6166e+06, -2.2474e+05],\n",
      "        [-7.6487e+05, -2.7607e+06, -2.3711e+05]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "-48:the loss_1 is : tensor([[3.0225e-01, 4.7478e-01, 1.4551e-01],\n",
      "        [0.0000e+00, 0.0000e+00, 2.5290e-31],\n",
      "        [0.0000e+00, 0.0000e+00, 5.1504e-36],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>)\n",
      "--48: the result of GMM by hand: tensor([2.5671e-01, 1.2759e-31, 2.5984e-36, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-48:the loss_2 is : tensor([2.5671e-01, 1.2759e-31, 2.5984e-36, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-48:the loss is : tensor([nan], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "-49:target_unpadded shape: torch.Size([624, 3])\n",
      "-49:the m[i].log_prob(target_unpadded) is : tensor([[-1.7796e+00, -2.1796e+00, -2.1794e+00],\n",
      "        [-8.1675e+00, -1.8094e+01, -4.5303e+00],\n",
      "        [-1.1772e+01, -2.7201e+01, -5.7446e+00],\n",
      "        ...,\n",
      "        [-3.7437e+05, -9.6460e+05, -1.0943e+05],\n",
      "        [-3.7735e+05, -9.7227e+05, -1.1030e+05],\n",
      "        [-4.2662e+05, -1.0992e+06, -1.2468e+05]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "-49:the loss_1 is : tensor([[1.6870e-01, 1.1309e-01, 1.1311e-01],\n",
      "        [2.8373e-04, 1.3865e-08, 1.0778e-02],\n",
      "        [7.7145e-06, 1.5367e-12, 3.2001e-03],\n",
      "        ...,\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>)\n",
      "--49: the result of GMM by hand: tensor([1.2762e-01, 5.8086e-03, 1.7047e-03, 1.2246e-05, 1.8913e-12, 1.8124e-15,\n",
      "        4.0617e-17, 7.3393e-19, 1.0693e-20, 1.2560e-22, 9.0841e-27, 5.5931e-29,\n",
      "        2.7765e-31, 1.1113e-33, 3.5865e-36, 9.3319e-39, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "       device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-49:the loss_2 is : tensor([1.2762e-01, 5.8086e-03, 1.7047e-03, 1.2246e-05, 1.8913e-12, 1.8123e-15,\n",
      "        4.0617e-17, 7.3392e-19, 1.0693e-20, 1.2560e-22, 9.0841e-27, 5.5930e-29,\n",
      "        2.7766e-31, 1.1113e-33, 3.5865e-36, 9.3319e-39, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "       device='cuda:0', grad_fn=<SumBackward1>)\n",
      "-49:the loss is : tensor([nan], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "训练次数：0，Loss：nan\n",
      "[PADDING]：一共padding的0个个数： 5000\n",
      "---- 1 batch----\n",
      "pi's shape:  torch.Size([50, 3])\n",
      "mu's shape:  torch.Size([50, 3])\n",
      "sigma's shape:  torch.Size([50, 3])\n",
      "The [pi,mu,sigma] is : \n",
      "\n",
      "tensor([[nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan]], device='cuda:0', grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan]], device='cuda:0', grad_fn=<AddmmBackward0>) \n",
      " tensor([[nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan]], device='cuda:0', grad_fn=<ExpBackward0>)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected parameter loc (Tensor of shape (3,)) of distribution Normal(loc: torch.Size([3]), scale: torch.Size([3])) to satisfy the constraint Real(), but found invalid values:\ntensor([nan, nan, nan], device='cuda:0', grad_fn=<PermuteBackward0>)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [314], line 40\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28mprint\u001B[39m(pi,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,mu,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,sigma)\n\u001B[0;32m     17\u001B[0m \u001B[38;5;66;03m# save the params\u001B[39;00m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;66;03m# params = list(mlp.named_parameters())\u001B[39;00m\n\u001B[0;32m     19\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     38\u001B[0m \n\u001B[0;32m     39\u001B[0m \u001B[38;5;66;03m# cal the loss and draw the MDN\u001B[39;00m\n\u001B[1;32m---> 40\u001B[0m duration,m  \u001B[38;5;241m=\u001B[39m \u001B[43mloss_preparation\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmu\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msigma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     41\u001B[0m \u001B[38;5;66;03m# draw_mdn(pi,duration,m,total_train_step)\u001B[39;00m\n\u001B[0;32m     42\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss_fn(pi,duration,m,mu,sigma)\n",
      "Cell \u001B[1;32mIn [228], line 6\u001B[0m, in \u001B[0;36mloss_preparation\u001B[1;34m(pi, mu, sigma, target)\u001B[0m\n\u001B[0;32m      4\u001B[0m m\u001B[38;5;241m=\u001B[39m[]\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(pi\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]):\n\u001B[1;32m----> 6\u001B[0m     m\u001B[38;5;241m.\u001B[39mappend(\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdistributions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mNormal\u001B[49m\u001B[43m(\u001B[49m\u001B[43mloc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmu\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mT\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msigma\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mT\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m      8\u001B[0m duration \u001B[38;5;241m=\u001B[39m target[:,:,\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39msqueeze_()\n\u001B[0;32m      9\u001B[0m \u001B[38;5;66;03m# # target_drop_padding.cpu().data.numpy()\u001B[39;00m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;66;03m# # target_drop_padding.to_csv()\u001B[39;00m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;66;03m# print(\"target_drop_padding shape:\",target_drop_padding.shape)\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;66;03m# len_0 = len(loss_2)\u001B[39;00m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;66;03m# print(\"non zero 占比：\",len(loss_2[torch.nonzero(loss_2)])/len_0)\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\py39\\lib\\site-packages\\torch\\distributions\\normal.py:56\u001B[0m, in \u001B[0;36mNormal.__init__\u001B[1;34m(self, loc, scale, validate_args)\u001B[0m\n\u001B[0;32m     54\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     55\u001B[0m     batch_shape \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloc\u001B[38;5;241m.\u001B[39msize()\n\u001B[1;32m---> 56\u001B[0m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mNormal\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mbatch_shape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidate_args\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidate_args\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\py39\\lib\\site-packages\\torch\\distributions\\distribution.py:56\u001B[0m, in \u001B[0;36mDistribution.__init__\u001B[1;34m(self, batch_shape, event_shape, validate_args)\u001B[0m\n\u001B[0;32m     54\u001B[0m         valid \u001B[38;5;241m=\u001B[39m constraint\u001B[38;5;241m.\u001B[39mcheck(value)\n\u001B[0;32m     55\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m valid\u001B[38;5;241m.\u001B[39mall():\n\u001B[1;32m---> 56\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m     57\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpected parameter \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mparam\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     58\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m(\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(value)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m of shape \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtuple\u001B[39m(value\u001B[38;5;241m.\u001B[39mshape)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m) \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     59\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mof distribution \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mrepr\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     60\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mto satisfy the constraint \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mrepr\u001B[39m(constraint)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     61\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbut found invalid values:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mvalue\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     62\u001B[0m             )\n\u001B[0;32m     63\u001B[0m \u001B[38;5;28msuper\u001B[39m(Distribution, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m()\n",
      "\u001B[1;31mValueError\u001B[0m: Expected parameter loc (Tensor of shape (3,)) of distribution Normal(loc: torch.Size([3]), scale: torch.Size([3])) to satisfy the constraint Real(), but found invalid values:\ntensor([nan, nan, nan], device='cuda:0', grad_fn=<PermuteBackward0>)"
     ]
    }
   ],
   "source": [
    "filename = \"../log_file.txt\"\n",
    "f = open(filename,'w')\n",
    "total_train_step = 0\n",
    "mlp.train()\n",
    "for epoch in range(0,1):\n",
    "    for batch_id,data in enumerate(train_loader):\n",
    "        input, target = data\n",
    "        print(f\"---- {batch_id} batch----\")\n",
    "        # print(f\"---- {batch_id} batch----\",file=f)\n",
    "\n",
    "        # do the inference\n",
    "        input = input.to(device)\n",
    "        pi, mu, sigma = mlp(input)\n",
    "        print(f\"The [pi,mu,sigma] is : \\n\")\n",
    "        print(pi,\"\\n\",mu,\"\\n\",sigma)\n",
    "\n",
    "        # save the params\n",
    "        # params = list(mlp.named_parameters())\n",
    "\n",
    "        # # print the weight and grad with 'sequential' structure\n",
    "        # for i,m in enumerate(mlp.mlp_call.children()):\n",
    "        #     if isinstance(m, nn.Conv2d):\n",
    "        #         print(str(i)+\"(Conv2d).weight = \",m.weight)\n",
    "        #         print(str(i)+\"(Conv2d).weight.grad = \",m.weight.grad)\n",
    "        #     if isinstance(m, nn.Linear):\n",
    "        #         print(str(i)+\"(Linear).weight = \",m.weight)\n",
    "        #         print(str(i)+\"(Linear).weight.grad = \",m.weight.grad)\n",
    "        #\n",
    "        # for i,m in enumerate(mlp.z_pi.children()):\n",
    "        #     if isinstance(m, nn.Linear):\n",
    "        #         print(str(i)+\"(Linear).weight = \",m.weight)\n",
    "        #         print(str(i)+\"(Linear).weight.grad = \",m.weight.grad)\n",
    "        #\n",
    "        # for i,m in enumerate(mlp.z_mu.children()):\n",
    "        #     if isinstance(m, nn.Linear):\n",
    "        #         print(str(i)+\"(Linear).weight = \",m.weight)\n",
    "        #         print(str(i)+\"(Linear).weight.grad = \",m.weight.grad)\n",
    "\n",
    "        # cal the loss and draw the MDN\n",
    "        duration,m  = loss_preparation(pi, mu, sigma, target)\n",
    "        # draw_mdn(pi,duration,m,total_train_step)\n",
    "        loss = loss_fn(pi,duration,m,mu,sigma)\n",
    "        # loss.retain_grad()\n",
    "        draw_loss(total_train_step, loss.item())\n",
    "        print(\"训练次数：{}，Loss：{}\".format(total_train_step, loss.item()))\n",
    "\n",
    "        # optim\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print(\"训练次数：{}，Loss：{}, Loss's grad: {}\".format(total_train_step, loss.item(), loss.grad))\n",
    "\n",
    "        total_train_step += 1\n",
    "        # if total_train_step % 10 == 0:\n",
    "            # 一般不写loss，而是loss.item()\n",
    "f.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "$\\mathcal{L}(y \\vert x) = - \\log\\bigg\\{\\sum_{k=1}^K \\pi_k(x)  \\mathcal{N}\\big(y \\vert \\mu_k(x), \\Sigma_k(x)\\big)\\bigg\\}$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
