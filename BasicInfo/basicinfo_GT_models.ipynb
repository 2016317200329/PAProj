{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2022/11/08 15:54\n",
    "# @Author  : Wang Yujia\n",
    "# @File    : basicinfo_GT_models.ipynb\n",
    "# @Description : 关于GT模型的计算结果的基本信息"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 0. What for\n",
    "1. 关于GT模型的计算结果的基本信息\n",
    "\n",
    "# 1. Preparations\n",
    "## 1.1 全局设置"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "from visdom import Visdom\n",
    "from tqdm.notebook import tqdm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Info about 'P' which is the input of NNs\n",
    "## 2.1 Are the length of ‘P’ from different GT models the same? Yes\n",
    "1. 比较2个model的P的长度是否一样（一样的话方便画图）：\n",
    "2. 注意这里的P是**未经过K筛选**的，"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# GT model-0\n",
    "filename_P_0 = \"../data/SA_PT/results/PT_all1303_P.csv\"\n",
    "# GT model-1\n",
    "filename_P_1 = \"../data/info_asymm/results/asc_symmetry/GT_asc_symmetry_2_woKP.csv\"\n",
    "\n",
    "# GT model-2\n",
    "filename_P_2 = \"../data/SA_PT/results/PT_all1303_oneforall_P.csv\"\n",
    "\n",
    "# read data\n",
    "P_0 = pd.read_csv(filename_P_0, encoding=\"utf-8\")\n",
    "P_1 = pd.read_csv(filename_P_1, encoding=\"utf-8\")\n",
    "P_2 = pd.read_csv(filename_P_2, encoding=\"utf-8\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# transform str 'P' into narray 'P'\n",
    "def transform(str):\n",
    "    a = np.array(np.mat(str),dtype=np.float64)\n",
    "    d = a.flatten()\n",
    "    return d"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT model-1 包括了 *612* 组setting\n",
      "GT model-2 包括了 *612* 组setting\n",
      "两个GTmodel的'P'等长\n"
     ]
    }
   ],
   "source": [
    "print(f\"GT model-1 包括了 *{P_1.shape[0]}* 组setting\")\n",
    "print(f\"GT model-2 包括了 *{P_2.shape[0]}* 组setting\")\n",
    "\n",
    "for i in range(0,P_1.shape[0]):\n",
    "    # transform str into narray\n",
    "    p_1_i = transform(P_1.loc[i,'P'])\n",
    "    p_2_i = transform(P_2.loc[i,'P'])\n",
    "    assert len(p_1_i) == len(p_2_i), \"P不等长!\"\n",
    "print(\"两个GTmodel的'P'等长\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2 compare ‘P’ generated by different GT models [2 lines]\n",
    "1. 比较两个P的图像，画在visdom中"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception in user code:\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\envs\\pythorch\\lib\\site-packages\\urllib3\\connection.py\", line 175, in _new_conn\n",
      "    (self._dns_host, self.port), self.timeout, **extra_kw\n",
      "  File \"D:\\Anaconda\\envs\\pythorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 95, in create_connection\n",
      "    raise err\n",
      "  File \"D:\\Anaconda\\envs\\pythorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 85, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\envs\\pythorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 710, in urlopen\n",
      "    chunked=chunked,\n",
      "  File \"D:\\Anaconda\\envs\\pythorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 398, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"D:\\Anaconda\\envs\\pythorch\\lib\\site-packages\\urllib3\\connection.py\", line 239, in request\n",
      "    super(HTTPConnection, self).request(method, url, body=body, headers=headers)\n",
      "  File \"D:\\Anaconda\\envs\\pythorch\\lib\\http\\client.py\", line 1287, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"D:\\Anaconda\\envs\\pythorch\\lib\\http\\client.py\", line 1333, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"D:\\Anaconda\\envs\\pythorch\\lib\\http\\client.py\", line 1282, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"D:\\Anaconda\\envs\\pythorch\\lib\\http\\client.py\", line 1042, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"D:\\Anaconda\\envs\\pythorch\\lib\\http\\client.py\", line 980, in send\n",
      "    self.connect()\n",
      "  File \"D:\\Anaconda\\envs\\pythorch\\lib\\site-packages\\urllib3\\connection.py\", line 205, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"D:\\Anaconda\\envs\\pythorch\\lib\\site-packages\\urllib3\\connection.py\", line 187, in _new_conn\n",
      "    self, \"Failed to establish a new connection: %s\" % e\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000025C51373828>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\envs\\pythorch\\lib\\site-packages\\requests\\adapters.py\", line 450, in send\n",
      "    timeout=timeout\n",
      "  File \"D:\\Anaconda\\envs\\pythorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 786, in urlopen\n",
      "    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]\n",
      "  File \"D:\\Anaconda\\envs\\pythorch\\lib\\site-packages\\urllib3\\util\\retry.py\", line 592, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/compare_P (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000025C51373828>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。',))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\envs\\pythorch\\lib\\site-packages\\visdom\\__init__.py\", line 693, in _send\n",
      "    data=json.dumps(msg),\n",
      "  File \"D:\\Anaconda\\envs\\pythorch\\lib\\site-packages\\visdom\\__init__.py\", line 654, in _handle_post\n",
      "    r = self.session.post(url, data=data)\n",
      "  File \"D:\\Anaconda\\envs\\pythorch\\lib\\site-packages\\requests\\sessions.py\", line 577, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"D:\\Anaconda\\envs\\pythorch\\lib\\site-packages\\requests\\sessions.py\", line 529, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"D:\\Anaconda\\envs\\pythorch\\lib\\site-packages\\requests\\sessions.py\", line 645, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"D:\\Anaconda\\envs\\pythorch\\lib\\site-packages\\requests\\adapters.py\", line 519, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/compare_P (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000025C51373828>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。',))\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "on_close() takes 1 positional argument but 3 were given\n",
      "Visdom python client failed to establish socket to get messages from the server. This feature is optional and can be disabled by initializing Visdom with `use_incoming_socket=False`, which will prevent waiting for this request to timeout.\n"
     ]
    }
   ],
   "source": [
    "# 添加,use_incoming_socket=False之后似乎没办法append？\n",
    "env_str = \"compare_P\"\n",
    "viz = Visdom(env = \"compare_P\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# P_1.shape[0]\n",
    "for i in range(0,P_1.shape[0]):\n",
    "    # transform str into narray\n",
    "    p_1_i = transform(P_1.loc[i,'P'])\n",
    "    p_2_i = transform(P_2.loc[i,'P'])\n",
    "\n",
    "    v = P_1.loc[i,'retail']\n",
    "    b = P_1.loc[i,'bidfee']\n",
    "    d = P_1.loc[i,'bidincrement']\n",
    "\n",
    "    viz.line(Y = p_1_i, X = np.arange(0,len(p_1_i)), win = \"P_\"+str(i), env = env_str,update = 'append',name=\"model-1\",\n",
    "             opts= dict(title = f'P_{i}_v={v}_b={b}_d={d}',showlegend=True))\n",
    "    viz.line(Y = p_2_i, X = np.arange(0,len(p_2_i)), win = \"P_\"+str(i), env = env_str,update = 'append',name=\"model-2\")\n",
    "\n",
    "print(\"Done\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 保存整个环境\n",
    "viz.save(envs=['compare_P'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.3 compare ‘P’ under different params [3 lines]\n",
    "1. 这次画3条曲线，2条和上面一样，多一条表示的是对每个settings做一次infer得到params，这个params下generate出来的P曲线\n",
    "2. 因此有1303而不是612组“settings”"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "P_1.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_P_from_i(i):\n",
    "    v = P_0.loc[i,'retail']\n",
    "    b = P_0.loc[i,'bidfee']\n",
    "    d = P_0.loc[i,'bidincrement']\n",
    "\n",
    "    p_1 = P_1[(P_1.loc[:,'retail'] == v) & (P_1.loc[:,'bidfee'] == b) & (P_1.loc[:,'bidincrement'] == d)]\n",
    "    p_2 = P_2[(P_2.loc[:,'retail'] == v) & (P_2.loc[:,'bidfee'] == b) & (P_2.loc[:,'bidincrement'] == d)]\n",
    "\n",
    "    p_1_arr = transform(p_1.P.item())\n",
    "    p_2_arr = transform(p_2.P.item())\n",
    "\n",
    "    return (p_1_arr,p_2_arr)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "env_str = \"compare_P_2\"\n",
    "viz = Visdom(env=env_str)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in tqdm(range(0,P_0.shape[0])):\n",
    "    p_0_i = transform(P_0.loc[i,'P'])\n",
    "    # get transformed P from key_i\n",
    "    p_1_i,p_2_i = get_P_from_i(i)\n",
    "\n",
    "    v = P_0.loc[i,'retail']\n",
    "    b = P_0.loc[i,'bidfee']\n",
    "    d = P_0.loc[i,'bidincrement']\n",
    "\n",
    "    # assert(len(p_0_i) == len(p_1_i),\"Not in the same length!\")\n",
    "\n",
    "    viz.line(Y = p_0_i, X = np.arange(0,len(p_0_i)), win = \"P_\"+str(i), env = env_str,update = 'append',name=\"model-0\",\n",
    "             opts= dict(title = f'P_{i}_v={v}_b={b}_d={d}',showlegend=True))\n",
    "    viz.line(Y = p_1_i, X = np.arange(0,len(p_1_i)), win = \"P_\"+str(i), env = env_str,update = 'append',name=\"model-1\")\n",
    "    viz.line(Y = p_2_i, X = np.arange(0,len(p_2_i)), win = \"P_\"+str(i), env = env_str,update = 'append',name=\"model-2\")\n",
    "\n",
    "print(\"Done\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 保存整个环境\n",
    "viz.save(envs=env_str)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.4 ‘P’ in the target data\n",
    "1. 如果setting=[v,b,d]的话，画‘P’没什么意义，因为对于实际数据，不止要考虑这3个设置，还要考虑product_id等"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Info about dataset\n",
    "## 3.1 How many ‘settings’ in the dataset\n",
    "1. dataset指的是samples数量在16之上的所有的ascending-price auctions,GT的两个model用这些data做了generate的过程\n",
    "2. 根据settings含义的不同，需要有不同的统计"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "按照setting=['retail', 'bidfee', 'bidincrement'], 一共有 *612*\n",
      "按照setting=['product_id', 'retail', 'bidfee', 'bidincrement'], 一共有 *1303*\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../data/info_asymm/datawithnp_asc_symmetry_2_selected.csv\"\n",
    "data = pd.read_csv(data_path, encoding=\"utf-8\")\n",
    "\n",
    "setting_1 = ['retail','bidfee','bidincrement']\n",
    "setting_2 = ['product_id','retail','bidfee','bidincrement']\n",
    "\n",
    "data_1 = data.groupby(setting_1)\n",
    "data_2 = data.groupby(setting_2)\n",
    "\n",
    "print(f\"按照setting={setting_1}, 一共有 *{len(data_1)}*\")\n",
    "print(f\"按照setting={setting_2}, 一共有 *{len(data_2)}*\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.2 Are the dataset in the same size in the amount of setting?\n",
    "1. 2个GT models用的dataset有微小不同，他们的settings数目是一样的吗: YES"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "按照setting=['retail', 'bidfee', 'bidincrement'], 一共有 *612*\n",
      "按照setting=['product_id', 'retail', 'bidfee', 'bidincrement'], 一共有 *1303*\n"
     ]
    }
   ],
   "source": [
    "data_pt_path = \"../data/SA_PT/datawithnp_PT_selected.csv\"\n",
    "data_pt = pd.read_csv(data_pt_path, encoding=\"utf-8\")\n",
    "\n",
    "data_pt_1 = data_pt.groupby(setting_1)\n",
    "data_pt_2 = data_pt.groupby(setting_2)\n",
    "\n",
    "print(f\"按照setting={setting_1}, 一共有 *{len(data_pt_1)}*\")\n",
    "print(f\"按照setting={setting_2}, 一共有 *{len(data_pt_2)}*\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.3 What if I drop settings with short 'T'?\n",
    "1. 尝试drop掉`T < drop_size` 的settings，注意T = (v-b)/d\n",
    "2. 这里settings指的是setting_1 = ['retail','bidfee','bidincrement']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "data_key_path = \"../data/SA_PT/data_key_PT_vbd.csv\"\n",
    "data_key_vbd = pd.read_csv(data_key_path,encoding=\"utf-8\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of T: *17756.995098039217*\n",
      "median of T: *1398.0*\n"
     ]
    }
   ],
   "source": [
    "data_key_vbd['T'] = np.array((data_key_vbd.retail-data_key_vbd.bidfee)/data_key_vbd.bidincrement,dtype=int)\n",
    "data_key_vbd.sort_values(by = 'T', inplace=True, ascending=True,ignore_index=True)\n",
    "print(f\"mean of T: *{np.mean(data_key_vbd['T'])}*\")\n",
    "print(f\"median of T: *{np.median(data_key_vbd['T'])}*\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最初settings数量为 *612*\n",
      "drop_size = *100*\n",
      "剩余settings数量为 *591*\n",
      "drop掉了 *21* 个setting，占比：*0.03431372549019608*\n"
     ]
    }
   ],
   "source": [
    "drop_size = 100\n",
    "print(f\"最初settings数量为 *{data_key_vbd.shape[0]}*\")\n",
    "data_key_ls100 = data_key_vbd[(data_key_vbd.loc[:,'T']>=drop_size)]\n",
    "print(f\"drop_size = *{drop_size}*\")\n",
    "print(f\"剩余settings数量为 *{data_key_ls100.shape[0]}*\")\n",
    "print(f\"drop掉了 *{data_key_vbd.shape[0]-data_key_ls100.shape[0]}* 个setting，占比：*{(data_key_vbd.shape[0]-data_key_ls100.shape[0])/(data_key_vbd.shape[0])}*\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最初settings数量为 *612*\n",
      "drop_size = *150*\n",
      "剩余settings数量为 *573*\n",
      "drop掉了 *39* 个setting，占比：*0.06372549019607843*\n"
     ]
    }
   ],
   "source": [
    "drop_size = 150\n",
    "print(f\"最初settings数量为 *{data_key_vbd.shape[0]}*\")\n",
    "data_key_ls100 = data_key_vbd[(data_key_vbd.loc[:, 'T'] >= drop_size)]\n",
    "print(f\"drop_size = *{drop_size}*\")\n",
    "print(f\"剩余settings数量为 *{data_key_ls100.shape[0]}*\")\n",
    "print(f\"drop掉了 *{data_key_vbd.shape[0] - data_key_ls100.shape[0]}* 个setting，占比：*{(data_key_vbd.shape[0] - data_key_ls100.shape[0]) / (data_key_vbd.shape[0])}*\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最初settings数量为 *612*\n",
      "drop_size = *200*\n",
      "剩余settings数量为 *546*\n",
      "drop掉了 *66* 个setting，占比：*0.10784313725490197*\n"
     ]
    }
   ],
   "source": [
    "drop_size = 200\n",
    "print(f\"最初settings数量为 *{data_key_vbd.shape[0]}*\")\n",
    "data_key_ls100 = data_key_vbd[(data_key_vbd.loc[:, 'T'] >= drop_size)]\n",
    "print(f\"drop_size = *{drop_size}*\")\n",
    "print(f\"剩余settings数量为 *{data_key_ls100.shape[0]}*\")\n",
    "print(f\"drop掉了 *{data_key_vbd.shape[0] - data_key_ls100.shape[0]}* 个setting，占比：*{(data_key_vbd.shape[0] - data_key_ls100.shape[0]) / (data_key_vbd.shape[0])}*\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最初settings数量为 *612*\n",
      "drop_size = *300*\n",
      "剩余settings数量为 *490*\n",
      "drop掉了 *122* 个setting，占比：*0.19934640522875818*\n"
     ]
    }
   ],
   "source": [
    "drop_size = 300\n",
    "print(f\"最初settings数量为 *{data_key_vbd.shape[0]}*\")\n",
    "data_key_ls100 = data_key_vbd[(data_key_vbd.loc[:, 'T'] >= drop_size)]\n",
    "print(f\"drop_size = *{drop_size}*\")\n",
    "print(f\"剩余settings数量为 *{data_key_ls100.shape[0]}*\")\n",
    "print(f\"drop掉了 *{data_key_vbd.shape[0] - data_key_ls100.shape[0]}* 个setting，占比：*{(data_key_vbd.shape[0] - data_key_ls100.shape[0]) / (data_key_vbd.shape[0])}*\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.4 when \"v-C(t-1)-dt-b\"=0，t=？\n",
    "1. v-C(t-1)-dt-b=0时，t为多少？对每个settings都进行求解，得出最大值\n",
    "2. 求这个值是为了设定threshold K"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v-C(t-1)-dt-b=0时\n",
      "t平均有: 1515.4787581699347\n",
      "t中位数有: 490.5\n"
     ]
    }
   ],
   "source": [
    "# GT model-2 (PT)\n",
    "filename_P_2 = \"../data/SA_PT/results/PT_all1303_oneforall_P.csv\"\n",
    "P_2 = pd.read_csv(filename_P_2, encoding=\"utf-8\")\n",
    "\n",
    "t_K = np.array([0]*P_2.shape[0])\n",
    "\n",
    "for i in range(0,P_2.shape[0]):\n",
    "    v = P_2.loc[i,'retail']\n",
    "    b = P_2.loc[i,'bidfee']\n",
    "    d = P_2.loc[i,'bidincrement']\n",
    "\n",
    "    t_K[i] = (v-0.8*b) / (0.2+d)\n",
    "print(f\"v-C(t-1)-dt-b=0时\")\n",
    "print(f\"t平均有: {np.mean(t_K)}\")\n",
    "print(f\"t中位数有: {np.median(t_K)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
