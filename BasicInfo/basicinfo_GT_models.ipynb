{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2022/11/08 15:54\n",
    "# @Author  : Wang Yujia\n",
    "# @File    : basicinfo_GT_models.ipynb\n",
    "# @Description : 关于GT模型的计算结果的基本信息"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 0. What for\n",
    "1. 关于GT模型的计算结果的基本信息\n",
    "\n",
    "# 1. Preparations\n",
    "## 1.1 全局设置"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "\n",
    "features_GT = ['product_id','bidincrement','bidfee','retail']\n",
    "\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "from visdom import Visdom\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "# viz = Visdom(env='P',use_incoming_socket=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2 读取data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../dataSA_PT/results/results/PT_all1288_P.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-148-690983f65891>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mP_1\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mP_1_path\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mencoding\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"utf-8\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 6\u001B[1;33m \u001B[0mP_2\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mP_2_path\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mencoding\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"utf-8\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mD:\\Anaconda\\envs\\pythorch\\lib\\site-packages\\pandas\\io\\parsers.py\u001B[0m in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001B[0m\n\u001B[0;32m    686\u001B[0m     )\n\u001B[0;32m    687\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 688\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0m_read\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    689\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    690\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda\\envs\\pythorch\\lib\\site-packages\\pandas\\io\\parsers.py\u001B[0m in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    452\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    453\u001B[0m     \u001B[1;31m# Create the parser.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 454\u001B[1;33m     \u001B[0mparser\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mTextFileReader\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfp_or_buf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    455\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    456\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mchunksize\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0miterator\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda\\envs\\pythorch\\lib\\site-packages\\pandas\\io\\parsers.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[0;32m    946\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"has_index_names\"\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"has_index_names\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    947\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 948\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_make_engine\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    949\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    950\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mclose\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda\\envs\\pythorch\\lib\\site-packages\\pandas\\io\\parsers.py\u001B[0m in \u001B[0;36m_make_engine\u001B[1;34m(self, engine)\u001B[0m\n\u001B[0;32m   1178\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_make_engine\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mengine\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"c\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1179\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mengine\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m\"c\"\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1180\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mCParserWrapper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1181\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1182\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mengine\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m\"python\"\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda\\envs\\pythorch\\lib\\site-packages\\pandas\\io\\parsers.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, src, **kwds)\u001B[0m\n\u001B[0;32m   1991\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"compression\"\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mencoding\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1992\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msrc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1993\u001B[1;33m                 \u001B[0msrc\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msrc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"rb\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1994\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhandles\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msrc\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1995\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../dataSA_PT/results/results/PT_all1288_P.csv'"
     ]
    }
   ],
   "source": [
    "# P in info_insym\n",
    "P_1_path = \"../data/info_asymm/results/asc_symmetry/GT_asc_symmetry_2_P.csv\"\n",
    "P_2_path = \"../dataSA_PT/results/PT_all1288_P.csv\"\n",
    "\n",
    "P_1 = pd.read_csv(P_1_path, encoding=\"utf-8\")\n",
    "P_2 = pd.read_csv(P_2_path, encoding=\"utf-8\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Info about P which is the input of NNs\n",
    "## 2.1 How many auction settings are included in 'info_insymm', 'GT'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 'info_insymm', there is *(612, 4)*\n",
      "In 'GT', there is *(612, 5)*\n"
     ]
    }
   ],
   "source": [
    "print(f\"In 'info_insymm', there is *{P_1.shape}*\")\n",
    "print(f\"In 'GT', there is *{P_2.shape}*\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Info about dataset\n",
    "## 3.1 How many ‘settings’ in the dataset\n",
    "1. dataset指的是samples数量在16之上的所有的ascending-price auctions,GT的两个model用这些data做了generate的过程\n",
    "2. 根据settings含义的不同，需要有不同的统计"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "按照setting=['retail', 'bidfee', 'bidincrement'], 一共有 *612*\n",
      "按照setting=['product_id', 'retail', 'bidfee', 'bidincrement'], 一共有 *1303*\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../data/info_asymm/datawithnp_asc_symmetry_2_selected.csv\"\n",
    "data = pd.read_csv(data_path, encoding=\"utf-8\")\n",
    "\n",
    "setting_1 = ['retail','bidfee','bidincrement']\n",
    "setting_2 = ['product_id','retail','bidfee','bidincrement']\n",
    "\n",
    "data_1 = data.groupby(setting_1)\n",
    "data_2 = data.groupby(setting_2)\n",
    "\n",
    "print(f\"按照setting={setting_1}, 一共有 *{len(data_1)}*\")\n",
    "print(f\"按照setting={setting_2}, 一共有 *{len(data_2)}*\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.2 Are the dataset in the same size in the amount of setting?\n",
    "1. 2个GT models用的dataset有微小不同，他们的settings数目是一样的吗: YES"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "按照setting=['retail', 'bidfee', 'bidincrement'], 一共有 *612*\n",
      "按照setting=['product_id', 'retail', 'bidfee', 'bidincrement'], 一共有 *1303*\n"
     ]
    }
   ],
   "source": [
    "data_pt_path = \"../data/SA_PT/datawithnp_PT_selected.csv\"\n",
    "data_pt = pd.read_csv(data_pt_path, encoding=\"utf-8\")\n",
    "\n",
    "data_pt_1 = data_pt.groupby(setting_1)\n",
    "data_pt_2 = data_pt.groupby(setting_2)\n",
    "\n",
    "print(f\"按照setting={setting_1}, 一共有 *{len(data_pt_1)}*\")\n",
    "print(f\"按照setting={setting_2}, 一共有 *{len(data_pt_2)}*\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Info about result ‘P’\n",
    "## 4.1 the length of ‘P’ of different GT models the same? Yes\n",
    "1. 比较2个model的P的长度是否一样（一样的话方便画图）：\n",
    "2. 注意这里的P是**未经过K筛选**的，"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# GT model-0\n",
    "filename_P_0 = \"../data/SA_PT/results/PT_all1303_P.csv\"\n",
    "# GT model-1\n",
    "filename_P_1 = \"../data/info_asymm/results/asc_symmetry/GT_asc_symmetry_2_woKP.csv\"\n",
    "\n",
    "# GT model-2\n",
    "filename_P_2 = \"../data/SA_PT/results/PT_all1303_oneforall_P.csv\"\n",
    "\n",
    "# read data\n",
    "P_0 = pd.read_csv(filename_P_0, encoding=\"utf-8\")\n",
    "P_1 = pd.read_csv(filename_P_1, encoding=\"utf-8\")\n",
    "P_2 = pd.read_csv(filename_P_2, encoding=\"utf-8\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# transform str 'P' into narray 'P'\n",
    "def transform(str):\n",
    "    a = np.array(np.mat(str))\n",
    "    d = a.flatten()\n",
    "    return d"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:8: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "<>:8: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "<>:8: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "<ipython-input-155-8009a2cabfc1>:8: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(len(p_1_i) == len(p_2_i),f\"{i}: P不等长!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT model-1 包括了 *612* 组setting\n",
      "GT model-2 包括了 *612* 组setting\n",
      "两个GTmodel的'P'等长\n"
     ]
    }
   ],
   "source": [
    "print(f\"GT model-1 包括了 *{P_1.shape[0]}* 组setting\")\n",
    "print(f\"GT model-2 包括了 *{P_2.shape[0]}* 组setting\")\n",
    "\n",
    "for i in range(0,P_1.shape[0]):\n",
    "    # transform str into narray\n",
    "    p_1_i = transform(P_1.loc[i,'P'])\n",
    "    p_2_i = transform(P_2.loc[i,'P'])\n",
    "    assert(len(p_1_i) == len(p_2_i),f\"{i}: P不等长!\")\n",
    "print(\"两个GTmodel的'P'等长\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.2 compare ‘P’ generated by different GT models [2 lines]\n",
    "1. 比较两个P的图像，画在visdom中"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 添加,use_incoming_socket=False之后似乎没办法append？\n",
    "env_str = \"compare_P\"\n",
    "viz = Visdom(env = \"compare_P\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# P_1.shape[0]\n",
    "for i in range(0,P_1.shape[0]):\n",
    "    # transform str into narray\n",
    "    p_1_i = transform(P_1.loc[i,'P'])\n",
    "    p_2_i = transform(P_2.loc[i,'P'])\n",
    "\n",
    "    v = P_1.loc[i,'retail']\n",
    "    b = P_1.loc[i,'bidfee']\n",
    "    d = P_1.loc[i,'bidincrement']\n",
    "\n",
    "    viz.line(Y = p_1_i, X = np.arange(0,len(p_1_i)), win = \"P_\"+str(i), env = env_str,update = 'append',name=\"model-1\",\n",
    "             opts= dict(title = f'P_{i}_v={v}_b={b}_d={d}',showlegend=True))\n",
    "    viz.line(Y = p_2_i, X = np.arange(0,len(p_2_i)), win = \"P_\"+str(i), env = env_str,update = 'append',name=\"model-2\")\n",
    "\n",
    "print(\"Done\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 保存整个环境\n",
    "viz.save(envs=['compare_P'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.3 compare 'P' under different params [3 lines]\n",
    "1. 这次画3条曲线，2条和上面一样，多一条表示的是对每个settings做一次infer得到params，这个params下generate出来的P曲线\n",
    "2. 因此有1303而不是612组“settings”"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "   bidincrement  bidfee  retail  \\\n0          0.15    0.75  169.99   \n1          0.15    0.75  499.99   \n2          0.15    0.75  299.99   \n3          0.15    0.75   89.99   \n4          0.15    0.75   59.99   \n\n                                                   P  \n0  [0.004412024236719825, 0.004396437716806756, 0...  \n1  [0.001500030000600061, 0.001498229388403341, 0...  \n2  [0.0025000833361111807, 0.0024950805012603767,...  \n3  [0.008334259362151375, 0.00827859868074787, 0....  \n4  [0.012502083680613452, 0.012376728563495022, 0...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bidincrement</th>\n      <th>bidfee</th>\n      <th>retail</th>\n      <th>P</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.15</td>\n      <td>0.75</td>\n      <td>169.99</td>\n      <td>[0.004412024236719825, 0.004396437716806756, 0...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.15</td>\n      <td>0.75</td>\n      <td>499.99</td>\n      <td>[0.001500030000600061, 0.001498229388403341, 0...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.15</td>\n      <td>0.75</td>\n      <td>299.99</td>\n      <td>[0.0025000833361111807, 0.0024950805012603767,...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.15</td>\n      <td>0.75</td>\n      <td>89.99</td>\n      <td>[0.008334259362151375, 0.00827859868074787, 0....</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.15</td>\n      <td>0.75</td>\n      <td>59.99</td>\n      <td>[0.012502083680613452, 0.012376728563495022, 0...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_1.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "从1303那个dataset中，根据key_i找到对应的P"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "def get_P_from_i(i):\n",
    "    v = P_0.loc[i,'retail']\n",
    "    b = P_0.loc[i,'bidfee']\n",
    "    d = P_0.loc[i,'bidincrement']\n",
    "\n",
    "    p_1 = P_1[(P_1.loc[:,'retail'] == v) & (P_1.loc[:,'bidfee'] == b) & (P_1.loc[:,'bidincrement'] == d)]\n",
    "    p_2 = P_2[(P_2.loc[:,'retail'] == v) & (P_2.loc[:,'bidfee'] == b) & (P_2.loc[:,'bidincrement'] == d)]\n",
    "\n",
    "    p_1_arr = transform(p_1.P.item())\n",
    "    p_2_arr = transform(p_2.P.item())\n",
    "\n",
    "    return (p_1_arr,p_2_arr)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    }
   ],
   "source": [
    "env_str = \"compare_P_2\"\n",
    "viz = Visdom(env=env_str)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/1303 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5371932bebe94b0680b292b9990e2ec7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-86-36ae511e2ed2>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      3\u001B[0m     \u001B[0mp_0_i\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtransform\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mP_0\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mloc\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;34m'P'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m     \u001B[1;31m# get transformed P from key_i\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m     \u001B[0mp_1_i\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mp_2_i\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mget_P_from_i\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      6\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m     \u001B[0mv\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mP_0\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mloc\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;34m'retail'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-78-c84470c4f56a>\u001B[0m in \u001B[0;36mget_P_from_i\u001B[1;34m(i)\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m     \u001B[1;31m# print(type(p_1.P.item()))\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 10\u001B[1;33m     \u001B[0mp_1_arr\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtransform\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mp_1\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mP\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     11\u001B[0m     \u001B[0mp_2_arr\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtransform\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mp_2\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mP\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     12\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mp_1_arr\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mp_2_arr\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-18-ed7b542c7e93>\u001B[0m in \u001B[0;36mtransform\u001B[1;34m(str)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# transform str 'P' into narray 'P'\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mtransform\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstr\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m     \u001B[0ma\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstr\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m     \u001B[0md\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0ma\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mflatten\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0md\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda\\envs\\pythorch\\lib\\site-packages\\numpy\\matrixlib\\defmatrix.py\u001B[0m in \u001B[0;36masmatrix\u001B[1;34m(data, dtype)\u001B[0m\n\u001B[0;32m     67\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     68\u001B[0m     \"\"\"\n\u001B[1;32m---> 69\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mmatrix\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     70\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     71\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda\\envs\\pythorch\\lib\\site-packages\\numpy\\matrixlib\\defmatrix.py\u001B[0m in \u001B[0;36m__new__\u001B[1;34m(subtype, data, dtype, copy)\u001B[0m\n\u001B[0;32m    140\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    141\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 142\u001B[1;33m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_convert_from_string\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    143\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    144\u001B[0m         \u001B[1;31m# now convert data to an array\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda\\envs\\pythorch\\lib\\site-packages\\numpy\\matrixlib\\defmatrix.py\u001B[0m in \u001B[0;36m_convert_from_string\u001B[1;34m(data)\u001B[0m\n\u001B[0;32m     24\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mcol\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mtrow\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     25\u001B[0m             \u001B[0mtemp\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcol\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 26\u001B[1;33m             \u001B[0mnewrow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mextend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmap\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mast\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mliteral_eval\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtemp\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     27\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mcount\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     28\u001B[0m             \u001B[0mNcols\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnewrow\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(0,P_0.shape[0])):\n",
    "    p_0_i = transform(P_0.loc[i,'P'])\n",
    "    # get transformed P from key_i\n",
    "    p_1_i,p_2_i = get_P_from_i(i)\n",
    "\n",
    "    v = P_0.loc[i,'retail']\n",
    "    b = P_0.loc[i,'bidfee']\n",
    "    d = P_0.loc[i,'bidincrement']\n",
    "\n",
    "    # assert(len(p_0_i) == len(p_1_i),\"Not in the same length!\")\n",
    "\n",
    "    viz.line(Y = p_0_i, X = np.arange(0,len(p_0_i)), win = \"P_\"+str(i), env = env_str,update = 'append',name=\"model-0\",\n",
    "             opts= dict(title = f'P_{i}_v={v}_b={b}_d={d}',showlegend=True))\n",
    "    viz.line(Y = p_1_i, X = np.arange(0,len(p_1_i)), win = \"P_\"+str(i), env = env_str,update = 'append',name=\"model-1\")\n",
    "    viz.line(Y = p_2_i, X = np.arange(0,len(p_2_i)), win = \"P_\"+str(i), env = env_str,update = 'append',name=\"model-2\")\n",
    "\n",
    "print(\"Done\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 保存整个环境\n",
    "viz.save(envs=env_str)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.3 'P' in the target data\n",
    "1. 如果setting=[v,b,d]的话，画‘P’没什么意义，因为对于实际数据，不止要考虑这3个设置，还要考虑product_id等"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
