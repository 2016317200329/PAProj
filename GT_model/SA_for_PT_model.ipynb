{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 310,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2022/10/09 16:19\n",
    "# @Author  : Wang Yujia\n",
    "# @File    : SA_for_PT_model.ipynb\n",
    "# @Description : Parameter estimation for PT_model using Simulated Annealing"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 0. What for\n",
    "\n",
    "# 1. Preparations\n",
    "1. infer参数一是需要data，二是需要把p表示出来才能写出来loss func\n",
    "2. data来自`data_selected_path`\n",
    "\n",
    "## 1.1 全局设置\n",
    "1. 除了表示uniq auction的features，还引入了\n",
    "    - 'cnt_uniq':表示paper里的Loss function公式里的A"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    }
   ],
   "source": [
    "# data path\n",
    "data_selected_path = \"../data/info_asymm/datawithnp_asc_symmetry_2_selected.csv\"\n",
    "# data_key path\n",
    "data_key_path = \"../data/SA_PT/data_key.csv\"\n",
    "# optimized parameters' saving path:\n",
    "params_opitim_path = \"../data/SA_PT/params_opitim.csv\"\n",
    "\n",
    "# for PT\n",
    "# alpha = 1\n",
    "# delta = 1\n",
    "# labda = 2.25\n",
    "# features that GT need\n",
    "features_GT = ['product_id','bidincrement','bidfee','retail']\n",
    "features_GT_infer = ['cnt_uniq']\n",
    "\n",
    "# for SA\n",
    "# initial params\n",
    "table_5_M = [0.025,0.85,3.72]\n",
    "# lower/ upper bound\n",
    "lb = [-0.3,0.01,0.01]\n",
    "ub = [0.3, 3, 18]\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sympy\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "from sko.SA import SABoltzmann\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from sko.tools import set_run_mode\n",
    "from scipy.optimize import fsolve\n",
    "from visdom import Visdom\n",
    "\n",
    "viz = Visdom()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2 data 读取\n",
    "1. 读取data以做SA\n",
    "2. 提取出来`data_key`，以及其他计算需要的features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For PT model, there are *1303* settings waiting to be inferred.\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(data_selected_path, encoding=\"utf-8\")\n",
    "data_key = data[features_GT].copy()\n",
    "data_key.drop_duplicates(inplace=True)\n",
    "data_key.to_csv(data_key_path,header=True, encoding=\"utf-8\",index=False)\n",
    "\n",
    "B = np.array(data.bidfee)               # bid fee (cent to dollar)\n",
    "D = np.array(data.bidincrement)         # bid increment (cent to dollar)\n",
    "V = np.array(data.retail)               # valuation\n",
    "# 需要计算`N_uniq_auction`组setting下的结果\n",
    "N_uniq_auction= data_key.shape[0]\n",
    "\n",
    "print(\"For PT model, there are *{}* settings waiting to be inferred.\".format(N_uniq_auction))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.3 functions about 'key'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "outputs": [],
   "source": [
    "# get key from i in 'data_key'\n",
    "def get_key_from_index(i,str=\"NotStr\"):\n",
    "    if(str==\"str\"):\n",
    "        key_i = list(data_key.iloc[i,:])\n",
    "        key_i_str = (str(key_i[0]),str(key_i[1]),str(key_i[2]))\n",
    "        return key_i_str\n",
    "    else:\n",
    "        key_i = data_key.iloc[i,:]\n",
    "        return key_i\n",
    "\n",
    "#features_GT = ['product_id','bidincrement','bidfee','retail']\n",
    "def select_data_fromkey(key_i_str):\n",
    "    return data[(data['product_id'] == key_i_str[0]) & (data['bidincrement'] == key_i_str[1]) & (data['bidfee'] == key_i_str[2]) & (data['retail'] == key_i_str[3])].copy()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. PT model\n",
    "## 2.1 prob. weighting func\n",
    "1. 根据Eq(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "outputs": [],
   "source": [
    "def OMEGA(p,delta):\n",
    "    return p**delta * ((p**delta + (1-p)**delta)**(-1/delta))\n",
    "    # return p"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2 C_{t-1}\n",
    "1. 根据5.1.2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "outputs": [],
   "source": [
    "def C(t,b):\n",
    "    return 0.2*t*b"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.3 value functions\n",
    "1. 根据Eq(7)-(9)\n",
    "2. 注意这里把(-labda)(1-sympy.E**(alpha*x))/alpha的`labda`拿到外面去了，方便写"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "outputs": [],
   "source": [
    "# valuation function\n",
    "def f(x, alpha):\n",
    "    # return (1-x**alpha)\n",
    "    return (1-sympy.E**(-alpha*x))\n",
    "    # return (1-np.exp(-alpha*x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.4 Equi. condition\n",
    "1. 根据Eq(6)\n",
    "2. 注意分辨怎么代入上面的公式"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "outputs": [],
   "source": [
    "ans_scipy=[]\n",
    "def func_1(u,*args):\n",
    "    alpha,delta,labda,t,b,tmp = args\n",
    "    return (labda * f(x=C(t-1, b), alpha=alpha) - labda * OMEGA(u, delta) * f(x=(C(t-1, b) + b), alpha=alpha) + OMEGA(1-u, delta) * f(tmp, alpha))\n",
    "\n",
    "def func_2(u,*args):\n",
    "    alpha,delta,labda,t,b,tmp = args\n",
    "    return (-f(x=C(t-1, b), alpha=alpha) + OMEGA(u, delta) * f(x=(C(t-1, b) + b), alpha=alpha) + (1 - OMEGA(u, delta)) * f(-tmp, alpha))\n",
    "\n",
    "def f_Equi(t,v,d,b,alpha,labda,delta):\n",
    "    u = sympy.Symbol('u')\n",
    "\n",
    "    tmp = v-d*t-C(t-1,b) - b\n",
    "\n",
    "    if(tmp >= 0):\n",
    "        func_1 = (labda * f(x=C(t-1, b), alpha=alpha) - labda * OMEGA(u, delta) * f(x=(C(t-1, b) + b), alpha=alpha) + OMEGA(1-u, delta) * f(tmp, alpha))\n",
    "        root =  sympy.nsolve(func_1,(0,1),solver='bisect', verify=False)\n",
    "        #print(f\"t:{t} ---- u:{root}\")\n",
    "    else:\n",
    "        func_2 = (-f(x=C(t-1, b), alpha=alpha) + OMEGA(u, delta) * f(x=(C(t-1, b) + b), alpha=alpha) + (1 - OMEGA(u, delta)) * f(-tmp, alpha))\n",
    "        root =  sympy.nsolve(func_2,(0,1),solver='bisect', verify=False)\n",
    "        #print(f\"t:{t} -- u:{root}\")\n",
    "\n",
    "    # if(tmp >= 0):\n",
    "    #     root = fsolve(func_1,np.zeros(1),args =(alpha,delta,labda,t,b,tmp))\n",
    "    #     if(root == 0.0):\n",
    "    #         print(f\"t:{t} ---- u:{root}\")\n",
    "    # else:\n",
    "    #     root = fsolve(func_2,np.zeros(1),args =(alpha,delta,labda,t,b,tmp))\n",
    "    #     if(root == 0.0):\n",
    "    #         print(f\"t:{t} -- u:{root}\")\n",
    "    return root"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. SA\n",
    "## 3.1 define loss function\n",
    "1. loss function: NLL for auctions with same `features_GT`\n",
    "2."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "outputs": [],
   "source": [
    "def loss_func(params,other_params):\n",
    "    #start_time_loss = datetime.datetime.now()\n",
    "    alpha = params[0]\n",
    "    delta = params[1]\n",
    "    labda = params[2]\n",
    "\n",
    "    max_T,v,d,b = other_params\n",
    "\n",
    "    # solve for U from Equi. condt.\n",
    "    U_i = [0] * (max_T + 1)\n",
    "    U_i[0] = 1\n",
    "\n",
    "    for t in range(1,max_T+1):\n",
    "\n",
    "        U_i[t] = f_Equi(t, v, d, b, alpha, labda, delta)\n",
    "        #viz.line([0.0],[0],win = 'U_i_'+str(i),opts= dict(title='U_i[t]'))\n",
    "        #viz.line([np.float(U_i[t])],[t],win = 'U_i_'+str(i), update='append')\n",
    "\n",
    "    # calculate NLL under this auction setting & PT params\n",
    "    nll = 0.0\n",
    "    if(U_i[0]==1):\n",
    "        U_i.pop(0)            # because U_i[0]=1\n",
    "    U_tmp_df = pd.DataFrame(U_i, index=np.arange(0, U_i.__len__()), columns=['U'], dtype=float)\n",
    "    for idx in range(0,data_i.shape[0]):\n",
    "        # sum up the log prob among all durations of this auction\n",
    "        nll += ( np.sum(U_tmp_df[0:(T_i[idx]-1)][:].apply(np.log,axis=1)) + np.log(1-U_tmp_df.iat[(T_i[idx]-1),0]) )* cnt_n_2_i[idx]\n",
    "    #print('> The loss costs {time_costs}s \\n'.format(time_costs=(datetime.datetime.now() - start_time_loss).total_seconds()))\n",
    "\n",
    "    return float(-nll)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.2 do SA\n",
    "1. 要对每一个setting做一次infer == 对每一个setting执行一次SA。\n",
    "    - 可以并行吗？YES\n",
    "2. 具体的：对每个setting `i`\n",
    "    - 每一个setting `i` 可以提取出来一个`data_i`，代表所有auction\n",
    "    - 每一个`data_i`中的`cnt_uniq`，也就是`A`，是相同的，表示setting `i` 进行的拍卖总次数.【但是这个`A`在计算loss的时候派不上用场】\n",
    "    - `N`表示duration，因此paper公式里的$T_a$即`N[a]`\n",
    "    - 因此有`A = sum(data_i['cnt_n_2'])`，其中的'cnt_n_2'表示了该行对应的`duration=N`发生的次数\n",
    "    - 按照上文，求解`U[i]_t` which is a array with shape of (max(N)),也就是求解paper里的`p_t`\n",
    "    - 求nll时，记得\n",
    "3.每次进行`L`次对参数的试探寻找，每次寻找对应一个温度一组新的参数。\n",
    "    - 优化的完成/退出条件：温度小于`T_min`或者最低温度保持`max_stay_counter`次的不变\n",
    "    - 鉴于温度小于`T_min`很难达到，因此基本上对一组参数进行优化要进行L*max_stay_counter+1次运算（loss运算）"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "outputs": [],
   "source": [
    "params_opitim = pd.DataFrame(columns=['key_idx','alpha','delta','labda','initial_loss','final_loss','avg_loss'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:18: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "<>:18: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "<>:18: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "<ipython-input-321-c904c3f6ad72>:18: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(A_i == sum(cnt_n_2_i),\"'cnt_uniq' does not match with sum of 'cnt_n_2'!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> For the *5_th( data_key, the max_T is: *527*\n",
      "> retail = 49.99,bidincrement = 0.15, bidfee = 0.75, infer PT's parameters\n",
      "> Initilizing SA....... \n",
      "\n",
      "> Now do SA....... \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\pythorch\\lib\\site-packages\\ipykernel_launcher.py:24: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STOP CODE:  Stay unchanged in the last 11 iterations\n",
      "> The whole inference process costs 1520.446903s \n",
      "\n",
      "> SA ENDS....... \n",
      "\n",
      "> For the *6_th( data_key, the max_T is: *2686*\n",
      "> retail = 399.99,bidincrement = 0.15, bidfee = 0.75, infer PT's parameters\n",
      "> Initilizing SA....... \n",
      "\n",
      "> Now do SA....... \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\pythorch\\lib\\site-packages\\ipykernel_launcher.py:24: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'pop from an empty set'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-321-c904c3f6ad72>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     34\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     35\u001B[0m     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"> Now do SA....... \\n\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 36\u001B[1;33m     \u001B[0mbest_x\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbest_y\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0msa_boltzmann\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrun\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     37\u001B[0m     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'> The whole inference process costs {time_costs}s \\n'\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtime_costs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdatetime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdatetime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnow\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mstart_time\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtotal_seconds\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     38\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda\\envs\\pythorch\\lib\\site-packages\\sko\\SA.py\u001B[0m in \u001B[0;36mrun\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     78\u001B[0m                 \u001B[0mx_new\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_new_x\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx_current\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     79\u001B[0m                 \u001B[1;31m# print(\"x_new after clipping: \", x_new)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 80\u001B[1;33m                 \u001B[0my_new\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx_new\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     81\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     82\u001B[0m                 \u001B[1;31m# Metropolis\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-319-ae86005aa98e>\u001B[0m in \u001B[0;36mloss_func\u001B[1;34m(params)\u001B[0m\n\u001B[0;32m     11\u001B[0m     \u001B[1;32mfor\u001B[0m \u001B[0mt\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mmax_T\u001B[0m\u001B[1;33m+\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     12\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 13\u001B[1;33m         \u001B[0mU_i\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mt\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mf_Equi\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mt\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mv\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0md\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mb\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0malpha\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlabda\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdelta\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     14\u001B[0m         \u001B[1;31m#viz.line([0.0],[0],win = 'U_i_'+str(i),opts= dict(title='U_i[t]'))\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     15\u001B[0m         \u001B[1;31m#viz.line([np.float(U_i[t])],[t],win = 'U_i_'+str(i), update='append')\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-318-06cfc14ce579>\u001B[0m in \u001B[0;36mf_Equi\u001B[1;34m(t, v, d, b, alpha, labda, delta)\u001B[0m\n\u001B[0;32m     19\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     20\u001B[0m         \u001B[0mfunc_2\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m(\u001B[0m\u001B[1;33m-\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mC\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mt\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mb\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0malpha\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0malpha\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mOMEGA\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mu\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdelta\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mC\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mt\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mb\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mb\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0malpha\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0malpha\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mOMEGA\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mu\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdelta\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m-\u001B[0m\u001B[0mtmp\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0malpha\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 21\u001B[1;33m         \u001B[0mroot\u001B[0m \u001B[1;33m=\u001B[0m  \u001B[0msympy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnsolve\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfunc_2\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0msolver\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'bisect'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mverify\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     22\u001B[0m         \u001B[1;31m#print(f\"t:{t} -- u:{root}\")\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda\\envs\\pythorch\\lib\\site-packages\\sympy\\utilities\\decorator.py\u001B[0m in \u001B[0;36mfunc_wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     86\u001B[0m         \u001B[0mdps\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmpmath\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdps\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     87\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 88\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     89\u001B[0m         \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     90\u001B[0m             \u001B[0mmpmath\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdps\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdps\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda\\envs\\pythorch\\lib\\site-packages\\sympy\\solvers\\solvers.py\u001B[0m in \u001B[0;36mnsolve\u001B[1;34m(dict, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2924\u001B[0m         \u001B[0msyms\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfree_symbols\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2925\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mfargs\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2926\u001B[1;33m             \u001B[0mfargs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0msyms\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcopy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpop\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2927\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msyms\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m1\u001B[0m \u001B[1;32mand\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mfargs\u001B[0m \u001B[1;32min\u001B[0m \u001B[0msyms\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mfargs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32min\u001B[0m \u001B[0msyms\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2928\u001B[0m             raise ValueError(filldedent('''\n",
      "\u001B[1;31mKeyError\u001B[0m: 'pop from an empty set'"
     ]
    }
   ],
   "source": [
    "# Perform SA respectively for all settings\n",
    "# for i in range(0,N_uniq_auction):\n",
    "for i in range(5,8):\n",
    "    start_time = datetime.datetime.now()\n",
    "\n",
    "    # get i_th data_key\n",
    "    key_i = get_key_from_index(i)\n",
    "    # extract data with same `key_i` into a table\n",
    "    data_i = select_data_fromkey(key_i)\n",
    "    data_i.reset_index(drop=True,inplace=True)\n",
    "\n",
    "    T_i = data_i['N'].astype(int)          # auction duration sequence\n",
    "    max_T = int(max(T_i))                  # max duration value\n",
    "\n",
    "    cnt_n_2_i = data_i['cnt_n_2'].astype(int)       # Number of occurrences of different durations\n",
    "    # for a certain auction(like 'data_i'), 'cnt_uniq' should be all the same\n",
    "    A_i = int(data_i['cnt_uniq'].unique())\n",
    "    assert(A_i == sum(cnt_n_2_i),\"'cnt_uniq' does not match with sum of 'cnt_n_2'!\")\n",
    "\n",
    "    v = float(data_i['retail'].unique())\n",
    "    d = float(data_i['bidincrement'].unique())\n",
    "    b = float(data_i['bidfee'].unique())\n",
    "\n",
    "    # calculate NLL\n",
    "    print(f\"> For the *{i}_th* data_key, the max_T is: *{max_T}*\")\n",
    "    print(\"> retail = {0},bidincrement = {1}, bidfee = {2}, infer PT's parameters\".format(v,d,b))\n",
    "    print(\"> Initilizing SA....... \\n\")\n",
    "    # L=50, max_stay_counter=50\n",
    "    set_run_mode(loss_func, 'cached')\n",
    "    set_run_mode(loss_func, 'multithreading')\n",
    "    # T_max = round(v)或者 T_max = (v-d)/b\n",
    "    sa_boltzmann = SABoltzmann(func=loss_func, x0=table_5_M, other_params = [max_T,v,d,b],T_max=round((v-d)/b), T_min=1, learn_rate=0.3, L=20, max_stay_counter=10,\n",
    "                            lb=lb, ub=ub)\n",
    "\n",
    "    print(\"> Now do SA....... \\n\")\n",
    "    best_x, best_y = sa_boltzmann.run()\n",
    "    print('> The whole inference process costs {time_costs}s \\n'.format(time_costs=(datetime.datetime.now() - start_time).total_seconds()))\n",
    "\n",
    "    print(\"> SA ENDS....... \\n\")\n",
    "\n",
    "    # draw the pic of NLL Loss in SA process\n",
    "    viz.line([0.0]*(sa_boltzmann.iter_cycle+1),[0]*(sa_boltzmann.iter_cycle+1),win = 'Loss of '+str(i),opts= dict(title='Loss of '+str(i)))\n",
    "    viz.line(np.array(sa_boltzmann.generation_best_Y),np.arange(0,sa_boltzmann.iter_cycle+1),win = 'Loss of '+str(i), update='append')\n",
    "\n",
    "    # dicard plt drawing since visdom is better\n",
    "    # plt.title(\"The loss(NLL) in SA\".format(i,N_uniq_auction))\n",
    "    # plt.xlabel(\"iter_cycle\")\n",
    "    # plt.ylabel(\"Loss history of SA\")\n",
    "    # sns.lineplot(x = np.arange(0,sa_boltzmann.iter_cycle+1),y=np.array(sa_boltzmann.generation_best_Y))\n",
    "\n",
    "    # append the opitimized params into the df\n",
    "    df_tmp = pd.DataFrame([[i,best_x[0],best_x[1],best_x[2],sa_boltzmann.generation_best_Y[0],best_y,best_y/A_i]],columns=['key_idx','alpha','delta','labda','initial_loss','final_loss','avg_loss'])\n",
    "    params_opitim = params_opitim.append(df_tmp,ignore_index=True)  # ignore_index=True could help in rearranging index\n",
    "\n",
    "# save inference results\n",
    "params_opitim.to_csv(params_opitim_path, header=True, encoding=\"utf-8\",index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4 P\n",
    "1. 得到`params_opitim`之后，可以对不同的auction settings做generate了\n",
    "2. generate过程无非是求u-->p，u的代码在上面loss func里写过了。然后把P存到dict里"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# solve for U&P respectively for all settings\n",
    "P = {}\n",
    "for i in range(0,N_uniq_auction):\n",
    "\n",
    "    # get optimized params\n",
    "    alpha, labda, delta = params_opitim.iloc[i][0],params_opitim.iloc[i][1],params_opitim.iloc[i][2]\n",
    "\n",
    "    # get i_th data_key\n",
    "    key_i = get_key_from_index(i)\n",
    "    # extract data with same `key_i` into a table\n",
    "    data_i = select_data_fromkey(key_i)\n",
    "    data_i.reset_index(drop=True,inplace=True)\n",
    "\n",
    "    T_i = data_i['N'].astype(int)          # auction duration sequence\n",
    "    max_T = int(max(T_i))                  # max duration value\n",
    "\n",
    "    cnt_n_2_i = data_i['cnt_n_2'].astype(int)       # Number of occurrences of different durations\n",
    "\n",
    "    v = float(data_i['retail'].unique())\n",
    "    d = float(data_i['bidincrement'].unique())\n",
    "    b = float(data_i['bidfee'].unique())\n",
    "\n",
    "    U_i = [0] * (max_T + 1)\n",
    "    U_i[0] = 1\n",
    "    key_i_str = get_key_from_index\n",
    "    P[key_i_str] = np.array([0.0]*(max_T+1))\n",
    "    P_tmp = [0.0]*(max_T+1)   # P is what we want to generate\n",
    "    P_tmp[0] = 1\n",
    "    tmp2 = 1\n",
    "\n",
    "    # solve for U\n",
    "    for t in range(1,max_T+1):\n",
    "        U_i[t] = f_Equi(t, v, d, b, alpha, labda, delta)\n",
    "        P_tmp[t] = (1- U_i[t])*tmp2\n",
    "        tmp2 = tmp2*U_i[t]\n",
    "    # solve for P\n",
    "    # for j in range()\n",
    "    # # P[key_i][j] = 1.0-b[i]/(v[i]-s[i]*(j-1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}