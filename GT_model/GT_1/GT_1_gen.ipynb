{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 0. Intro\n",
    "1. 试图整合fixed和ascending两种拍卖\n",
    "2. 直接输出LEN=300的data\n",
    "\n",
    "# 1. Global settings\n",
    "## 1.1 data path"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "# Small dataset\n",
    "# data_np_path = r'../../data/small_auctions_np.csv'\n",
    "# settings_NN_path = r\"../../data/small_settings_NN.csv\"\n",
    "\n",
    "# Large data\n",
    "data_np_path = r'E:\\DATA\\large_dta\\large_auctions_np.csv'                 #\n",
    "settings_NN_path = r'E:\\DATA\\large_dta\\large_settings_NN.csv'\n",
    "\n",
    "# output path\n",
    "data_path_root = \"../../data/info_asymm/results/\"\n",
    "# target data is from method-2\n",
    "filename_head = \"GT_1_large_LEN=\"\n",
    "filename_tail = \".csv\"\n",
    "\n",
    "# 衡量一场auction是否unique的标志\n",
    "unique_setting_GT = ['bidincrement','bidfee','retail','flg_fixedprice']\n",
    "unique_setting_NN = ['desc','bidincrement','bidfee','retail','flg_fixedprice']\n",
    "\n",
    "# threshold\n",
    "LEN=300\n",
    "\n",
    "import numpy as np\n",
    "#import cupy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from visdom import Visdom"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2 read"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For GT-1, there are *80* settings waiting to be inferred.\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(data_np_path, encoding=\"utf-8\")\n",
    "data_key = pd.read_csv(settings_NN_path, encoding=\"utf-8\")\n",
    "\n",
    "print(\"For GT-1, there are *{}* settings waiting to be inferred.\".format(data_key.shape[0]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. U&P\n",
    "1. There is $n \\leq T_i $\n",
    "2. `U[i][0]`初始化为1，方便后续`P`的计算\n",
    "3. `U[i][j]`表示在setting i下：\n",
    "> The probability that somebody makes the jth bid (given that j − 1 previous bids have been made)\n",
    "4. `P`作为一个**dict**，它的key是`features_GT`,每一个key对应一个大小为(T+1)的list.\n",
    "5. 由于threshold的存在，`P[key_i]`的大小设置为`K+1`，其中`p[key_i][K]`记录的是sum(P[i]) when i > K\n",
    "    - 如果threshold> T_i，则用0去padding"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, ...]\nIndex: []\n\n[0 rows x 300 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>290</th>\n      <th>291</th>\n      <th>292</th>\n      <th>293</th>\n      <th>294</th>\n      <th>295</th>\n      <th>296</th>\n      <th>297</th>\n      <th>298</th>\n      <th>299</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n<p>0 rows × 300 columns</p>\n</div>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# col_names = ['bidincrement','bidfee','retail']\n",
    "col_names = []\n",
    "tmp = np.arange(0,LEN)\n",
    "tmp_str = [str(x) for x in tmp]\n",
    "col_names.extend(tmp_str)\n",
    "\n",
    "P_df = pd.DataFrame(columns=col_names)\n",
    "\n",
    "P_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/80 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c984043575b14b20a6437dd9eeec2c5a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# for every uniq setting i\n",
    "for i in tqdm(range(0,data_key.shape[0])):\n",
    "\n",
    "    # Get params\n",
    "    v = float(data_key.loc[i,'retail'].item())            # retail price = valuation\n",
    "    d = float(data_key.loc[i,'bidincrement'].item())      # bid increment\n",
    "    b = float(data_key.loc[i,'bidfee'].item())            # bid fee\n",
    "\n",
    "    # d==0 suggests a fixed-price auction\n",
    "    if d == 0:\n",
    "        T_i = np.inf                                    # duration limitation\n",
    "    else:\n",
    "        T_i = np.floor((v-b)/d)                         # duration limitation\n",
    "\n",
    "    # Solve for U with length of LEN\n",
    "    U = [0] * (LEN + 2)                                 # the prob. that someone offers a bid in t_th round\n",
    "    U[0],U[1] = 1,1                                     # 实际上u[0]用不到,u[1]=1保证auction至少1轮\n",
    "    for t in range(2,len(U)):\n",
    "        if(t<T_i):  # 如果不超过理论上限T_i，可计算\n",
    "            U[t] = 1.0-(b/(v-d*(t-1)))\n",
    "        else:       # 超过理论上限T_i，不可计算，置为0\n",
    "            U[t] = 0.0\n",
    "        assert U[t]>=0, \"U[t]<0 when t ={},and b = {},v = {}, d = {}\".format(t,b,v,d)\n",
    "\n",
    "    # Solve for P with length of LEN\n",
    "    P = np.array([0.0]*(LEN+1))\n",
    "    P[0] = 0.0                                            # auction duration==0的概率=0\n",
    "    tmp = np.array([0.0]*(LEN+3))                         # tmp的大小不需要太精确\n",
    "    tmp[0] = 1.0\n",
    "\n",
    "    # 注意：P[i][t] = U[i][1]*U[i][2]*...*(1-U[i][t+1])\n",
    "    for t in range(1,len(P)):\n",
    "        tmp[t] = tmp[t-1]*U[t]                          # tmp[t]存了U从1到(t)的连乘积\n",
    "        P[t] = (1-U[t+1])*tmp[t]\n",
    "\n",
    "    # Dele the P[0]\n",
    "    P = np.delete(P,[0],axis=0)\n",
    "    assert len(P)==LEN,\"P has wrong length (should be LEN)\"\n",
    "\n",
    "    # if np.floor((v-b)/d) > LEN:                     # 理论upper bound比较高，存在截断的情况，做归一化？\n",
    "    #     scale_sum = np.sum(P)\n",
    "    #     P = P/scale_sum\n",
    "\n",
    "    # Concat with dataframe\n",
    "    # pd_tmp = pd.DataFrame(data=[[d,b,v]])\n",
    "    # pd_tmp = pd.concat([pd_tmp,pd.DataFrame(P).T],axis=1)\n",
    "    pd_tmp = pd.DataFrame(P).T\n",
    "    pd_tmp.columns = col_names\n",
    "    P_df = pd.concat([P_df,pd_tmp],ignore_index=True)\n",
    "\n",
    "    # draw\n",
    "    #\n",
    "    # if(plot_flag& (i%10 == 0)):\n",
    "    #     viz.line(p,np.arange(0,p.shape[0]),win = 'P_'+str(i),env=env_str, opts= dict(title = f'P_{i}_v={v}_b={b}_d={d}'))\n",
    "\n",
    "print(\"Done\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. save"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/info_asymm/results/GT_1_large_LEN=300.csv\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "filename_P = data_path_root + filename_head + str(LEN) + filename_tail\n",
    "P_df.to_csv(filename_P,header=True,index=False,encoding=\"utf-8\")\n",
    "print(filename_P)\n",
    "print(\"DONE\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
