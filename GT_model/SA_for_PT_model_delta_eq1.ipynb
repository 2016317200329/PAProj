{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 222,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2022/10/09 16:19\n",
    "# @Author  : Wang Yujia\n",
    "# @File    : SA_for_PT_model.ipynb\n",
    "# @Description : Parameter estimation for PT_model using Simulated Annealing and Delta==1"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 0. What for\n",
    "\n",
    "# 1. Preparations\n",
    "1. infer参数一是需要data，二是需要把p表示出来才能写出来loss func\n",
    "2. data来自`data_selected_path`\n",
    "\n",
    "## 1.1 全局设置\n",
    "1. 除了表示uniq auction的features，还引入了\n",
    "    - 'cnt_uniq':表示paper里的Loss function公式里的A"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    }
   ],
   "source": [
    "# data path\n",
    "data_selected_path = \"../data/info_asymm/datawithnp_asc_symmetry_2_selected.csv\"\n",
    "# data_key path\n",
    "data_key_path = \"../data/SA_PT/data_key.csv\"\n",
    "# optimized parameters' saving path:\n",
    "params_opitim_path = \"../data/SA_PT/params_opitim.csv\"\n",
    "\n",
    "# features that GT need\n",
    "features_GT = ['product_id','bidincrement','bidfee','retail']\n",
    "features_GT_infer = ['cnt_uniq']\n",
    "\n",
    "# for SA\n",
    "# initial params\n",
    "table_5_M = [0.025,3.72]\n",
    "# lower/ upper bound\n",
    "lb = [-0.3,0.01]\n",
    "ub = [0.3,18]\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "#from sko.SA import SABoltzmann\n",
    "from SA_modified import SABoltzmann\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from sko.tools import set_run_mode\n",
    "from visdom import Visdom\n",
    "\n",
    "viz = Visdom()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2 data 读取\n",
    "1. 读取data以做SA\n",
    "2. 提取出来`data_key`，以及其他计算需要的features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For PT model, there are *1303* settings waiting to be inferred.\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(data_selected_path, encoding=\"utf-8\")\n",
    "data_key = data[features_GT].copy()\n",
    "data_key.drop_duplicates(inplace=True)\n",
    "data_key.to_csv(data_key_path,header=True, encoding=\"utf-8\",index=False)\n",
    "\n",
    "B = np.array(data.bidfee)               # bid fee (cent to dollar)\n",
    "D = np.array(data.bidincrement)         # bid increment (cent to dollar)\n",
    "V = np.array(data.retail)               # valuation\n",
    "# 需要计算`N_uniq_auction`组setting下的结果\n",
    "N_uniq_auction= data_key.shape[0]\n",
    "\n",
    "print(\"For PT model, there are *{}* settings waiting to be inferred.\".format(N_uniq_auction))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.3 functions about 'key'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "outputs": [],
   "source": [
    "# get key from i in 'data_key'\n",
    "def get_key_from_index(i,str=\"NotStr\"):\n",
    "    if(str==\"str\"):\n",
    "        key_i = list(data_key.iloc[i,:])\n",
    "        key_i_str = (str(key_i[0]),str(key_i[1]),str(key_i[2]))\n",
    "        return key_i_str\n",
    "    else:\n",
    "        key_i = data_key.iloc[i,:]\n",
    "        return key_i\n",
    "\n",
    "#features_GT = ['product_id','bidincrement','bidfee','retail']\n",
    "def select_data_fromkey(key_i_str):\n",
    "    return data[(data['product_id'] == key_i_str[0]) & (data['bidincrement'] == key_i_str[1]) & (data['bidfee'] == key_i_str[2]) & (data['retail'] == key_i_str[3])].copy()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. PT model\n",
    "## 2.1 prob. weighting func\n",
    "1. 根据Eq(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "outputs": [],
   "source": [
    "def OMEGA(p):\n",
    "    return p"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2 C_{t-1}\n",
    "1. 根据5.1.2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "outputs": [],
   "source": [
    "def C(t,b):\n",
    "    return 0.2*t*b"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.3 the valuation function\n",
    "1. 根据Eq(7)-(9)\n",
    "2. 注意这里把(-labda)(1-sympy.E**(alpha*x))/alpha的`labda`拿到外面去了，方便写"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "outputs": [],
   "source": [
    "def f(x, alpha):\n",
    "    # return (1-x**alpha)\n",
    "    # return (1-sympy.E**(-alpha*x))\n",
    "    return (1-np.exp(-alpha*x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.4 Equi. condition\n",
    "1. 根据Eq(6)\n",
    "2. 注意分辨怎么代入上面的公式\n",
    "3. `delta = 1`时，公式可以大大化简，见ipad上的公式"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "outputs": [],
   "source": [
    "# for scipy use\n",
    "def func_1(u,*args):\n",
    "    alpha,delta,labda,t,b,tmp = args\n",
    "    return (labda * f(x=C(t-1, b), alpha=alpha) - labda * OMEGA(u) * f(x=(C(t-1, b) + b), alpha=alpha) + OMEGA(1-u) * f(tmp, alpha))\n",
    "\n",
    "# for scipy use\n",
    "def func_2(u,*args):\n",
    "    alpha,delta,labda,t,b,tmp = args\n",
    "    return (-f(x=C(t-1, b), alpha=alpha) + OMEGA(u) * f(x=(C(t-1, b) + b), alpha=alpha) + (1 - OMEGA(u)) * f(-tmp, alpha))\n",
    "\n",
    "def f_Equi(t,v,d,b,alpha,labda):\n",
    "\n",
    "    tmp = v-d*t-C(t-1,b) - b\n",
    "\n",
    "    if (tmp>=0):\n",
    "    # simplify the equation and get the root directly:\n",
    "    #     root = 1 + labda * np.exp(-alpha*C(t-1,b)) * (np.exp(-alpha*b) - 1) /\\\n",
    "    #            ( labda * (1 - np.exp(-alpha * (C(t-1,b)+b)) )  + (1 - np.exp(-alpha*tmp)) )\n",
    "        root = (labda*f(C(t-1,b),alpha) + f(tmp,alpha)) / (labda*f(C(t-1,b)+b,alpha) + f(tmp,alpha))\n",
    "        # if(np.isclose(root,0.0)):\n",
    "        #     print(f\"t:{t} ---- u == 0.0:{root} ---- alpha : {alpha}\")\n",
    "    else:\n",
    "        root = (f(C(t-1,b),alpha) - f(-tmp,alpha)) / (f(C(t-1,b)+b,alpha) + f(-tmp,alpha))\n",
    "        # if(np.isclose(root,0.0)):\n",
    "        #     print(f\"t:{t} -- u == 0.0:{root} -- alpha : {alpha}\")\n",
    "\n",
    "    # if(root > 1.0):\n",
    "    #     print(f\"t:{t} ---- u > 1.0:{root} ---- alpha: {alpha}\")\n",
    "\n",
    "    #viz.line([[0.0,0.0]],[0],win = 'root compare',opts= dict(title='root in 2 methods'+str(t),legend=['simplify', 'sympy']))\n",
    "    #viz.line([[np.float(root1),np.float(root)]],[t],win = 'root compare', update='append')\n",
    "\n",
    "    return root"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. SA\n",
    "## 3.1 define loss function\n",
    "1. loss function: NLL for auctions with same `features_GT`\n",
    "2."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "outputs": [],
   "source": [
    "def loss_func(params,other_params):\n",
    "    # start_time_loss = datetime.datetime.now()\n",
    "    alpha = params[0]\n",
    "    # delta = 1\n",
    "    labda = params[1]\n",
    "    max_T,v,d,b = other_params\n",
    "\n",
    "    # solve for U from Equi. condt.\n",
    "    U_i = [0] * (max_T + 1)\n",
    "    U_i[0] = 1\n",
    "    tag_u_gt_1 = 0\n",
    "\n",
    "    for t in range(1,max_T+1):\n",
    "\n",
    "        U_i[t] = f_Equi(t, v, d, b, alpha, labda)\n",
    "        if((U_i[t] > 1.0) & (tag_u_gt_1 == 0)):\n",
    "            tag_u_gt_1 = t\n",
    "            print(f\"from t={t}, u>1\")\n",
    "        elif((U_i[t] > 1.0) & (tag_u_gt_1 == t-1)):\n",
    "            tag_u_gt_1 = t\n",
    "        elif((U_i[t] > 1.0) & (tag_u_gt_1 != t-1)):\n",
    "            print(\"-----------u>1 for twice---------\")\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    # calculate NLL under this auction setting & PT params\n",
    "    nll = 0.0\n",
    "    if(U_i[0]==1):\n",
    "        U_i.pop(0)\n",
    "    U_tmp_df = pd.DataFrame(U_i, index=np.arange(0, U_i.__len__()), columns=['U'], dtype=float)\n",
    "    for idx in range(0,data_i.shape[0]):\n",
    "        # sum up the log prob among all durations of this auction\n",
    "        nll += ( np.sum(U_tmp_df[0:(T_i[idx]-1)][:].apply(np.log,axis=1)) + np.log(1-U_tmp_df.iat[(T_i[idx]-1),0]) )* cnt_n_2_i[idx]\n",
    "    # print('> The loss costs {time_costs}s \\n'.format(time_costs=(datetime.datetime.now() - start_time_loss).total_seconds()))\n",
    "\n",
    "    return float(-nll)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.2 do SA\n",
    "1. 要对每一个setting做一次infer == 对每一个setting执行一次SA。\n",
    "    - 可以并行吗？YES\n",
    "2. 具体的：对每个setting `i`\n",
    "    - 每一个setting `i` 可以提取出来一个`data_i`，代表所有auction\n",
    "    - 每一个`data_i`中的`cnt_uniq`，也就是`A`，是相同的，表示setting `i` 进行的拍卖总次数.【但是这个`A`在计算loss的时候派不上用场】\n",
    "    - `N`表示duration，因此paper公式里的$T_a$即`N[a]`\n",
    "    - 因此有`A = sum(data_i['cnt_n_2'])`，其中的'cnt_n_2'表示了该行对应的`duration=N`发生的次数\n",
    "    - 按照上文，求解`U[i]_t` which is a array with shape of (max(N)),也就是求解paper里的`p_t`\n",
    "3.每次进行`L`次对参数的试探寻找，每次寻找对应一个温度一组新的参数。\n",
    "    - 优化的完成/退出条件：温度小于`T_min`或者最低温度保持`max_stay_counter`次的不变\n",
    "    - 鉴于温度小于`T_min`很难达到，因此基本上对一组参数进行优化要进行L*max_stay_counter+1次运算（loss运算）"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "outputs": [],
   "source": [
    "params_opitim = pd.DataFrame(columns=['key_idx','alpha','delta','labda','initial_loss','final_loss','avg_loss'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:18: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "<>:18: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "<>:18: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "<ipython-input-233-f3fac6e199c8>:18: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(A_i == sum(cnt_n_2_i),\"'cnt_uniq' does not match with sum of 'cnt_n_2'!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> For the *20_th* data_key, the max_T is: *1141*\n",
      "> retail = 129.99,bidincrement = 0.15, bidfee = 0.75, infer PT's parameters\n",
      "> Initilizing SA....... \n",
      "\n",
      "> Now do SA....... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform SA respectively for all settings\n",
    "# for i in range(0,N_uniq_auction):\n",
    "for i in range(20,50):\n",
    "    start_time = datetime.datetime.now()\n",
    "\n",
    "    # get i_th data_key\n",
    "    key_i = get_key_from_index(i)\n",
    "    # extract data with same `key_i` into a table\n",
    "    data_i = select_data_fromkey(key_i)\n",
    "    data_i.reset_index(drop=True,inplace=True)\n",
    "\n",
    "    T_i = data_i['N'].astype(int)          # auction duration sequence\n",
    "    max_T = int(max(T_i))                  # max duration value\n",
    "\n",
    "    cnt_n_2_i = data_i['cnt_n_2'].astype(int)       # Number of occurrences of different durations\n",
    "    # for a certain auction(like 'data_i'), 'cnt_uniq' should be all the same\n",
    "    A_i = int(data_i['cnt_uniq'].unique())\n",
    "    assert(A_i == sum(cnt_n_2_i),\"'cnt_uniq' does not match with sum of 'cnt_n_2'!\")\n",
    "\n",
    "    v = float(data_i['retail'].unique())\n",
    "    d = float(data_i['bidincrement'].unique())\n",
    "    b = float(data_i['bidfee'].unique())\n",
    "\n",
    "    # calculate NLL\n",
    "    print(f\"> For the *{i}_th* data_key, the max_T is: *{max_T}*\")\n",
    "    print(\"> retail = {0},bidincrement = {1}, bidfee = {2}, infer PT's parameters\".format(v,d,b))\n",
    "    print(\"> Initilizing SA....... \\n\")\n",
    "    # L=50, max_stay_counter=50\n",
    "    set_run_mode(loss_func, 'cached')\n",
    "    set_run_mode(loss_func, 'multithreading')\n",
    "    sa_boltzmann = SABoltzmann(func=loss_func, x0=table_5_M, other_params = [max_T,v,d,b],T_max=round((v-d)/b), T_min=1, learn_rate=0.3, L=40, max_stay_counter=15,\n",
    "                            lb=lb, ub=ub)\n",
    "\n",
    "    print(\"> Now do SA....... \\n\")\n",
    "    best_x, best_y = sa_boltzmann.run()\n",
    "    print('> The whole inference process costs {time_costs}s \\n'.format(time_costs=(datetime.datetime.now() - start_time).total_seconds()))\n",
    "\n",
    "    print(\"> SA ENDS....... \\n\")\n",
    "\n",
    "    # # draw the pic of NLL Loss in SA\n",
    "    # plt.title(\"The loss(NLL) in SA\".format(i,N_uniq_auction))\n",
    "    # plt.xlabel(\"iter_cycle\")\n",
    "    # plt.ylabel(\"Loss history of SA\")\n",
    "    # sns.lineplot(x = np.arange(0,sa_boltzmann.iter_cycle+1),y=np.array(sa_boltzmann.generation_best_Y))\n",
    "    # draw the pic of NLL Loss in SA process\n",
    "    viz.line([0.0]*(sa_boltzmann.iter_cycle+1),[0]*(sa_boltzmann.iter_cycle+1),win = 'Loss of '+str(i),opts= dict(title='Loss of '+str(i)))\n",
    "    viz.line(np.array(sa_boltzmann.generation_best_Y),np.arange(0,sa_boltzmann.iter_cycle+1),win = 'Loss of '+str(i), update='append')\n",
    "\n",
    "    # append the opitimized params into the df\n",
    "    df_tmp = pd.DataFrame([[i,best_x[0],1,best_x[1],sa_boltzmann.generation_best_Y[0],best_y,best_y/A_i]],columns=['key_idx','alpha','delta','labda','initial_loss','final_loss','avg_loss'])\n",
    "    params_opitim = params_opitim.append(df_tmp,ignore_index=True)  # ignore_index=True could help in rearranging index"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# save 'params_opitim' for later check\n",
    "params_opitim.to_csv(params_opitim_path, header=True, encoding=\"utf-8\",index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4 P\n",
    "1. 得到`params_opitim`之后，可以对不同的auction settings做generate了\n",
    "2. generate过程无非是求u-->p，u的代码在上面loss func里写过了。然后把P存到dict里"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# solve for U&P respectively for all settings\n",
    "P = {}\n",
    "for i in range(0,N_uniq_auction):\n",
    "\n",
    "    # get optimized params\n",
    "    alpha, labda, delta = params_opitim.iloc[i][0],params_opitim.iloc[i][1],params_opitim.iloc[i][2]\n",
    "\n",
    "    # get i_th data_key\n",
    "    key_i = get_key_from_index(i)\n",
    "    # extract data with same `key_i` into a table\n",
    "    data_i = select_data_fromkey(key_i)\n",
    "    data_i.reset_index(drop=True,inplace=True)\n",
    "\n",
    "    T_i = data_i['N'].astype(int)          # auction duration sequence\n",
    "    max_T = int(max(T_i))                  # max duration value\n",
    "\n",
    "    cnt_n_2_i = data_i['cnt_n_2'].astype(int)       # Number of occurrences of different durations\n",
    "\n",
    "    v = float(data_i['retail'].unique())\n",
    "    d = float(data_i['bidincrement'].unique())\n",
    "    b = float(data_i['bidfee'].unique())\n",
    "\n",
    "    U_i = [0] * (max_T + 1)\n",
    "    U_i[0] = 1\n",
    "    key_i_str = get_key_from_index\n",
    "    P[key_i_str] = np.array([0.0]*(max_T+1))\n",
    "    P_tmp = [0.0]*(max_T+1)   # P is what we want to generate\n",
    "    P_tmp[0] = 1\n",
    "    tmp2 = 1\n",
    "\n",
    "    # solve for U\n",
    "    for t in range(1,max_T+1):\n",
    "        U_i[t] = f_Equi(t, v, d, b, alpha, labda)\n",
    "        P_tmp[t] = (1- U_i[t])*tmp2\n",
    "        tmp2 = tmp2*U_i[t]\n",
    "    # solve for P\n",
    "    # for j in range()\n",
    "    # # P[key_i][j] = 1.0-b[i]/(v[i]-s[i]*(j-1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2]\n",
      "[0.25375862 2.82002336]\n",
      "[0.25375862 5.64004671]\n"
     ]
    }
   ],
   "source": [
    "n_dim = 2\n",
    "xc = np.random.normal([0.0,0.0], [0.1,2.0], size=(n_dim))\n",
    "std = np.array([1,2])\n",
    "print(std)\n",
    "print(xc)\n",
    "print(xc*std)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}