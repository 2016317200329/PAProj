{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ [ \"KMP_DUPLICATE_LIB_OK\" ]= \"TRUE\"\n",
    "\n",
    "%load_ext autoreload\n",
    "%matplotlib notebook\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2022/11/12 09:54\n",
    "# @Author  : Wang Yujia\n",
    "# @File    : SA_for_PT_one_for_all.ipynb\n",
    "# @Description : for all settings and data, just infer one params"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 0. What for\n",
    "1. 给所有的data和setting，只infer一组params\n",
    "\n",
    "# 1. Preparations\n",
    "## 1.1 全局设置"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# 人工数据集or真实数据集\n",
    "ARTIFICIAL = True\n",
    "# seed = [3,31,204,223,407,62,508,626]\n",
    "# [4,31,204,35,407,66,508,512]\n",
    "\n",
    "seed = 512\n",
    "noise_pct = 0.05\n",
    "\n",
    "SET_VAL = False\n",
    "train_pct = 0.7\n",
    "vali_pct = 0.2\n",
    "test_pct = 0.1\n",
    "\n",
    "\n",
    "# Small dataset\n",
    "data_small_np_path = r'../../data/small_auctions_np.csv'\n",
    "settings_small_NN_path = r\"../../data/small_settings_NN.csv\"\n",
    "\n",
    "# Large data\n",
    "data_large_np_path = r'E:\\DATA\\large_dta\\large_auctions_np.csv'\n",
    "settings_large_NN_path = r'E:\\DATA\\large_dta\\large_settings_NN.csv'\n",
    "\n",
    "# data\n",
    "if ARTIFICIAL:\n",
    "    target_root_path = \"../../data/artificial_targets_v2_noise=\" +str(noise_pct)\n",
    "else:\n",
    "    target_root_path = \"../../data/targets_all\"\n",
    "\n",
    "# params_opitim_path = r\"../../data/params_and_K_sampled.csv\"\n",
    "\n",
    "unique_setting_NN = ['desc','bidincrement','bidfee','retail','flg_endprice']\n",
    "LEN = 300\n",
    "\n",
    "# output path\n",
    "if ARTIFICIAL:\n",
    "    params_opitim_unified_path = r\"../../data/SA_PT/params_artificial_unified_noise=\"+str(noise_pct)+ \"_seed=\"+str(seed)+\".csv\"\n",
    "else:\n",
    "    params_opitim_unified_path = \"../../data/SA_PT/params_opitim_unified_seed=\"+str(seed)+\".csv\"\n",
    "\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "from visdom import Visdom\n",
    "from SA_for_PT_funcs_delta_eq1 import *\n",
    "from SA_modified import SABoltzmann\n",
    "from sko.tools import set_run_mode\n",
    "from func_timeout import func_set_timeout\n",
    "import func_timeout\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from MLP.utils import setup_seed\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# for SA\n",
    "# initial params\n",
    "table_5_M = [0.025,3.72]\n",
    "# lower/ upper bound\n",
    "lb = [-0.3,0.01]\n",
    "ub = [0.3,18]\n",
    "# viz = Visdom(env='P',use_incoming_socket=False)\n",
    "max_trial = 3       # 算法执行次数，会产生max_trial个估计值\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2 data 读取\n",
    "1. 注意把small和large拼接成一张data table\n",
    "2. 由于columns不同，合并后data中肯定有nan，不过我们需要的columns不是nan就好"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For PT model, there are *1276* settings waiting to be inferred.\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                            desc  bidincrement  bidfee  \\\n0  Sony Ericsson S500i Unlocked Mysterious Green          0.15    0.75   \n1               PSP Slim & Lite Sony Piano Black          0.15    0.75   \n2     iPod Touch Apple 8GB with Software Upgrade          0.15    0.75   \n3      Logitech Cordless Wave Keyboard and Mouse          0.15    0.75   \n4                     SanDisk Cruzer Contour 4GB          0.15    0.75   \n\n   retail  flg_endprice  \n0  499.99             0  \n1  169.99             0  \n2  299.99             0  \n3   89.99             0  \n4   59.99             0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>desc</th>\n      <th>bidincrement</th>\n      <th>bidfee</th>\n      <th>retail</th>\n      <th>flg_endprice</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Sony Ericsson S500i Unlocked Mysterious Green</td>\n      <td>0.15</td>\n      <td>0.75</td>\n      <td>499.99</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>PSP Slim &amp; Lite Sony Piano Black</td>\n      <td>0.15</td>\n      <td>0.75</td>\n      <td>169.99</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>iPod Touch Apple 8GB with Software Upgrade</td>\n      <td>0.15</td>\n      <td>0.75</td>\n      <td>299.99</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Logitech Cordless Wave Keyboard and Mouse</td>\n      <td>0.15</td>\n      <td>0.75</td>\n      <td>89.99</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>SanDisk Cruzer Contour 4GB</td>\n      <td>0.15</td>\n      <td>0.75</td>\n      <td>59.99</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_small = pd.read_csv(data_small_np_path, encoding=\"utf-8\")\n",
    "data_large = pd.read_csv(data_large_np_path, encoding=\"utf-8\")\n",
    "data = pd.concat([data_small,data_large],axis=0,ignore_index=True)\n",
    "# 由于columns不同，合并后data中肯定有nan，不过我们需要的columns不是nan就好\n",
    "\n",
    "data_key_small = pd.read_csv(settings_small_NN_path, encoding=\"utf-8\")\n",
    "data_key_large = pd.read_csv(settings_large_NN_path, encoding=\"utf-8\")\n",
    "data_key = pd.concat([data_key_small,data_key_large],axis=0,ignore_index=True)\n",
    "\n",
    "# 有`N_uniq_auction`组setting\n",
    "N_uniq_auction= data_key.shape[0]\n",
    "print(\"For PT model, there are *{}* settings waiting to be inferred.\".format(N_uniq_auction))\n",
    "data_key.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.3 functions about 'key'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "all_target_file = os.listdir(target_root_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def select_data_fromkey(i):\n",
    "    return data[(data['desc'] == data_key.iloc[i,0]) &\n",
    "                (data['bidincrement'] == data_key.iloc[i,1]) &\n",
    "                (data['bidfee'] == data_key.iloc[i,2]) &\n",
    "                (data['retail'] == data_key.iloc[i,3]) &\n",
    "                (data['flg_endprice'] == data_key.iloc[i,4])].copy()\n",
    "\n",
    "def readin_data_fromkey(i):\n",
    "    data_i_path = os.path.join(target_root_path,all_target_file[i])\n",
    "    data_i = pd.read_csv(data_i_path,encoding=\"utf-8\")\n",
    "    return data_i"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.4 seed\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "setup_seed(seed)\n",
    "\n",
    "DATA_len = len(target_root_path)\n",
    "\n",
    "shuffled_indices = np.random.permutation(DATA_len)\n",
    "\n",
    "train_idx = shuffled_indices[:int(train_pct * DATA_len)]\n",
    "if SET_VAL:\n",
    "    tmp = int((train_pct + vali_pct) * DATA_len)\n",
    "    val_idx = shuffled_indices[int(train_pct * DATA_len):tmp]\n",
    "    test_idx = shuffled_indices[tmp:]\n",
    "else :\n",
    "    tmp = int((train_pct + vali_pct) * DATA_len)\n",
    "    test_idx = shuffled_indices[int(train_pct * DATA_len):tmp]\n",
    "    val_idx = shuffled_indices[tmp:]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "8"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_idx)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. SA\n",
    "## 2.1 define loss function\n",
    "1. loss function: NLL for auctions with same `features_GT`\n",
    "2. “one for all”的不同之处在于，累加所有setting的情况求一个loss，不再区分`data_i`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def loss_func(params,other_params):\n",
    "    # start_time_lo\\ss = datetime.datetime.now()\n",
    "    alpha = params[0]\n",
    "    # delta = 1\n",
    "    labda = params[1]\n",
    "\n",
    "    # Sum up nll for all configs\n",
    "    NLL=0.0\n",
    "\n",
    "    # For those in training set\n",
    "    for i in train_idx:\n",
    "\n",
    "        data_i = readin_data_fromkey(i)\n",
    "\n",
    "        # # Extract data with same `key_i` into a table\n",
    "        # data_i = select_data_fromkey(i)\n",
    "        # data_i.reset_index(drop=True,inplace=True)\n",
    "\n",
    "        # Get params\n",
    "        v = float(data_key.iloc[i,3])\n",
    "        d = float(data_key.iloc[i,1])\n",
    "        b = float(data_key.iloc[i,2])\n",
    "        T_i = data_i['N'].astype(int)            # auction duration sequence\n",
    "\n",
    "        LEN,T = get_LEN_T(v,b,d,max(T_i))\n",
    "\n",
    "        # To get U_i given LEN and other params\n",
    "        # 如果eps设置为0，则可能出现loss=inf的情况（log(1-1)导致的）\n",
    "        U_i = get_U_GT2(LEN, v, d, b, alpha, labda)\n",
    "\n",
    "        # Calculate NLL loss under this auction setting & PT params\n",
    "        nll = get_nll_loss(T_i, U_i, LEN)\n",
    "\n",
    "        # Sum up nll for all configs\n",
    "        NLL += nll\n",
    "    print(f\"NLL loss is {NLL}\")\n",
    "    return float(NLL)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2 do SA\n",
    "1. 要对所有settings做一次infer\n",
    "2. 具体的：对每个setting `i`\n",
    "    - 每一个setting `i` 可以提取出来一个`data_i`，代表所有auction\n",
    "    - 每一个`data_i`中的`cnt_uniq`，也就是`A`，是相同的，表示setting `i` 进行的拍卖总次数.【但是这个`A`在计算loss的时候派不上用场】\n",
    "    - `N`表示duration，因此paper公式里的$T_a$即`N[a]`\n",
    "    - 因此有`A = sum(data_i['cnt_n_2'])`，其中的'cnt_n_2'表示了该行对应的`duration=N`发生的次数\n",
    "    - 按照上文，求解`U[i]_t` which is a array with shape of (max(N)),也就是求解paper里的`p_t`\n",
    "3.每次进行`L`次对参数的试探寻找，每次寻找对应一个温度一组新的参数。\n",
    "    - 优化的完成/退出条件：温度小于`T_min`或者最低温度保持`max_stay_counter`次的不变\n",
    "    - 鉴于温度小于`T_min`很难达到，因此基本上对一组参数进行优化要进行L*max_stay_counter+1次运算（loss运算）"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "params_opitim = pd.DataFrame(columns=['trial_time','alpha','delta','labda','initial_loss','final_loss','avg_loss'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> For the *0_th* trial\n",
      "NLL loss is 62854.666695331136\n",
      "> Now do SA....... \n",
      "\n",
      "NLL loss is 110128.01567383278\n",
      "NLL loss is 63249.08394861729\n",
      "NLL loss is 66814.83657259932\n",
      "NLL loss is 74629.43330652083\n",
      "NLL loss is 67159.43122089804\n",
      "NLL loss is 109273.65117551466\n",
      "NLL loss is 125080.75003436537\n",
      "NLL loss is 79495.98522086976\n",
      "NLL loss is 65954.17250542785\n",
      "NLL loss is 70373.90898482403\n",
      "NLL loss is 63231.593897289735\n",
      "NLL loss is 67727.37751678341\n",
      "NLL loss is 115659.09270959283\n",
      "NLL loss is 115901.13395920114\n",
      "NLL loss is 110080.2426829309\n",
      "NLL loss is 108351.39333268412\n",
      "NLL loss is 108167.02115382552\n",
      "NLL loss is 61362.43912956679\n",
      "NLL loss is 122227.3045313829\n",
      "NLL loss is 116794.58987649101\n",
      "NLL loss is 61751.75480942213\n",
      "NLL loss is 73655.85948869018\n",
      "NLL loss is 85067.22868533588\n",
      "NLL loss is 60620.70427117836\n",
      "NLL loss is 145818.2735351034\n",
      "NLL loss is 83222.9773344272\n",
      "NLL loss is 133128.28865542548\n",
      "NLL loss is 60651.23199784014\n",
      "NLL loss is 80293.62775502454\n",
      "NLL loss is 75152.89117657118\n",
      "NLL loss is 64907.13275335314\n",
      "NLL loss is 183015.9234867275\n",
      "NLL loss is 79295.97691336258\n",
      "NLL loss is 62580.33215997699\n",
      "NLL loss is 75566.85515159905\n",
      "NLL loss is 116548.74018890741\n",
      "NLL loss is 166131.98455847058\n",
      "NLL loss is 138355.48665728848\n",
      "NLL loss is 85951.60697459067\n",
      "NLL loss is 88873.85295326982\n",
      "NLL loss is 82709.97257297672\n",
      "NLL loss is 94670.40270101052\n",
      "NLL loss is 107133.81577878585\n",
      "NLL loss is 140960.05343752544\n",
      "NLL loss is 118855.97413916304\n",
      "NLL loss is 79629.27183316575\n",
      "NLL loss is 65853.30764216924\n",
      "NLL loss is 66771.23631951996\n",
      "NLL loss is 68104.15083369889\n",
      "NLL loss is 106560.08838786931\n",
      "NLL loss is 88326.99333627027\n",
      "NLL loss is 70091.61417475245\n",
      "NLL loss is 109287.33602700342\n",
      "NLL loss is 120695.21271019794\n",
      "NLL loss is 65167.760569087295\n",
      "NLL loss is 68611.07879291441\n",
      "NLL loss is 93515.66480451151\n",
      "NLL loss is 80810.34776714115\n",
      "NLL loss is 75253.66728422263\n",
      "NLL loss is 86732.47516507895\n",
      "NLL loss is 83741.7920972527\n",
      "NLL loss is 135045.25130814355\n",
      "NLL loss is 150473.27280674013\n",
      "NLL loss is 97493.03500598058\n",
      "NLL loss is 128300.16311028943\n",
      "NLL loss is 155886.08064284976\n",
      "NLL loss is 62373.060071617096\n",
      "NLL loss is 63321.52388281766\n",
      "NLL loss is 80570.00326073387\n",
      "NLL loss is 79454.01685035799\n",
      "NLL loss is 78242.37282869667\n",
      "NLL loss is 68930.76111064058\n",
      "NLL loss is 73206.82524523573\n",
      "NLL loss is 131931.16033365502\n",
      "NLL loss is 87298.34667108208\n",
      "NLL loss is 72931.22855658946\n",
      "NLL loss is 86803.36125114682\n",
      "NLL loss is 138125.55866868008\n",
      "NLL loss is 72880.1274574\n",
      "NLL loss is 70401.23700782377\n",
      "NLL loss is 70379.12902087995\n",
      "NLL loss is 70882.56152867625\n",
      "NLL loss is 77612.22749287267\n",
      "NLL loss is 66245.7063959716\n",
      "NLL loss is 80352.7678710447\n",
      "NLL loss is 126545.37377614672\n",
      "NLL loss is 82568.40817508563\n",
      "NLL loss is 89892.53716658482\n",
      "NLL loss is 87114.89732281493\n",
      "NLL loss is 150604.40719144823\n",
      "NLL loss is 142549.10326277654\n",
      "NLL loss is 130749.34889240103\n",
      "NLL loss is 82945.72405125263\n",
      "NLL loss is 64131.425370070196\n",
      "NLL loss is 60609.352036438846\n",
      "NLL loss is 61498.07184062897\n",
      "NLL loss is 72312.98370658146\n",
      "NLL loss is 74939.07520624243\n",
      "NLL loss is 68591.25462885873\n",
      "NLL loss is 102652.35458940125\n",
      "NLL loss is 67181.38773294305\n",
      "NLL loss is 61826.448708643635\n",
      "NLL loss is 139457.24073845946\n",
      "NLL loss is 60172.181730307\n",
      "NLL loss is 71492.8795270423\n",
      "NLL loss is 60781.820737320864\n",
      "NLL loss is 76683.8990882044\n",
      "NLL loss is 128550.4403573761\n",
      "NLL loss is 68889.76678547145\n",
      "NLL loss is 67935.78010619621\n",
      "NLL loss is 59937.34394679171\n",
      "NLL loss is 65604.13639252886\n",
      "NLL loss is 103384.94989824333\n",
      "NLL loss is 96216.20813125979\n",
      "NLL loss is 74838.70569441603\n",
      "NLL loss is 74201.4185247434\n",
      "NLL loss is 93717.77515148003\n",
      "NLL loss is 60741.72380804782\n",
      "NLL loss is 68907.54986804267\n",
      "NLL loss is 75544.92571647617\n",
      "NLL loss is 86377.97011316907\n",
      "NLL loss is 73883.41917757911\n",
      "NLL loss is 72994.88585860786\n",
      "NLL loss is 59928.028682766104\n",
      "NLL loss is 133056.8929235557\n",
      "NLL loss is 68438.02188945095\n",
      "NLL loss is 64887.235418452336\n",
      "NLL loss is 68440.13300287523\n",
      "NLL loss is 81146.51495403475\n",
      "NLL loss is 179124.77319051826\n",
      "NLL loss is 60299.43214604923\n",
      "NLL loss is 64359.000498016176\n",
      "NLL loss is 72236.95027428085\n",
      "NLL loss is 62665.48286551152\n",
      "NLL loss is 78958.0257158907\n",
      "NLL loss is 74960.73032668466\n",
      "NLL loss is 77074.76807378867\n",
      "NLL loss is 163041.42818183568\n",
      "NLL loss is 84994.47100059669\n",
      "NLL loss is 142931.0703536688\n",
      "NLL loss is 85488.74307128048\n",
      "NLL loss is 71940.78867116418\n",
      "NLL loss is 71297.14218767986\n",
      "NLL loss is 72671.70857436472\n",
      "NLL loss is 106126.09979614064\n",
      "NLL loss is 126200.37351586834\n",
      "NLL loss is 111921.78500289266\n",
      "NLL loss is 71496.38747959501\n",
      "NLL loss is 64399.75215890726\n",
      "NLL loss is 138327.92004744028\n",
      "NLL loss is 85391.18013248823\n",
      "NLL loss is 67230.9928822462\n",
      "NLL loss is 78241.74747350218\n",
      "NLL loss is 62543.260258003036\n",
      "NLL loss is 145400.97227048708\n",
      "NLL loss is 74429.4231941134\n",
      "NLL loss is 75646.87606610374\n",
      "NLL loss is 169122.97078739488\n",
      "NLL loss is 128302.87680076523\n",
      "NLL loss is 123762.41520459017\n",
      "NLL loss is 71127.69391153075\n",
      "NLL loss is 79572.25343045293\n",
      "NLL loss is 148247.44944371172\n",
      "NLL loss is 77286.19291099055\n",
      "NLL loss is 148861.6921151933\n",
      "NLL loss is 59909.04416403039\n",
      "NLL loss is 64294.108368843044\n",
      "NLL loss is 70307.71587960896\n",
      "NLL loss is 64467.612094649776\n",
      "NLL loss is 88293.02934401738\n",
      "NLL loss is 66810.14841105678\n",
      "NLL loss is 87299.68173378475\n",
      "NLL loss is 78566.54887821534\n",
      "NLL loss is 60597.01127296342\n",
      "NLL loss is 70490.79211953923\n",
      "NLL loss is 71233.74681980281\n",
      "NLL loss is 125040.08194224737\n",
      "NLL loss is 62148.40264508413\n",
      "NLL loss is 73110.93587225553\n",
      "NLL loss is 201915.28604767\n",
      "NLL loss is 104401.87269245778\n",
      "NLL loss is 65270.491994288604\n",
      "NLL loss is 127835.01754281882\n",
      "NLL loss is 82596.80772388646\n",
      "NLL loss is 76682.23304557113\n",
      "NLL loss is 68159.0240793261\n",
      "NLL loss is 114895.72604217178\n",
      "NLL loss is 84318.30104328555\n",
      "NLL loss is 65132.76654617326\n",
      "NLL loss is 92314.60065166114\n",
      "NLL loss is 67231.32565978894\n",
      "NLL loss is 86415.43157842365\n",
      "NLL loss is 79006.10866762654\n",
      "NLL loss is 63974.611264162\n",
      "NLL loss is 112150.45236771587\n",
      "NLL loss is 68181.06348310073\n",
      "NLL loss is 172001.95423046727\n",
      "NLL loss is 92364.25161452033\n",
      "NLL loss is 86274.97599479485\n",
      "NLL loss is 62235.34378495156\n",
      "NLL loss is 141763.1838090313\n",
      "NLL loss is 126488.89321438767\n",
      "NLL loss is 60741.21412861491\n",
      "NLL loss is 60492.56686045794\n",
      "NLL loss is 62050.66572185097\n",
      "NLL loss is 76272.46318865463\n",
      "NLL loss is 116239.0972062186\n",
      "NLL loss is 83241.47289560501\n",
      "NLL loss is 77933.94147361927\n",
      "NLL loss is 82423.96558139713\n",
      "NLL loss is 136782.20789681593\n",
      "NLL loss is 66686.51587023382\n",
      "NLL loss is 183017.75063925234\n",
      "NLL loss is 155813.43540077258\n",
      "NLL loss is 142922.02741852475\n",
      "NLL loss is 69283.12469279887\n",
      "NLL loss is 75302.1617470655\n",
      "NLL loss is 81466.14213827356\n",
      "NLL loss is 80298.05649021073\n",
      "NLL loss is 116351.91203442567\n",
      "NLL loss is 70350.81898337849\n",
      "NLL loss is 62101.144775153625\n",
      "NLL loss is 63953.6675268723\n",
      "NLL loss is 67231.22437808331\n",
      "NLL loss is 93296.20095474327\n",
      "NLL loss is 62629.049309619244\n",
      "NLL loss is 166570.92297948274\n",
      "NLL loss is 142874.4789154392\n",
      "NLL loss is 79488.22521277487\n",
      "NLL loss is 82327.07853176199\n",
      "NLL loss is 93475.21941095538\n",
      "NLL loss is 111926.66530468616\n",
      "NLL loss is 71142.43245498734\n",
      "NLL loss is 144083.913954483\n",
      "NLL loss is 224200.17318454638\n",
      "NLL loss is 87086.89829594409\n",
      "NLL loss is 78711.93091041662\n",
      "NLL loss is 73290.25847224938\n",
      "NLL loss is 67073.08030662723\n",
      "NLL loss is 138522.10425543936\n",
      "NLL loss is 65002.35671204703\n",
      "NLL loss is 121438.17350877059\n",
      "NLL loss is 78515.39644056659\n",
      "NLL loss is 97663.62023273161\n",
      "NLL loss is 59860.04990367445\n",
      "NLL loss is 83939.68598191575\n",
      "NLL loss is 67231.37621874592\n",
      "NLL loss is 141811.7250485609\n",
      "NLL loss is 97951.57366700796\n",
      "NLL loss is 60528.479797351945\n",
      "NLL loss is 70299.60839884485\n",
      "NLL loss is 81905.64963383543\n",
      "NLL loss is 72908.0134084424\n",
      "NLL loss is 82755.3477345469\n",
      "NLL loss is 69062.31048400498\n",
      "NLL loss is 119071.5659973806\n",
      "NLL loss is 75743.26881447654\n",
      "NLL loss is 174117.60057990876\n",
      "NLL loss is 143436.2715638006\n",
      "NLL loss is 77786.99667868875\n",
      "NLL loss is 60119.46645460395\n",
      "NLL loss is 76358.69795416904\n",
      "NLL loss is 82835.90462957835\n",
      "NLL loss is 141374.77893329225\n",
      "NLL loss is 114846.70585326018\n",
      "NLL loss is 74224.6823200981\n",
      "NLL loss is 86826.20272480803\n",
      "NLL loss is 81530.42506578896\n",
      "NLL loss is 65393.576279629844\n",
      "NLL loss is 59918.33913727224\n",
      "NLL loss is 70760.90477856083\n",
      "NLL loss is 104059.93266263152\n",
      "NLL loss is 108851.39479671817\n",
      "NLL loss is 109055.31846114477\n",
      "NLL loss is 68792.25245370522\n",
      "NLL loss is 152959.06197089094\n",
      "NLL loss is 65925.24407741347\n",
      "NLL loss is 92749.9810902105\n",
      "NLL loss is 128638.24215803272\n",
      "NLL loss is 158659.36493486335\n",
      "NLL loss is 61527.67737222654\n",
      "NLL loss is 157982.12391295106\n",
      "NLL loss is 153653.73902256016\n",
      "NLL loss is 88331.62535929374\n",
      "NLL loss is 62221.62229290341\n",
      "NLL loss is 95282.80792724395\n",
      "NLL loss is 87016.6641957423\n",
      "NLL loss is 74730.61042773181\n",
      "NLL loss is 61944.02095294227\n",
      "NLL loss is 65129.49568173817\n",
      "NLL loss is 141848.07498467164\n",
      "NLL loss is 76424.90486650892\n",
      "NLL loss is 73627.5960244736\n",
      "NLL loss is 136395.858323092\n",
      "NLL loss is 130064.2961872378\n",
      "NLL loss is 126110.11526710891\n",
      "NLL loss is 67856.67228295418\n",
      "NLL loss is 155262.0853816487\n",
      "NLL loss is 193923.82896340455\n",
      "NLL loss is 65654.84579797523\n",
      "NLL loss is 67749.92482433145\n",
      "NLL loss is 63230.70409862006\n",
      "NLL loss is 100805.44847698265\n",
      "NLL loss is 67258.9496056382\n",
      "NLL loss is 64743.95647397625\n",
      "NLL loss is 63698.209970593816\n",
      "NLL loss is 64421.376449693154\n",
      "NLL loss is 67133.36167591297\n",
      "NLL loss is 85123.28944719362\n",
      "NLL loss is 93281.65942878585\n",
      "NLL loss is 60537.46165615996\n",
      "NLL loss is 160825.58758084007\n",
      "NLL loss is 129713.17960151301\n",
      "NLL loss is 73901.93249943278\n",
      "NLL loss is 120563.25514841\n",
      "NLL loss is 72942.04738136855\n",
      "NLL loss is 62009.021301697\n",
      "NLL loss is 154529.0400821261\n",
      "NLL loss is 69331.81323277144\n",
      "NLL loss is 76192.55572155275\n",
      "NLL loss is 66570.91763790407\n",
      "NLL loss is 63157.94671753521\n",
      "NLL loss is 80146.22569130133\n",
      "NLL loss is 66642.76363240574\n",
      "NLL loss is 134473.1262590098\n",
      "NLL loss is 71251.82562999222\n",
      "NLL loss is 63924.15571262408\n",
      "NLL loss is 74352.72486202893\n",
      "NLL loss is 90680.21825982728\n",
      "NLL loss is 63178.05918950415\n",
      "NLL loss is 68336.54365804364\n",
      "NLL loss is 117585.87801609578\n",
      "NLL loss is 61701.43597115525\n",
      "NLL loss is 70437.25889608217\n",
      "NLL loss is 81202.6197334329\n",
      "NLL loss is 86555.7351308708\n",
      "NLL loss is 84844.6229184575\n",
      "NLL loss is 188076.14116139253\n",
      "NLL loss is 176203.62826509014\n",
      "NLL loss is 85846.08060036706\n",
      "NLL loss is 83311.38493076996\n",
      "NLL loss is 87043.18831945167\n",
      "NLL loss is 129906.79680378927\n",
      "NLL loss is 83048.18339416466\n",
      "NLL loss is 149980.53798466525\n",
      "NLL loss is 73855.7465414876\n",
      "NLL loss is 68248.6401531461\n",
      "NLL loss is 75099.16860209538\n",
      "NLL loss is 71959.85783898401\n",
      "NLL loss is 172009.9633747698\n",
      "NLL loss is 112701.2079563991\n",
      "NLL loss is 61963.0798018122\n",
      "NLL loss is 130146.33577810804\n",
      "NLL loss is 68033.65090115507\n",
      "NLL loss is 128729.46482373243\n",
      "NLL loss is 168661.09447136076\n",
      "NLL loss is 70796.91791724379\n",
      "NLL loss is 73877.76937550791\n",
      "NLL loss is 101622.71544904039\n",
      "NLL loss is 174529.88443090167\n",
      "NLL loss is 74586.70404596071\n",
      "NLL loss is 83485.10600308451\n",
      "NLL loss is 148100.08709841804\n",
      "NLL loss is 61334.66031157581\n",
      "NLL loss is 59862.06221577928\n",
      "NLL loss is 103243.41764859569\n",
      "NLL loss is 77346.49069432466\n",
      "NLL loss is 68568.18336015473\n",
      "NLL loss is 64860.42770623844\n",
      "NLL loss is 60279.836137150276\n",
      "NLL loss is 68419.36658931366\n",
      "NLL loss is 157841.48168483528\n",
      "NLL loss is 174060.52440957635\n",
      "NLL loss is 64295.222887109936\n",
      "NLL loss is 92390.27353623632\n",
      "NLL loss is 142774.41399675375\n",
      "NLL loss is 137126.76880554523\n",
      "NLL loss is 75908.71105121075\n",
      "NLL loss is 60612.710481132075\n",
      "NLL loss is 64888.8732103073\n",
      "NLL loss is 74265.58150091881\n",
      "NLL loss is 63025.32188004769\n",
      "NLL loss is 77613.46002332255\n",
      "NLL loss is 99828.1736080337\n",
      "NLL loss is 65933.198120321\n",
      "NLL loss is 61515.78125700458\n",
      "NLL loss is 64801.20528841286\n",
      "NLL loss is 66558.57363593137\n",
      "NLL loss is 134929.81109299726\n",
      "NLL loss is 67159.27577833668\n",
      "NLL loss is 173769.86011406415\n",
      "NLL loss is 71417.17511042768\n",
      "NLL loss is 94004.4628233144\n",
      "NLL loss is 59943.11238908902\n",
      "NLL loss is 156557.06243400555\n",
      "NLL loss is 96426.54418462842\n",
      "NLL loss is 65811.57953522496\n",
      "NLL loss is 85148.99004198286\n",
      "NLL loss is 63869.3753219128\n",
      "NLL loss is 98542.20276296805\n",
      "NLL loss is 88121.95203610265\n",
      "NLL loss is 115270.50800674148\n",
      "NLL loss is 132851.1009982618\n",
      "NLL loss is 64234.93936853355\n",
      "NLL loss is 98408.90043423734\n",
      "NLL loss is 165280.0669147198\n",
      "NLL loss is 65530.05224118136\n",
      "NLL loss is 128086.30057036987\n",
      "NLL loss is 63135.783761981475\n",
      "NLL loss is 77914.41383380517\n",
      "NLL loss is 64893.48715184175\n",
      "NLL loss is 84505.83147682084\n",
      "NLL loss is 84492.61772690655\n",
      "NLL loss is 175517.14754212176\n",
      "NLL loss is 106953.61141209574\n",
      "NLL loss is 80261.66933251616\n",
      "NLL loss is 115290.31484535385\n",
      "NLL loss is 68922.43207089388\n",
      "NLL loss is 72015.58664332346\n",
      "NLL loss is 74951.69370144334\n",
      "NLL loss is 65682.89990241833\n",
      "NLL loss is 65859.84255740598\n",
      "NLL loss is 69340.37221407233\n",
      "NLL loss is 60925.00274501858\n",
      "NLL loss is 63258.947801034934\n",
      "NLL loss is 79553.08503763708\n",
      "NLL loss is 90673.17357574172\n",
      "NLL loss is 69060.26094438144\n",
      "NLL loss is 71435.97506571101\n",
      "NLL loss is 68285.49997673176\n",
      "NLL loss is 83427.33331334218\n",
      "NLL loss is 147140.4592819441\n",
      "NLL loss is 144461.41134898065\n",
      "NLL loss is 89283.47798742326\n",
      "NLL loss is 194244.89301220572\n",
      "NLL loss is 140569.94269030046\n",
      "NLL loss is 76326.63209762992\n",
      "NLL loss is 61237.61432201571\n",
      "NLL loss is 159122.29311819794\n",
      "NLL loss is 66928.00030133741\n",
      "NLL loss is 147755.98167180782\n",
      "NLL loss is 63500.89852943166\n",
      "NLL loss is 192970.6727572763\n",
      "NLL loss is 65561.91539826311\n",
      "NLL loss is 76368.93656328712\n",
      "NLL loss is 141229.02078274824\n",
      "NLL loss is 75294.91885708434\n",
      "NLL loss is 91348.28481383609\n",
      "NLL loss is 75173.39919481764\n",
      "NLL loss is 63002.9233656814\n",
      "NLL loss is 72416.65086960862\n",
      "NLL loss is 60351.696954151696\n",
      "NLL loss is 67261.48198851231\n",
      "NLL loss is 171407.01167672395\n",
      "NLL loss is 162572.33291668657\n",
      "NLL loss is 94027.49577362469\n",
      "NLL loss is 75893.80429540465\n",
      "NLL loss is 155365.7185410184\n",
      "NLL loss is 101785.29930474752\n",
      "NLL loss is 60522.545513134966\n",
      "NLL loss is 114594.79079530411\n",
      "NLL loss is 79538.45544076046\n",
      "NLL loss is 68402.19590139054\n",
      "NLL loss is 160241.3691245531\n",
      "NLL loss is 81553.3588047824\n",
      "NLL loss is 115488.94165826988\n",
      "NLL loss is 140762.56572391416\n",
      "NLL loss is 108560.17989984721\n",
      "NLL loss is 111706.79746941385\n",
      "NLL loss is 71246.01832656942\n",
      "NLL loss is 91791.77941935325\n",
      "NLL loss is 83188.26954781414\n",
      "NLL loss is 65515.26793025398\n",
      "NLL loss is 61591.88759566955\n",
      "NLL loss is 117190.8009664419\n",
      "NLL loss is 77935.01369014889\n",
      "NLL loss is 123037.83866829016\n",
      "NLL loss is 61624.38608889574\n",
      "NLL loss is 61885.06410744326\n",
      "NLL loss is 72726.39540398611\n",
      "STOP CODE:  Stay unchanged in the last 11 iterations\n",
      "> SA ENDS....... \n",
      "\n",
      "> For the *1_th* trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_22204\\1801197125.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  params_opitim = params_opitim.append(df_tmp,ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLL loss is 62854.666695331136\n",
      "> Now do SA....... \n",
      "\n",
      "NLL loss is 117980.37580788058\n",
      "NLL loss is 112452.55653339883\n",
      "NLL loss is 106541.8803242039\n",
      "NLL loss is 183080.10785199716\n",
      "NLL loss is 74189.46583915813\n",
      "NLL loss is 74247.76454306192\n",
      "NLL loss is 98494.47799502859\n",
      "NLL loss is 64066.064282314794\n",
      "NLL loss is 93010.33402046132\n",
      "NLL loss is 62993.68501204375\n",
      "NLL loss is 147547.92890211314\n",
      "NLL loss is 180769.89762203622\n",
      "NLL loss is 168495.48610491003\n",
      "NLL loss is 173526.36361822858\n",
      "NLL loss is 99707.29655470043\n",
      "NLL loss is 110799.43047959016\n",
      "NLL loss is 62141.993783282414\n",
      "NLL loss is 88604.43054219754\n",
      "NLL loss is 70721.66175808814\n",
      "NLL loss is 75966.94252203927\n",
      "NLL loss is 79157.02425851396\n",
      "NLL loss is 94912.25875834165\n",
      "NLL loss is 153745.4589789418\n",
      "NLL loss is 69988.10870683819\n",
      "NLL loss is 69552.96638783213\n",
      "NLL loss is 115553.48769404515\n",
      "NLL loss is 77101.52384969109\n",
      "NLL loss is 78725.15546165443\n",
      "NLL loss is 67624.29206915708\n",
      "NLL loss is 75405.15052438718\n",
      "NLL loss is 63479.73658678973\n",
      "NLL loss is 60464.572353798394\n",
      "NLL loss is 73507.25403662237\n",
      "NLL loss is 73039.78245545809\n",
      "NLL loss is 61817.55431818191\n",
      "NLL loss is 70750.18802444992\n",
      "NLL loss is 61854.76566269078\n",
      "NLL loss is 162935.71804633868\n",
      "NLL loss is 64309.52526174344\n",
      "NLL loss is 112656.94107855255\n",
      "NLL loss is 60785.26307397248\n",
      "NLL loss is 99251.482522478\n",
      "NLL loss is 139753.08372392246\n",
      "NLL loss is 135716.7786979574\n",
      "NLL loss is 65401.6589214798\n",
      "NLL loss is 96823.96667860847\n",
      "NLL loss is 71327.29679423543\n",
      "NLL loss is 101682.80023567805\n",
      "NLL loss is 73954.91381250902\n",
      "NLL loss is 70821.13716688866\n",
      "NLL loss is 85382.57919048361\n",
      "NLL loss is 127199.08833699612\n",
      "NLL loss is 65614.7148484366\n",
      "NLL loss is 64379.732976453844\n",
      "NLL loss is 138724.25020372288\n",
      "NLL loss is 65890.95126944408\n",
      "NLL loss is 77147.94709557714\n",
      "NLL loss is 168776.0507413221\n",
      "NLL loss is 77443.52701494121\n",
      "NLL loss is 148935.68279026437\n",
      "NLL loss is 118583.2462980855\n",
      "NLL loss is 112839.4358475079\n",
      "NLL loss is 83468.33300264775\n",
      "NLL loss is 142020.56031226358\n",
      "NLL loss is 183575.04017948828\n",
      "NLL loss is 145094.08026795584\n",
      "NLL loss is 59971.43062560579\n",
      "NLL loss is 177558.72080912525\n",
      "NLL loss is 63792.779146142166\n",
      "NLL loss is 84627.98505788743\n",
      "NLL loss is 63944.67323300533\n",
      "NLL loss is 154425.27056731872\n",
      "NLL loss is 161800.92324565502\n",
      "NLL loss is 170523.24756659934\n",
      "NLL loss is 201323.95385025773\n",
      "NLL loss is 65455.70459905826\n",
      "NLL loss is 69722.07700413553\n",
      "NLL loss is 176928.0965326111\n",
      "NLL loss is 71808.578297962\n",
      "NLL loss is 150005.105122259\n",
      "NLL loss is 69906.11024852293\n",
      "NLL loss is 90019.58490241099\n",
      "NLL loss is 117268.75445653913\n",
      "NLL loss is 65948.85150702631\n",
      "NLL loss is 67676.15954968678\n",
      "NLL loss is 83955.48250389846\n",
      "NLL loss is 114182.02630981692\n",
      "NLL loss is 61225.306899470845\n",
      "NLL loss is 141951.5180175314\n",
      "NLL loss is 103289.56274172741\n",
      "NLL loss is 71600.8813144675\n",
      "NLL loss is 61872.93366387547\n",
      "NLL loss is 112155.62710174765\n",
      "NLL loss is 59846.324775017165\n",
      "NLL loss is 93014.21935701775\n",
      "NLL loss is 60635.31117143642\n",
      "NLL loss is 78200.7804196035\n",
      "NLL loss is 85233.1165098488\n",
      "NLL loss is 72497.36752996613\n",
      "NLL loss is 66122.8250589573\n",
      "NLL loss is 67510.83074845759\n",
      "NLL loss is 134187.27866606717\n",
      "NLL loss is 64158.19898966554\n",
      "NLL loss is 82993.33764767107\n",
      "NLL loss is 77019.45370709414\n",
      "NLL loss is 77876.5122690255\n",
      "NLL loss is 67136.26316392064\n",
      "NLL loss is 86955.39456346187\n",
      "NLL loss is 86064.8390085069\n",
      "NLL loss is 72548.18784647917\n",
      "NLL loss is 174340.21717595734\n",
      "NLL loss is 60917.578757994976\n",
      "NLL loss is 62326.899633150424\n",
      "NLL loss is 188238.92318921565\n",
      "NLL loss is 65456.62538978506\n",
      "NLL loss is 89672.45259098268\n",
      "NLL loss is 75508.13892221829\n",
      "NLL loss is 60141.427698075466\n",
      "NLL loss is 82961.12462568772\n",
      "NLL loss is 126501.84178373388\n",
      "NLL loss is 91581.4074441947\n",
      "NLL loss is 62674.34684207046\n",
      "NLL loss is 94058.60417809474\n",
      "NLL loss is 69047.52542761879\n",
      "NLL loss is 82284.4491957271\n",
      "NLL loss is 74327.35618447985\n",
      "NLL loss is 68087.79582549448\n",
      "NLL loss is 76167.26954689472\n",
      "NLL loss is 127802.25860070332\n",
      "NLL loss is 61667.67355689051\n",
      "NLL loss is 60213.228571892105\n",
      "NLL loss is 68127.96218263321\n",
      "NLL loss is 175767.82114166542\n",
      "NLL loss is 77178.7078504956\n",
      "NLL loss is 129619.14316330713\n",
      "NLL loss is 70175.48308161338\n",
      "NLL loss is 72004.87988281263\n",
      "NLL loss is 74472.0899527093\n",
      "NLL loss is 70896.75084541466\n",
      "NLL loss is 146168.9831429391\n",
      "NLL loss is 134929.41865270765\n",
      "NLL loss is 143620.51621299965\n",
      "NLL loss is 63467.601105790876\n",
      "NLL loss is 60454.280848976094\n",
      "NLL loss is 62681.40869691311\n",
      "NLL loss is 83888.27841931107\n",
      "NLL loss is 91555.08190084204\n",
      "NLL loss is 92477.0687674303\n",
      "NLL loss is 59968.080342935296\n",
      "NLL loss is 63133.36640272524\n",
      "NLL loss is 65520.513645370644\n",
      "NLL loss is 133973.47331418926\n",
      "NLL loss is 75781.77400038623\n",
      "NLL loss is 165638.95616471776\n",
      "NLL loss is 110637.77186194579\n",
      "NLL loss is 116704.60267068454\n",
      "NLL loss is 131947.61877037614\n",
      "NLL loss is 72346.66154914214\n",
      "NLL loss is 81184.8996866683\n",
      "NLL loss is 71697.69271796364\n",
      "NLL loss is 67151.60497160727\n",
      "NLL loss is 71258.18650328882\n",
      "NLL loss is 130586.34443937914\n",
      "NLL loss is 108751.07109211736\n",
      "NLL loss is 81881.41520938603\n",
      "NLL loss is 67170.90699951358\n",
      "NLL loss is 110213.16403318796\n",
      "NLL loss is 71338.85188045946\n",
      "NLL loss is 64174.447389178546\n",
      "NLL loss is 131530.53612569225\n",
      "NLL loss is 60437.07666164102\n",
      "NLL loss is 72532.9107419206\n",
      "NLL loss is 186277.2673367441\n",
      "NLL loss is 72656.31286118025\n",
      "NLL loss is 89355.89081720705\n",
      "NLL loss is 74101.04517646274\n",
      "NLL loss is 72091.73469090696\n",
      "NLL loss is 203249.89724541377\n",
      "NLL loss is 63997.474977208556\n",
      "NLL loss is 141066.69912177772\n",
      "NLL loss is 60558.32009172104\n",
      "NLL loss is 83513.8482781776\n",
      "NLL loss is 143554.99697724014\n",
      "NLL loss is 84446.84172242729\n",
      "NLL loss is 63473.55411420102\n",
      "NLL loss is 125745.93808565849\n",
      "NLL loss is 109323.83578722674\n",
      "NLL loss is 75030.9384306052\n",
      "NLL loss is 70185.4188636235\n",
      "NLL loss is 61544.29329266389\n",
      "NLL loss is 80686.28915868343\n",
      "NLL loss is 146543.84354931803\n",
      "NLL loss is 64238.83641566518\n",
      "NLL loss is 77619.30421506686\n",
      "NLL loss is 66394.41077881573\n",
      "NLL loss is 63537.41855522181\n",
      "NLL loss is 95241.54327536962\n",
      "NLL loss is 75820.2807653685\n",
      "NLL loss is 99324.89656982987\n",
      "NLL loss is 61776.17118320429\n",
      "NLL loss is 76049.88493816117\n",
      "NLL loss is 72587.01843794313\n",
      "NLL loss is 61739.549848691524\n",
      "NLL loss is 83641.85535196878\n",
      "NLL loss is 75101.36377657244\n",
      "NLL loss is 64593.75507385757\n",
      "NLL loss is 65367.00791298481\n",
      "NLL loss is 66852.20026737174\n",
      "NLL loss is 84676.49947141678\n",
      "NLL loss is 154218.64502300887\n",
      "NLL loss is 60298.157417376875\n",
      "NLL loss is 86644.85789101104\n",
      "NLL loss is 151193.3292002852\n",
      "NLL loss is 67748.69385039581\n",
      "NLL loss is 122898.89952427796\n",
      "NLL loss is 180744.08635753646\n",
      "NLL loss is 63070.835212086495\n",
      "NLL loss is 166413.8754772546\n",
      "NLL loss is 75343.80662375169\n",
      "NLL loss is 149077.75799746462\n",
      "NLL loss is 135172.57805515765\n",
      "NLL loss is 157371.40930884634\n",
      "NLL loss is 75893.05106283247\n",
      "NLL loss is 60703.79505260242\n",
      "NLL loss is 72441.82800729404\n",
      "NLL loss is 122110.89382169695\n",
      "NLL loss is 117876.27684738746\n",
      "NLL loss is 72960.38697054701\n",
      "NLL loss is 94137.48158933099\n",
      "NLL loss is 68843.48655803736\n",
      "NLL loss is 71310.66645177758\n",
      "NLL loss is 70017.58526533529\n",
      "NLL loss is 65782.80538021885\n",
      "NLL loss is 77458.85543988206\n",
      "NLL loss is 83356.15493010136\n",
      "NLL loss is 64584.95828299241\n",
      "NLL loss is 78431.09236168048\n",
      "NLL loss is 126741.2292055777\n",
      "NLL loss is 89330.60679498066\n",
      "NLL loss is 143922.50517972725\n",
      "NLL loss is 61481.357718663756\n",
      "NLL loss is 123102.68175178977\n",
      "NLL loss is 81003.55424477148\n",
      "NLL loss is 65183.62376221612\n",
      "NLL loss is 164918.1277156152\n",
      "NLL loss is 62479.937920189295\n",
      "NLL loss is 72203.88187640892\n",
      "NLL loss is 71637.99622469753\n",
      "NLL loss is 72974.55338479631\n",
      "NLL loss is 88353.0055637553\n",
      "NLL loss is 77115.79205597106\n",
      "NLL loss is 138799.74878601095\n",
      "NLL loss is 70559.5453932451\n",
      "NLL loss is 75044.29725583945\n",
      "NLL loss is 70747.82224300681\n",
      "NLL loss is 64098.70959972867\n",
      "NLL loss is 94300.99019881264\n",
      "NLL loss is 65345.575480503125\n",
      "NLL loss is 77772.15525408357\n",
      "NLL loss is 61627.52977274885\n",
      "NLL loss is 77469.19308373165\n",
      "NLL loss is 105227.87533428798\n",
      "NLL loss is 61278.74151138584\n",
      "NLL loss is 65484.336293921544\n",
      "NLL loss is 66440.13636167855\n",
      "NLL loss is 92918.17757394872\n",
      "NLL loss is 62325.710645550156\n",
      "NLL loss is 148829.13737731634\n",
      "NLL loss is 60096.22174714235\n",
      "NLL loss is 153200.58802491956\n",
      "NLL loss is 88671.77186078603\n",
      "NLL loss is 60297.35467431178\n",
      "NLL loss is 61955.42947166191\n",
      "NLL loss is 133513.52774525216\n",
      "NLL loss is 84778.53605351316\n",
      "NLL loss is 172656.957014132\n",
      "NLL loss is 63515.90657513437\n",
      "NLL loss is 89072.99151600598\n",
      "NLL loss is 140348.33727710572\n",
      "NLL loss is 80024.53451331782\n",
      "NLL loss is 72882.40392933485\n",
      "NLL loss is 96148.54667866984\n",
      "NLL loss is 61465.221393955646\n",
      "NLL loss is 66034.79829675498\n",
      "NLL loss is 111013.08334751589\n",
      "NLL loss is 100153.49087200282\n",
      "NLL loss is 124421.74317653087\n",
      "NLL loss is 166664.44556856793\n",
      "NLL loss is 62277.099399233055\n",
      "NLL loss is 150650.89742638174\n",
      "NLL loss is 80319.82655651504\n",
      "NLL loss is 141873.57238917137\n",
      "NLL loss is 61207.548889062935\n",
      "NLL loss is 172193.12404903627\n",
      "NLL loss is 65294.37231280323\n",
      "NLL loss is 62975.935499080544\n",
      "NLL loss is 62343.317748229936\n",
      "NLL loss is 77479.21449440172\n",
      "NLL loss is 184373.93083341283\n",
      "NLL loss is 75310.49704213638\n",
      "NLL loss is 132749.9926982622\n",
      "NLL loss is 62290.241133778894\n",
      "NLL loss is 185264.61719447596\n",
      "NLL loss is 68856.421837532\n",
      "NLL loss is 75490.64168103992\n",
      "NLL loss is 108506.10244129144\n",
      "NLL loss is 63286.05890568109\n",
      "NLL loss is 73848.60882991535\n",
      "NLL loss is 72369.03318841328\n",
      "NLL loss is 80448.24931038414\n",
      "NLL loss is 73980.18008908704\n",
      "NLL loss is 70841.62825719704\n",
      "NLL loss is 74511.17918338643\n",
      "NLL loss is 61861.314581192906\n",
      "NLL loss is 72161.08767972565\n",
      "NLL loss is 65297.00972529113\n",
      "NLL loss is 61218.78573687236\n",
      "NLL loss is 72049.57538127185\n",
      "NLL loss is 76164.69181213496\n",
      "NLL loss is 74434.65002235539\n",
      "STOP CODE:  Stay unchanged in the last 11 iterations\n",
      "> SA ENDS....... \n",
      "\n",
      "> For the *2_th* trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_22204\\1801197125.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  params_opitim = params_opitim.append(df_tmp,ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLL loss is 62854.666695331136\n",
      "> Now do SA....... \n",
      "\n",
      "NLL loss is 66822.23953867434\n",
      "NLL loss is 61690.479721584816\n",
      "NLL loss is 110240.37128206395\n",
      "NLL loss is 133205.0200055679\n",
      "NLL loss is 112945.86517125396\n",
      "NLL loss is 113215.50837375683\n",
      "NLL loss is 115883.1808147543\n",
      "NLL loss is 79653.27952567131\n",
      "NLL loss is 179776.50232385617\n",
      "NLL loss is 61900.6535587946\n",
      "NLL loss is 108575.74978036332\n",
      "NLL loss is 66067.94357401844\n",
      "NLL loss is 89988.07507624106\n",
      "NLL loss is 132251.6138663396\n",
      "NLL loss is 68083.45756843538\n",
      "NLL loss is 108605.27090320156\n",
      "NLL loss is 116875.3508181698\n",
      "NLL loss is 139667.86045887275\n",
      "NLL loss is 62391.60423787479\n",
      "NLL loss is 208922.63959546777\n",
      "NLL loss is 133457.40774151718\n",
      "NLL loss is 99932.12400023683\n",
      "NLL loss is 115341.22224902383\n",
      "NLL loss is 106738.49918106456\n",
      "NLL loss is 63884.65107015313\n",
      "NLL loss is 63390.92245272638\n",
      "NLL loss is 125488.67486654491\n",
      "NLL loss is 108212.31270791173\n",
      "NLL loss is 84682.28773054246\n",
      "NLL loss is 71170.93915944462\n",
      "NLL loss is 61816.77424004545\n",
      "NLL loss is 70257.3944851208\n",
      "NLL loss is 110164.78337825196\n",
      "NLL loss is 184532.51938732073\n",
      "NLL loss is 129255.69670507441\n",
      "NLL loss is 71702.2360185073\n",
      "NLL loss is 109935.5215844378\n",
      "NLL loss is 61734.85140387657\n",
      "NLL loss is 70911.98806652986\n",
      "NLL loss is 110642.51202366863\n",
      "NLL loss is 73520.65366970401\n",
      "NLL loss is 155288.0680321652\n",
      "NLL loss is 87362.96199123563\n",
      "NLL loss is 73999.19691129266\n",
      "NLL loss is 68423.06406248367\n",
      "NLL loss is 66383.1832188915\n",
      "NLL loss is 110411.45235408634\n",
      "NLL loss is 108162.19456554457\n",
      "NLL loss is 67275.20869002829\n",
      "NLL loss is 129184.29754456559\n",
      "NLL loss is 117466.70043253672\n",
      "NLL loss is 111796.99276919835\n",
      "NLL loss is 135873.35349168617\n",
      "NLL loss is 111372.54691881355\n",
      "NLL loss is 110241.6608692704\n",
      "NLL loss is 195474.85277833362\n",
      "NLL loss is 210842.73662729393\n",
      "NLL loss is 113424.04481092063\n",
      "NLL loss is 109103.20702205403\n",
      "NLL loss is 76499.83205305159\n",
      "NLL loss is 133646.5931267907\n",
      "NLL loss is 68177.65403711631\n",
      "NLL loss is 108169.8508092861\n",
      "NLL loss is 71628.53906388549\n",
      "NLL loss is 110534.66234969186\n",
      "NLL loss is 63275.01352141453\n",
      "NLL loss is 83120.62609784272\n",
      "NLL loss is 108310.20367295749\n",
      "NLL loss is 68837.79349115776\n",
      "NLL loss is 117608.84540683418\n",
      "NLL loss is 70747.12383557757\n",
      "NLL loss is 69601.4288599011\n",
      "NLL loss is 106952.42745027202\n",
      "NLL loss is 109013.9472644234\n",
      "NLL loss is 131682.64330823766\n",
      "NLL loss is 113035.7739010187\n",
      "NLL loss is 82494.47484519359\n",
      "NLL loss is 173485.03438360122\n",
      "NLL loss is 114948.4804022154\n",
      "NLL loss is 66575.16165991186\n",
      "NLL loss is 71950.45625540838\n",
      "NLL loss is 76937.96161011794\n",
      "NLL loss is 175526.27583427416\n",
      "NLL loss is 108301.9546686113\n",
      "NLL loss is 70023.89473216413\n",
      "NLL loss is 61528.35501580252\n",
      "NLL loss is 68819.53864690516\n",
      "NLL loss is 63258.338463607244\n",
      "NLL loss is 60907.6588029307\n",
      "NLL loss is 144577.441950023\n",
      "NLL loss is 60118.43661562156\n",
      "NLL loss is 80271.04983875879\n",
      "NLL loss is 60731.031415781596\n",
      "NLL loss is 88585.28803633845\n",
      "NLL loss is 107825.54201854352\n",
      "NLL loss is 114071.86195513759\n",
      "NLL loss is 115572.02499112963\n",
      "NLL loss is 60587.82290931152\n",
      "NLL loss is 132719.20662758994\n",
      "NLL loss is 66620.1888116421\n",
      "NLL loss is 131884.14661013908\n",
      "NLL loss is 135000.68974115443\n",
      "NLL loss is 66873.98911959183\n",
      "NLL loss is 62585.00332421269\n",
      "NLL loss is 65805.26355116638\n",
      "NLL loss is 79520.15869925795\n",
      "NLL loss is 153027.8048013922\n",
      "NLL loss is 174029.5773856556\n",
      "NLL loss is 76134.34219264648\n",
      "NLL loss is 76811.42872463848\n",
      "NLL loss is 104618.45247414973\n",
      "NLL loss is 68043.40033324416\n",
      "NLL loss is 64181.601745981294\n",
      "NLL loss is 72342.45606853721\n",
      "NLL loss is 152485.27622448542\n",
      "NLL loss is 62410.80472322507\n",
      "NLL loss is 121459.1481507386\n",
      "NLL loss is 114259.32209165368\n",
      "NLL loss is 71541.34628707844\n",
      "NLL loss is 75778.21977259526\n",
      "NLL loss is 69056.29898579305\n",
      "NLL loss is 67506.203228839\n",
      "NLL loss is 62071.69133613989\n",
      "NLL loss is 77467.09278287794\n",
      "NLL loss is 146658.8405476615\n",
      "NLL loss is 80190.0134017406\n",
      "NLL loss is 161284.08221815093\n",
      "NLL loss is 131893.90714295482\n",
      "NLL loss is 60886.87111317025\n",
      "NLL loss is 74510.4423188473\n",
      "NLL loss is 69823.73257471132\n",
      "NLL loss is 118963.03744624462\n",
      "NLL loss is 87899.90580187789\n",
      "NLL loss is 153802.92183296394\n",
      "NLL loss is 66498.14310924713\n",
      "NLL loss is 111767.45354122928\n",
      "NLL loss is 133494.4660976289\n",
      "NLL loss is 73932.40087466157\n",
      "NLL loss is 87781.09876426886\n",
      "NLL loss is 66642.50260161949\n",
      "NLL loss is 132322.41527675086\n",
      "NLL loss is 61850.21389845127\n",
      "NLL loss is 60269.46328048938\n",
      "NLL loss is 66443.26416147931\n",
      "NLL loss is 92971.56629230424\n",
      "NLL loss is 62298.04254360597\n",
      "NLL loss is 62915.60944611093\n",
      "NLL loss is 86652.94898777918\n",
      "NLL loss is 61534.15921823933\n",
      "NLL loss is 70055.15336247516\n",
      "NLL loss is 73892.3080321762\n",
      "NLL loss is 78041.15674339405\n",
      "NLL loss is 158547.41401179493\n",
      "NLL loss is 113078.95023485368\n",
      "NLL loss is 136635.28478955463\n",
      "NLL loss is 116549.14005430127\n",
      "NLL loss is 145840.75196801854\n",
      "NLL loss is 175456.46613589875\n",
      "NLL loss is 105916.2600284837\n",
      "NLL loss is 135035.88007782813\n",
      "NLL loss is 77371.40719192389\n",
      "NLL loss is 66349.16174495395\n",
      "NLL loss is 108671.56580208743\n",
      "NLL loss is 144120.68170045473\n",
      "NLL loss is 166027.43619066372\n",
      "NLL loss is 83138.93665291952\n",
      "NLL loss is 129685.52447519219\n",
      "NLL loss is 61463.6519390629\n",
      "NLL loss is 68506.71924171691\n",
      "NLL loss is 142067.98317391332\n",
      "NLL loss is 61912.38785506654\n",
      "NLL loss is 72982.74036879356\n",
      "NLL loss is 173234.64966963965\n",
      "NLL loss is 82677.29366069546\n",
      "NLL loss is 174918.2396171804\n",
      "NLL loss is 65924.0839818899\n",
      "NLL loss is 66503.88464191326\n",
      "NLL loss is 68261.25655335639\n",
      "NLL loss is 170116.29958014152\n",
      "NLL loss is 60124.05529297447\n",
      "NLL loss is 67470.21881472623\n",
      "NLL loss is 73720.5988385522\n",
      "NLL loss is 164764.41830539986\n",
      "NLL loss is 63378.87392991581\n",
      "NLL loss is 79726.70394421132\n",
      "NLL loss is 76833.00693109671\n",
      "NLL loss is 150351.36101844592\n",
      "NLL loss is 138315.2237616316\n",
      "NLL loss is 147842.2877024956\n",
      "NLL loss is 203087.70029330987\n",
      "NLL loss is 61276.85841369584\n",
      "NLL loss is 156307.4959042196\n",
      "NLL loss is 156618.18875952976\n",
      "NLL loss is 86727.64064457909\n",
      "NLL loss is 64493.99474132177\n",
      "NLL loss is 136525.53205791296\n",
      "NLL loss is 73135.13342106462\n",
      "NLL loss is 63344.967142111986\n",
      "NLL loss is 81287.28481151385\n",
      "NLL loss is 71245.31966619549\n",
      "NLL loss is 138085.23010542904\n",
      "NLL loss is 73586.36405500982\n",
      "NLL loss is 61099.52514280049\n",
      "NLL loss is 60623.33043270368\n",
      "NLL loss is 75447.31039201573\n",
      "NLL loss is 63547.809676860634\n",
      "NLL loss is 65889.37489561242\n",
      "NLL loss is 163251.3880102907\n",
      "NLL loss is 182304.2427191947\n",
      "NLL loss is 76699.8887823534\n",
      "NLL loss is 93201.94151642382\n",
      "NLL loss is 59822.27837490235\n",
      "NLL loss is 162792.45560127447\n",
      "NLL loss is 65176.72101655529\n",
      "NLL loss is 73979.7347363783\n",
      "NLL loss is 85297.61892303123\n",
      "NLL loss is 70566.09225179597\n",
      "NLL loss is 66943.23731285834\n",
      "NLL loss is 70044.27086774164\n",
      "NLL loss is 92807.20243377643\n",
      "NLL loss is 85960.51769026728\n",
      "NLL loss is 89830.6597844379\n",
      "NLL loss is 128719.45235604075\n",
      "NLL loss is 60711.702996371394\n",
      "NLL loss is 77181.34564976982\n",
      "NLL loss is 125753.26966248147\n",
      "NLL loss is 86600.80352500366\n",
      "NLL loss is 146895.1171697483\n",
      "NLL loss is 60959.091927128764\n",
      "NLL loss is 157507.56399041435\n",
      "NLL loss is 82007.74078308794\n",
      "NLL loss is 133002.80390331452\n",
      "NLL loss is 172375.04976604233\n",
      "NLL loss is 73594.87207413574\n",
      "NLL loss is 160676.12145257046\n",
      "NLL loss is 65887.36533364918\n",
      "NLL loss is 69417.4891470478\n",
      "NLL loss is 73840.1384079107\n",
      "NLL loss is 117469.35536017414\n",
      "NLL loss is 66824.90989596455\n",
      "NLL loss is 75471.399966317\n",
      "NLL loss is 133245.51429538795\n",
      "NLL loss is 72344.34528733307\n",
      "NLL loss is 92546.20920361602\n",
      "NLL loss is 60707.00896046565\n",
      "NLL loss is 68612.8899756582\n",
      "NLL loss is 84972.20386122717\n",
      "NLL loss is 108139.4157035673\n",
      "NLL loss is 112032.85231109259\n",
      "NLL loss is 126111.14311315493\n",
      "NLL loss is 145167.04265180646\n",
      "NLL loss is 64609.82698608181\n",
      "NLL loss is 120189.9437715432\n",
      "NLL loss is 125601.88286440825\n",
      "NLL loss is 160295.43003359513\n",
      "NLL loss is 80384.50992179668\n",
      "NLL loss is 65325.999237983255\n",
      "NLL loss is 79534.61594445158\n",
      "NLL loss is 111641.15466055267\n",
      "NLL loss is 82085.83514821925\n",
      "NLL loss is 82826.12369000305\n",
      "NLL loss is 63322.99589664262\n",
      "NLL loss is 83119.41401247679\n",
      "NLL loss is 115614.50873636153\n",
      "NLL loss is 67889.13804432435\n",
      "NLL loss is 114574.33425096584\n",
      "NLL loss is 137653.4267786031\n",
      "NLL loss is 131828.82219814343\n",
      "NLL loss is 130544.63328736494\n",
      "NLL loss is 66050.18196895036\n",
      "NLL loss is 96427.54792997387\n",
      "NLL loss is 92433.72786553919\n",
      "NLL loss is 67082.27947150444\n",
      "NLL loss is 108403.98432749341\n",
      "NLL loss is 68863.96297406079\n",
      "NLL loss is 62498.57471135751\n",
      "NLL loss is 72836.05634117221\n",
      "NLL loss is 137703.5404002183\n",
      "NLL loss is 65220.05212580405\n",
      "NLL loss is 70632.68335619809\n",
      "NLL loss is 127339.5934158322\n",
      "NLL loss is 164595.8256678391\n",
      "NLL loss is 120745.43638548841\n",
      "NLL loss is 109860.87987099742\n",
      "NLL loss is 61087.68880693728\n",
      "NLL loss is 191000.5703800108\n",
      "NLL loss is 66529.91923126987\n",
      "NLL loss is 64393.80020921661\n",
      "NLL loss is 87207.30703363352\n",
      "NLL loss is 70529.69708973027\n",
      "NLL loss is 68184.96902072695\n",
      "NLL loss is 72080.82279813013\n",
      "NLL loss is 62628.15376378315\n",
      "NLL loss is 68526.29277366825\n",
      "NLL loss is 68154.7067270295\n",
      "NLL loss is 132573.42007709874\n",
      "NLL loss is 182023.32812695144\n",
      "NLL loss is 76374.23464149944\n",
      "NLL loss is 144953.25467334368\n",
      "NLL loss is 63778.50015026559\n",
      "NLL loss is 72186.41319305381\n",
      "NLL loss is 68923.1620170485\n",
      "NLL loss is 68724.3419243401\n",
      "NLL loss is 145745.62898802964\n",
      "NLL loss is 134931.98387466912\n",
      "NLL loss is 68251.1438335161\n",
      "NLL loss is 79299.49834723143\n",
      "NLL loss is 73890.76412587929\n",
      "NLL loss is 88558.31949864475\n",
      "NLL loss is 66711.3764538896\n",
      "NLL loss is 158570.92258884438\n",
      "NLL loss is 66076.58509458406\n",
      "NLL loss is 74244.07419580531\n",
      "NLL loss is 85419.10476356607\n",
      "NLL loss is 161754.843208345\n",
      "NLL loss is 77547.72266145611\n",
      "NLL loss is 73782.89902352498\n",
      "NLL loss is 80396.1344687931\n",
      "NLL loss is 92206.97260909835\n",
      "NLL loss is 187188.39426937996\n",
      "NLL loss is 85725.83837794252\n",
      "NLL loss is 63873.62842640024\n",
      "NLL loss is 96722.65655216761\n",
      "NLL loss is 135502.0136945309\n",
      "NLL loss is 118664.56885660166\n",
      "NLL loss is 112351.59813611934\n",
      "NLL loss is 134003.69189358613\n",
      "NLL loss is 132537.09680054843\n",
      "NLL loss is 116225.07907101446\n",
      "NLL loss is 68619.0425967684\n",
      "NLL loss is 74020.58098577951\n",
      "NLL loss is 76807.59710060994\n",
      "NLL loss is 141112.73259185176\n",
      "NLL loss is 62374.641182468076\n",
      "NLL loss is 75502.39486761286\n",
      "NLL loss is 70314.86471643392\n",
      "NLL loss is 157525.88653985268\n",
      "NLL loss is 83005.36008977889\n",
      "NLL loss is 72239.18486549586\n",
      "NLL loss is 75523.91604971437\n",
      "NLL loss is 124366.78263764674\n",
      "NLL loss is 132433.87469207234\n",
      "NLL loss is 61107.43235158185\n",
      "NLL loss is 97034.23804069975\n",
      "NLL loss is 61970.55958428374\n",
      "NLL loss is 73908.2457171152\n",
      "NLL loss is 61156.916475698235\n",
      "NLL loss is 112990.32646887527\n",
      "NLL loss is 65097.23591406807\n",
      "NLL loss is 74036.94615933487\n",
      "NLL loss is 160463.5703092107\n",
      "NLL loss is 63335.3884281036\n",
      "NLL loss is 66094.76352944666\n",
      "NLL loss is 88434.68143313934\n",
      "NLL loss is 148382.40840226607\n",
      "NLL loss is 72331.63848859012\n",
      "NLL loss is 82014.0803668989\n",
      "NLL loss is 141150.00139142835\n",
      "NLL loss is 63054.072077492834\n",
      "NLL loss is 83852.70354202979\n",
      "NLL loss is 64050.27919466514\n",
      "NLL loss is 73083.56538426387\n",
      "NLL loss is 61739.62464483391\n",
      "NLL loss is 64911.18397993456\n",
      "NLL loss is 134130.93756482998\n",
      "NLL loss is 79970.67136081777\n",
      "NLL loss is 61948.58439570523\n",
      "NLL loss is 70237.69304322424\n",
      "NLL loss is 168636.98059028297\n",
      "NLL loss is 67917.20599956346\n",
      "NLL loss is 110931.26747323791\n",
      "NLL loss is 60280.3185642885\n",
      "NLL loss is 74751.87081371303\n",
      "NLL loss is 190051.77057904704\n",
      "NLL loss is 116023.36468032948\n",
      "NLL loss is 60660.80383847983\n",
      "NLL loss is 61529.96081873317\n",
      "NLL loss is 70411.23130700737\n",
      "NLL loss is 169549.17502094453\n",
      "NLL loss is 62601.65670721726\n",
      "NLL loss is 122898.50716605806\n",
      "NLL loss is 131281.37975502553\n",
      "NLL loss is 66818.65502524718\n",
      "NLL loss is 59917.57678864518\n",
      "NLL loss is 83379.26802754143\n",
      "NLL loss is 78263.27904977078\n",
      "NLL loss is 140001.31469742287\n",
      "NLL loss is 145045.42752403344\n",
      "NLL loss is 72718.59574800757\n",
      "NLL loss is 118787.04333975636\n",
      "NLL loss is 87168.22026125033\n",
      "NLL loss is 69334.43553986479\n",
      "NLL loss is 81023.33163133713\n",
      "NLL loss is 152489.55218453737\n",
      "NLL loss is 154226.64307717516\n",
      "NLL loss is 63318.87907865494\n",
      "NLL loss is 78578.13354921307\n",
      "NLL loss is 171370.47197045205\n",
      "NLL loss is 185219.6434769866\n",
      "NLL loss is 86125.7304735883\n",
      "NLL loss is 69734.98415280355\n",
      "NLL loss is 60181.2480992765\n",
      "NLL loss is 172353.61791209862\n",
      "NLL loss is 63080.5376662544\n",
      "NLL loss is 65479.817643886476\n",
      "NLL loss is 67261.9864970504\n",
      "NLL loss is 67301.94060438579\n",
      "NLL loss is 65436.63195261512\n",
      "NLL loss is 104856.4836664753\n",
      "NLL loss is 95060.3574938136\n",
      "NLL loss is 66672.65606050339\n",
      "NLL loss is 74819.32177798747\n",
      "NLL loss is 85918.67230342078\n",
      "NLL loss is 65879.75316290757\n",
      "NLL loss is 74537.78616962805\n",
      "NLL loss is 69049.33213565323\n",
      "NLL loss is 163172.35290464395\n",
      "NLL loss is 129824.63253614774\n",
      "NLL loss is 70825.4883632609\n",
      "NLL loss is 68674.50991029096\n",
      "NLL loss is 87318.46175075899\n",
      "NLL loss is 65794.01800867415\n",
      "NLL loss is 83209.52511040078\n",
      "NLL loss is 146257.0418407443\n",
      "NLL loss is 59973.112936118116\n",
      "NLL loss is 64022.30579958673\n",
      "NLL loss is 141799.91140949648\n",
      "NLL loss is 77424.91266423883\n",
      "NLL loss is 86734.60668801362\n",
      "NLL loss is 69214.86225244324\n",
      "NLL loss is 240613.79898249335\n",
      "NLL loss is 132471.68059620296\n",
      "NLL loss is 74236.19624405363\n",
      "NLL loss is 114551.75190587302\n",
      "NLL loss is 73220.11792774218\n",
      "NLL loss is 77423.01879347568\n",
      "NLL loss is 118524.0965532689\n",
      "NLL loss is 62295.544371060845\n",
      "NLL loss is 148264.21022911678\n",
      "NLL loss is 161237.9148679542\n",
      "STOP CODE:  Stay unchanged in the last 11 iterations\n",
      "> SA ENDS....... \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_22204\\1801197125.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  params_opitim = params_opitim.append(df_tmp,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Perform SA for all settings at once\n",
    "for i in range(0,max_trial):\n",
    "    print(f\"> For the *{i}_th* trial\")\n",
    "    # print(\"> Initilizing SA....... \\n\")\n",
    "    set_run_mode(loss_func, 'cached')\n",
    "    set_run_mode(loss_func, 'multithreading')\n",
    "\n",
    "    initial_t = max(data['cnt_N'].astype(int))        # initial temperature\n",
    "\n",
    "    # other_params = [max_T,v,d,b,T_i,cnt_n_2_i]\n",
    "    sa_boltzmann = SABoltzmann(func=loss_func, x0=table_5_M, other_params = [], T_max=initial_t, T_min=1, learn_rate=0.2, L=20, max_stay_counter=10, lb=lb, ub=ub)\n",
    "\n",
    "    print(\"> Now do SA....... \\n\")\n",
    "    best_x, best_y = sa_boltzmann.run()\n",
    "    # print('> The whole inference process costs {time_costs}s \\n'.format(time_costs=(datetime.datetime.now() - start_time).total_seconds()))\n",
    "\n",
    "    print(\"> SA ENDS....... \\n\")\n",
    "\n",
    "    # Append the opitimized params of this trial\n",
    "    df_tmp = pd.DataFrame([ [i,best_x[0],1,best_x[1],sa_boltzmann.generation_best_Y[0],best_y,best_y/data.shape[0]] ], columns=['trial_time','alpha','delta','labda','initial_loss','final_loss','avg_loss'])\n",
    "    params_opitim = params_opitim.append(df_tmp,ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# save 'params_opitim' for later check\n",
    "params_opitim.to_csv(params_opitim_unified_path, header=True, encoding=\"utf-8\",index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "'../../data/SA_PT/params_artificial_unified_noise=0.05_seed=512.csv'"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_opitim_unified_path"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
