{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 0.Intro\n",
    "1. https://www.cnblogs.com/miners/p/15101283.html\n",
    "2."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.functional import softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Input\n",
    "- input data： 3个输入，每个长度为4"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([3, 4])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [\n",
    "    [1, 0, 1, 0], # Input 1\n",
    "    [0, 2, 0, 2], # Input 2\n",
    "    [1, 1, 1, 1]  # Input 3\n",
    "    ]\n",
    "x = torch.tensor(x, dtype=torch.float32)\n",
    "x.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. 手动设一个weight matrix\n",
    "- 下面的3个`w`是实际要学习的权重，有了这三个w，才可以获取key，query和value。\n",
    "- 这3个`W`矩阵的shape取决于input data，因为要进行@运算，使得结果是3个`N*N`的qkv矩阵（这里N=3）"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "w_key = [\n",
    "    [0, 0, 1],\n",
    "    [1, 1, 0],\n",
    "    [0, 1, 0],\n",
    "    [1, 1, 0]\n",
    "]\n",
    "w_query = [\n",
    "    [1, 0, 1],\n",
    "    [1, 0, 0],\n",
    "    [0, 0, 1],\n",
    "    [0, 1, 1]\n",
    "]\n",
    "w_value = [\n",
    "    [0, 2, 0],\n",
    "    [0, 3, 0],\n",
    "    [1, 0, 3],\n",
    "    [1, 1, 0]\n",
    "]\n",
    "w_key = torch.tensor(w_key, dtype=torch.float32)\n",
    "w_query = torch.tensor(w_query, dtype=torch.float32)\n",
    "w_value = torch.tensor(w_value, dtype=torch.float32)\n",
    "\n",
    "# print(\"Weights for key: \\n\", w_key)\n",
    "# print(\"Weights for query: \\n\", w_query)\n",
    "# print(\"Weights for value: \\n\", w_value)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. 矩阵乘法计算qkv\n",
    "1. Note: 通常在神经网络的初始化过程中，这些参数`w`都是比较小的，一般会在Gaussian, Xavier and Kaiming distributions随机采样完成。\n",
    "2. 在我们实际的应用中，有可能会在点乘后，加上一个bias的向量\n",
    "3. qkv都是`N*N`的矩阵"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: \n",
      " tensor([[0., 1., 1.],\n",
      "        [4., 4., 0.],\n",
      "        [2., 3., 1.]])\n",
      "Querys: \n",
      " tensor([[1., 0., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 1., 3.]])\n",
      "Values: \n",
      " tensor([[1., 2., 3.],\n",
      "        [2., 8., 0.],\n",
      "        [2., 6., 3.]])\n"
     ]
    }
   ],
   "source": [
    "keys = x @ w_key\n",
    "querys = x @ w_query\n",
    "values = x @ w_value\n",
    "\n",
    "print(\"Keys: \\n\", keys)\n",
    "print(\"Querys: \\n\", querys)\n",
    "print(\"Values: \\n\", values)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. 计算attn scores: q和k相乘\n",
    "1. 为了获取input1的attention score，我们使用点乘来处理所有的key和query\n",
    "2. 比如：【请在edit模式下阅读】，[1,0,2]表示input1的query，必须乘keys的T才可以\n",
    "            [0, 4, 2]\n",
    "[1, 0, 2] x [1, 4, 3] = [2, 4, 4]\n",
    "            [1, 0, 1]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 2.,  4.,  4.],\n        [ 4., 16., 12.],\n        [ 4., 12., 10.]])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_scores = querys @ keys.T   # keys@querys.T\n",
    "# tensor([[ 2.,  4.,  4.],  # attention scores from Query 1\n",
    "#         [ 4., 16., 12.],  # attention scores from Query 2\n",
    "#         [ 4., 12., 10.]]) # attention scores from Query 3\n",
    "attn_scores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 通常会给attn scores添加softmax"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6.3379e-02, 4.6831e-01, 4.6831e-01],\n",
      "        [6.0337e-06, 9.8201e-01, 1.7986e-02],\n",
      "        [2.9539e-04, 8.8054e-01, 1.1917e-01]])\n",
      "tensor([[0.0000, 0.5000, 0.5000],\n",
      "        [0.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.9000, 0.1000]])\n"
     ]
    }
   ],
   "source": [
    "attn_scores_softmax = softmax(attn_scores, dim=-1)\n",
    "print(attn_scores_softmax)\n",
    "# tensor([[6.3379e-02, 4.6831e-01, 4.6831e-01],\n",
    "#         [6.0337e-06, 9.8201e-01, 1.7986e-02],\n",
    "#         [2.9539e-04, 8.8054e-01, 1.1917e-01]])\n",
    "\n",
    "# For readability, approximate the above as follows\n",
    "attn_scores_softmax = [\n",
    "  [0.0, 0.5, 0.5],  # attention scores from Query 1\n",
    "  [0.0, 1.0, 0.0],  # attention scores from Query 2\n",
    "  [0.0, 0.9, 0.1]   # attention scores from Query 3\n",
    "]\n",
    "attn_scores_softmax = torch.tensor(attn_scores_softmax)\n",
    "print(attn_scores_softmax)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5.value乘score\n",
    "1. 得到3个weighted values\n",
    "2. 比如：[0,0.5,0.5]是input 1的attn score，我需要这3个attn score分别乘到value上去，以表示input 1对于3个value的“看法”，得到的矩阵就是\n",
    "1: 0.0 * [1, 2, 3] = [0.0, 0.0, 0.0]\n",
    "2: 0.5 * [2, 8, 0] = [1.0, 4.0, 0.0]\n",
    "3: 0.5 * [2, 6, 3] = [1.0, 3.0, 1.5]\n",
    "3. 上述矩阵相加，就是input 1的new representation，**实际上是value矩阵在attn下加权求和的过程**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[1.0000, 4.0000, 0.0000],\n",
      "         [2.0000, 8.0000, 0.0000],\n",
      "         [1.8000, 7.2000, 0.0000]],\n",
      "\n",
      "        [[1.0000, 3.0000, 1.5000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.2000, 0.6000, 0.3000]]])\n"
     ]
    }
   ],
   "source": [
    "# `None`表示在指定位置(此处是第二维)添加一维。\n",
    "# value变成(3,1,3),attn_scores_softmax.T变成(3,3,1)\n",
    "# 此时第一dim表示的是N,\n",
    "weighted_values = values[:,None,:] * attn_scores_softmax.T[:,:,None]\n",
    "print(weighted_values)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 把所有的weighted values进行element-wise的相加\n",
    "- **其中的结果向量[2.0, 7.0, 1.5]就是ouput1的和其他key交互的query representation**。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.0000, 7.0000, 1.5000],\n",
      "        [2.0000, 8.0000, 0.0000],\n",
      "        [2.0000, 7.8000, 0.3000]])\n"
     ]
    }
   ],
   "source": [
    "outputs = weighted_values.sum(dim=0)\n",
    "print(outputs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 因此是把n个1×T的encoding，变成n个1×n的encoding\n",
    "- 需要的参数3×T×n+bias"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
