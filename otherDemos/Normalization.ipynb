{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. BatchNorm\n",
    "1. 在batch内对某个channel求平均，"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m: BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "tensor([[ 0.5000,  1.0000,  1.5000,  2.0000],\n",
      "        [ 0.5000,  1.0000,  1.5000,  2.0000],\n",
      "        [-0.5000, -1.0000, -1.5000, -2.0000]], grad_fn=<MeanBackward1>)\n",
      "input: torch.Size([2, 3, 4])\n",
      "output: tensor([[[-0.1690,  0.5071,  1.1832,  1.8593],\n",
      "         [-0.1690,  0.5071,  1.1832,  1.8593],\n",
      "         [ 0.1690, -0.5071, -1.1832, -1.8593]],\n",
      "\n",
      "        [[-0.8452, -0.8452, -0.8452, -0.8452],\n",
      "         [-0.8452, -0.8452, -0.8452, -0.8452],\n",
      "         [ 0.8452,  0.8452,  0.8452,  0.8452]]],\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "output_2: tensor([[[-1.3416, -0.4472,  0.4472,  1.3416],\n",
      "         [-1.3416, -0.4472,  0.4472,  1.3416],\n",
      "         [ 1.3416,  0.4472, -0.4472, -1.3416]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000]]], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "### BatchNorm2d测试\n",
    "\n",
    "m = nn.BatchNorm1d(3, affine=False)  # affine: With Learnable Parameters or not\n",
    "print('m:', m)\n",
    "# The mean and std are calculated per-dimension over the mini-batches\n",
    "input = torch.tensor([\n",
    "    [[1.,2.,3.,4.],[1.,2.,3.,4.],[-1.,-2.,-3.,-4.]],\n",
    "    [[0.,0.,0.,0.],[0.,0.,0.,0.],[0.,0.,0.,0.]]\n",
    "], requires_grad=True)\n",
    "\n",
    "input_mean = torch.mean(input,dim=0)\n",
    "print(input_mean)\n",
    "print('input:', input.shape)\n",
    "output = m(input) # 归一化\n",
    "print('output:', output)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2 详细复现"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 4])\n"
     ]
    }
   ],
   "source": [
    "input = torch.tensor([[[1.,2.,3.,4.]],[[0.,0.,0.,0.]]])\n",
    "print(input.shape)\n",
    "# torch.Size([2, 1, 4])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---BN1---\n",
      "tensor([[-0.1690,  0.5071,  1.1832,  1.8593],\n",
      "        [-0.8452, -0.8452, -0.8452, -0.8452]])\n"
     ]
    }
   ],
   "source": [
    "BN1 = nn.BatchNorm1d(num_features=1,affine=False,eps=0)\n",
    "# input只有1个feature（只有1个channel），每个features的长度=4，第一个batch\n",
    "print(\"---BN1---\")\n",
    "print(torch.squeeze(BN1(input)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1690,  0.5071,  1.1832,  1.8593],\n",
      "        [-0.8452, -0.8452, -0.8452, -0.8452]])\n"
     ]
    }
   ],
   "source": [
    "ans = (input-torch.mean(torch.flatten(input)))/torch.sqrt(torch.var(torch.flatten(input),unbiased=False))\n",
    "print(torch.squeeze(ans))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Without Learnable Parameters\n",
    "m = nn.InstanceNorm1d(100)\n",
    "# With Learnable Parameters\n",
    "m = nn.InstanceNorm1d(100, affine=True)\n",
    "input = torch.randn(20, 100, 40)\n",
    "output = m(input)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[-1.4831e+00, -8.8348e-01,  6.8768e-01,  ..., -8.1930e-01,\n           6.9095e-01, -5.3252e-01],\n         [-1.2327e+00, -1.2125e+00, -7.2121e-01,  ..., -4.8107e-01,\n           3.9293e-01,  8.9848e-02],\n         [ 5.3689e-01,  1.3290e+00,  1.5948e-01,  ...,  8.6816e-02,\n          -4.4383e-01,  1.2817e+00],\n         ...,\n         [-9.7964e-02, -1.9393e-01,  4.0485e-01,  ...,  1.0258e-01,\n          -9.5850e-01, -1.0013e+00],\n         [ 4.5442e-01,  3.6064e-01,  3.2127e-01,  ..., -1.1502e+00,\n           5.7419e-01, -7.5054e-01],\n         [-4.1566e-01, -2.6860e-01, -7.3793e-01,  ..., -2.7608e-01,\n          -1.4282e+00,  2.0695e+00]],\n\n        [[-2.0859e-01, -8.0312e-01, -1.6692e+00,  ...,  6.6337e-01,\n          -1.7105e-01, -5.3840e-01],\n         [ 1.2919e+00, -7.0192e-01,  2.2917e+00,  ...,  9.9064e-01,\n          -9.4029e-02,  2.6051e-01],\n         [ 3.3777e-01,  4.2390e-01,  2.9630e-01,  ...,  1.6087e+00,\n           6.4012e-02, -1.1709e-02],\n         ...,\n         [ 8.0837e-01,  4.5672e-01, -3.4312e-01,  ..., -4.7515e-01,\n          -5.5667e-01,  1.9267e+00],\n         [-1.4931e+00,  1.3285e-01,  8.7858e-01,  ...,  4.1779e-03,\n          -8.9041e-01, -1.4108e+00],\n         [-6.6864e-03,  1.6153e+00,  1.0818e+00,  ...,  8.0462e-01,\n           1.2680e+00, -1.2013e+00]],\n\n        [[ 5.3600e-01,  1.0238e+00, -1.2504e+00,  ...,  7.4186e-01,\n           1.1041e+00,  1.1313e+00],\n         [-2.1227e-01,  1.3349e+00, -7.1143e-02,  ..., -4.3082e-01,\n           2.9995e-02,  1.4690e+00],\n         [ 9.1977e-01,  3.0581e-02,  4.2994e-01,  ..., -1.3761e+00,\n          -7.7635e-01,  7.6174e-01],\n         ...,\n         [ 6.7313e-01, -7.6058e-01,  6.6069e-01,  ..., -9.3665e-01,\n          -1.1390e+00,  1.4198e+00],\n         [ 9.8966e-01, -1.7290e+00, -1.8902e-01,  ...,  8.6627e-04,\n          -5.4328e-01,  9.5829e-01],\n         [-1.2937e+00, -6.7935e-01,  4.8284e-01,  ...,  6.7220e-02,\n           1.9461e-01,  1.2897e+00]],\n\n        ...,\n\n        [[-9.3191e-01, -6.3372e-01,  3.2227e-01,  ..., -2.0725e+00,\n           6.9024e-01,  1.3310e+00],\n         [-2.1224e+00,  9.5523e-01, -9.7266e-02,  ...,  5.3975e-01,\n          -1.1152e+00,  7.6110e-01],\n         [ 7.7698e-01,  8.8249e-01, -3.4838e-01,  ..., -2.9553e-01,\n          -5.8040e-01, -1.3132e+00],\n         ...,\n         [-4.2168e-01,  6.9595e-01,  1.8454e+00,  ..., -7.2850e-01,\n           1.2678e-01, -1.7043e-01],\n         [-8.6645e-01, -1.3985e-01, -2.8406e-01,  ...,  1.6404e+00,\n           1.1040e-01, -5.3154e-01],\n         [-3.5336e-01,  3.8537e-01,  1.8186e-01,  ..., -6.8805e-01,\n          -4.4753e-01,  2.7006e-01]],\n\n        [[-1.6931e+00,  3.7870e-01,  9.9955e-01,  ...,  1.7673e-01,\n           9.0113e-01, -3.7878e-01],\n         [-4.6148e-01, -7.4075e-01,  1.5966e+00,  ...,  1.7211e-01,\n           7.8180e-01, -1.0299e+00],\n         [-1.0623e+00,  4.5111e-01,  7.3343e-01,  ...,  6.5483e-01,\n           6.6650e-01, -6.7174e-01],\n         ...,\n         [-3.3652e-01,  9.5825e-01, -1.8304e-02,  ...,  5.7344e-01,\n           1.2316e+00,  1.2468e-01],\n         [-2.0841e+00, -9.3217e-01, -9.4802e-01,  ..., -6.4424e-01,\n          -1.5186e+00, -2.9483e-01],\n         [ 7.0897e-01, -1.6648e+00, -2.3819e+00,  ...,  5.0356e-01,\n           6.2224e-01, -1.7134e-01]],\n\n        [[ 9.6461e-01, -3.6769e-01,  2.1273e-01,  ...,  5.4014e-01,\n           1.4736e-01, -6.7125e-01],\n         [-7.7949e-03, -1.2696e-01, -7.9127e-01,  ...,  2.6946e+00,\n           7.7127e-01,  1.1656e+00],\n         [ 8.4931e-02,  2.2164e+00,  6.0538e-01,  ..., -5.1987e-01,\n          -1.1352e+00, -1.7810e-01],\n         ...,\n         [ 7.9959e-01, -1.0310e+00,  2.2336e-01,  ...,  1.9520e+00,\n           1.3386e+00,  1.2221e+00],\n         [ 9.4221e-01,  1.7899e+00,  2.3805e+00,  ...,  5.9890e-02,\n           1.0042e+00,  1.7569e+00],\n         [-1.2096e+00,  2.2821e+00,  1.9303e-02,  ...,  1.9556e+00,\n          -2.1143e-01,  5.1547e-01]]], grad_fn=<ViewBackward0>)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. InstanceNorm\n",
    "1. 此时只和[1.,2.,3.,4.]Norm后的结果，只和这一组数据有关，所以是“instance”"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4])\n",
      "output_2: tensor([[[-1.3416, -0.4472,  0.4472,  1.3416],\n",
      "         [-1.3411, -0.4470,  0.4470,  1.3411],\n",
      "         [ 1.3416,  0.4472, -0.4472, -1.3416]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000]]], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.tensor([\n",
    "    [[1.,2.,3.,4.],[0.1,0.2,0.3,0.4],[-1.,-2.,-3.,-4.]],\n",
    "    [[0.,0.,0.,0.],[0.,0.,0.,0.],[0.,0.,0.,0.]]\n",
    "], requires_grad=True)\n",
    "\n",
    "print(input.shape)\n",
    "m2 = nn.InstanceNorm1d(num_features=3,affine=False)\n",
    "output_2 = m2(input)\n",
    "print('output_2:', output_2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([-1.3416, -0.4472,  0.4472,  1.3416])"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 复现：\n",
    "one_chanel = torch.tensor([1.,2.,3.,4.])\n",
    "mean_value = torch.mean(one_chanel)\n",
    "std_value = torch.std(one_chanel,unbiased=False)\n",
    "\n",
    "(one_chanel - mean_value) / std_value"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4])\n",
      "output_3: tensor([[-1.3416, -0.4472,  0.4472,  1.3416],\n",
      "        [-1.2910, -0.4303,  0.4303,  1.2910],\n",
      "        [ 1.3416,  0.4472, -0.4472, -1.3416]], grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.tensor([\n",
    "    [1.,2.,3.,4.],[0.01,0.02,0.03,0.04],[-1.,-2.,-3.,-4.],\n",
    "], requires_grad=True)\n",
    "print(input.shape)\n",
    "\n",
    "m3 = nn.InstanceNorm1d(num_features=3,affine=True)\n",
    "output_3 = m3(input)\n",
    "print('output_3:', output_3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. LayerNorm\n",
    "1. 从参数可以看出来，是elementwise的求值\n",
    "2. 没有channel之分，管你什么channel什么batch，除了`normalized_shape`，其他维度都flatten，都拿进来求mean求std\n",
    "3. RNN中使用它是因为：\n",
    "    - 对于同一时刻的数据，必须保持相对大小“统一”\n",
    "4. https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html#layernorm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4])\n",
      "torch.Size([6, 4])\n",
      "output_4: tensor([[[-1.5213, -0.1690,  0.5071,  1.1832],\n",
      "         [ 1.6867, -0.8835, -0.5622, -0.2410],\n",
      "         [ 1.3416,  0.4472, -0.4472, -1.3416]],\n",
      "\n",
      "        [[-1.7320,  0.5773,  0.5773,  0.5773],\n",
      "         [-1.7320,  0.5773,  0.5773,  0.5773],\n",
      "         [ 1.7320, -0.5773, -0.5773, -0.5773]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.tensor([\n",
    "    [[0,2.,3.,4.],[1,0.2,0.3,0.4],[-1.,-2.,-3.,-4.]],\n",
    "    [[-1,0.,0.,0.],[-1,0.,0.,0.],[1,0.,0.,0.]]\n",
    "], requires_grad=True)\n",
    "\n",
    "print(input.shape)\n",
    "m4 = nn.LayerNorm(normalized_shape=4,elementwise_affine=True)\n",
    "output_4 = m4(input)\n",
    "print('output_4:', output_4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. GROUPNORM\n",
    "1. 思想是把channel分成不同的group：\n",
    "    - 可以和InstanceNorm互换\n",
    "    - 可以和LayerNorm互换"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Separate 6 channels into 6 groups (equivalent with InstanceNorm)\n",
    "m = nn.GroupNorm(6, 6)\n",
    "\n",
    "#Put all 6 channels into a single group (equivalent with LayerNorm)\n",
    "m = nn.GroupNorm(1, 6)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "3.5"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "sum(np.arange(1,8))/8"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "2.7"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.arange(1,3))/6 + sum(np.arange(4,8))/10"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
